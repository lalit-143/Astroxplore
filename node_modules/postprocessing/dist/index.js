/**
 * postprocessing v7.0.0-alpha-1 build Tue Jan 02 2024
 * https://github.com/pmndrs/postprocessing
 * Copyright 2015 Raoul van RÃ¼schen
 * @license Zlib
 */

// package.json
var version = "7.0.0-alpha-1";

// src/core/Input.ts
import { EventDispatcher as EventDispatcher3, UnsignedByteType } from "three";

// src/enums/GBuffer.ts
var GBuffer = /* @__PURE__ */ ((GBuffer2) => {
  GBuffer2["COLOR"] = "GBUFFER_COLOR";
  GBuffer2["DEPTH"] = "GBUFFER_DEPTH";
  GBuffer2["NORMAL"] = "GBUFFER_NORMAL";
  GBuffer2["ROUGHNESS"] = "GBUFFER_ROUGHNESS";
  GBuffer2["METALNESS"] = "GBUFFER_METALNESS";
  return GBuffer2;
})(GBuffer || {});

// src/utils/ObservableMap.ts
import { EventDispatcher } from "three";
var ObservableMap = class _ObservableMap extends EventDispatcher {
  /**
   * Triggers when an entry is added, replaced or removed.
   *
   * @event
   */
  static EVENT_CHANGE = "change";
  /**
   * The internal data collection.
   */
  data;
  /**
   * Constructs a new map.
   *
   * @param iterable - A list of entries to add to this map.
   */
  constructor(iterable) {
    super();
    this.data = new Map(iterable);
  }
  get size() {
    return this.data.size;
  }
  get [Symbol.toStringTag]() {
    return this.data[Symbol.toStringTag];
  }
  clear() {
    const result = this.data.clear();
    this.dispatchEvent({ type: _ObservableMap.EVENT_CHANGE });
    return result;
  }
  delete(key) {
    const result = this.data.delete(key);
    this.dispatchEvent({ type: _ObservableMap.EVENT_CHANGE });
    return result;
  }
  get(key) {
    return this.data.get(key);
  }
  has(key) {
    return this.data.has(key);
  }
  set(key, value) {
    this.data.set(key, value);
    this.dispatchEvent({ type: _ObservableMap.EVENT_CHANGE });
    return this;
  }
  entries() {
    return this.data.entries();
  }
  keys() {
    return this.data.keys();
  }
  values() {
    return this.data.values();
  }
  forEach(callbackfn, thisArg) {
    return this.data.forEach(callbackfn, thisArg);
  }
  [Symbol.iterator]() {
    return this.data[Symbol.iterator]();
  }
};

// src/utils/ObservableSet.ts
import { EventDispatcher as EventDispatcher2 } from "three";
var ObservableSet = class _ObservableSet extends EventDispatcher2 {
  /**
   * Triggers when an entry is added, replaced or removed.
   *
   * @event
   */
  static EVENT_CHANGE = "change";
  /**
   * The internal data collection.
   */
  data;
  /**
   * Constructs a new set.
   *
   * @param iterable - A list of entries to add to this set.
   */
  constructor(iterable) {
    super();
    this.data = new Set(iterable);
  }
  get size() {
    return this.data.size;
  }
  get [Symbol.toStringTag]() {
    return this.data[Symbol.toStringTag];
  }
  clear() {
    const result = this.data.clear();
    this.dispatchEvent({ type: _ObservableSet.EVENT_CHANGE });
    return result;
  }
  delete(value) {
    const result = this.data.delete(value);
    this.dispatchEvent({ type: _ObservableSet.EVENT_CHANGE });
    return result;
  }
  has(value) {
    return this.data.has(value);
  }
  add(value) {
    this.data.add(value);
    this.dispatchEvent({ type: _ObservableSet.EVENT_CHANGE });
    return this;
  }
  entries() {
    return this.data.entries();
  }
  keys() {
    return this.data.keys();
  }
  values() {
    return this.data.values();
  }
  forEach(callbackfn, thisArg) {
    return this.data.forEach(callbackfn, thisArg);
  }
  [Symbol.iterator]() {
    return this.data[Symbol.iterator]();
  }
};

// src/core/Input.ts
var Input = class _Input extends EventDispatcher3 {
  /**
   * Triggers when an input resource is added, replaced or removed.
   *
   * This event is also fired when gBuffer components are changed. The actual gBuffer textures can be accessed through
   * the {@link textures} map by using {@link GBuffer} values as keys.
   *
   * @event
   */
  static EVENT_CHANGE = "change";
  /**
   * Identifies the default input buffer in the {@link textures} collection.
   */
  static BUFFER_DEFAULT = "buffer.default";
  defines;
  uniforms;
  /**
   * Required gBuffer components.
   *
   * {@link GBuffer.COLOR} is included by default.
   */
  gBuffer;
  /**
   * Input textures.
   *
   * Entries specified in {@link gBuffer} will be added automatically.
   *
   * @see {@link EVENT_CHANGE}
   */
  textures;
  /**
   * Constructs new input resources.
   */
  constructor() {
    super();
    const defines = new ObservableMap();
    const uniforms = new ObservableMap();
    const textures = new ObservableMap();
    const gBuffer = new ObservableSet(["GBUFFER_COLOR" /* COLOR */]);
    uniforms.addEventListener(ObservableMap.EVENT_CHANGE, (e) => this.dispatchEvent(e));
    textures.addEventListener(ObservableMap.EVENT_CHANGE, (e) => this.dispatchEvent(e));
    gBuffer.addEventListener(ObservableSet.EVENT_CHANGE, (e) => this.dispatchEvent(e));
    this.defines = defines;
    this.uniforms = uniforms;
    this.textures = textures;
    this.gBuffer = gBuffer;
  }
  /**
   * Alias for {@link textures}.
   */
  get buffers() {
    return this.textures;
  }
  /**
   * The default input buffer.
   */
  get defaultBuffer() {
    return this.textures.get(_Input.BUFFER_DEFAULT) || null;
  }
  set defaultBuffer(value) {
    this.textures.set(_Input.BUFFER_DEFAULT, value);
  }
  /**
   * Indicates whether the default buffer uses high precision.
   */
  get frameBufferPrecisionHigh() {
    return this.defaultBuffer?.type !== UnsignedByteType;
  }
};

// src/core/IOManager.ts
import { SRGBColorSpace as SRGBColorSpace3, WebGLMultipleRenderTargets as WebGLMultipleRenderTargets4 } from "three";

// src/passes/ClearPass.ts
import { Color as Color2, WebGLMultipleRenderTargets as WebGLMultipleRenderTargets2 } from "three";

// src/core/Pass.ts
import {
  BufferAttribute,
  BufferGeometry,
  EventDispatcher as EventDispatcher6,
  Mesh,
  OrthographicCamera as OrthographicCamera2,
  RawShaderMaterial as RawShaderMaterial2,
  Scene,
  ShaderMaterial,
  WebGLRenderTarget as WebGLRenderTarget2
} from "three";

// src/materials/FullscreenMaterial.ts
import {
  GLSL3,
  LinearSRGBColorSpace,
  NoBlending,
  PerspectiveCamera,
  RawShaderMaterial,
  SRGBColorSpace,
  Uniform as Uniform2,
  UnsignedByteType as UnsignedByteType2,
  Vector3,
  Vector4
} from "three";
var FullscreenMaterial = class extends RawShaderMaterial {
  /**
   * Constructs a new fullscreen shader material.
   */
  constructor(parameters) {
    super(Object.assign({
      name: "FullscreenMaterial",
      glslVersion: GLSL3,
      blending: NoBlending,
      depthWrite: false,
      depthTest: false
    }, parameters));
    Object.assign(this.uniforms, {
      projectionMatrix: new Uniform2(null),
      projectionMatrixInverse: new Uniform2(null),
      cameraParams: new Uniform2(new Vector3()),
      resolution: new Uniform2(new Vector4()),
      inputBuffer: new Uniform2(null)
    });
    this.outputPrecision = "lowp";
    this.onBeforeCompile = (shader, renderer) => {
      if (shader.defines === void 0 || shader.defines === null) {
        shader.defines = {};
      }
      if (renderer.getRenderTarget() === null) {
        shader.defines.RENDER_TO_SCREEN = true;
        switch (renderer.outputColorSpace) {
          case SRGBColorSpace:
            shader.defines.OUTPUT_COLOR_SPACE = 1;
            break;
          case LinearSRGBColorSpace:
            shader.defines.OUTPUT_COLOR_SPACE = 0;
            break;
          default:
            throw new Error(`Unsupported color space: ${renderer.outputColorSpace}`);
        }
        this.outputPrecision = "lowp";
        this.needsUpdate = false;
      } else {
        shader.defines.OUTPUT_COLOR_SPACE = 0;
      }
    };
  }
  /**
   * The precision of the output color.
   *
   * This setting will be set automatically by the I/O manager.
   */
  get outputPrecision() {
    return this.defines.OUTPUT_COLOR_PRECISION;
  }
  set outputPrecision(value) {
    this.defines.OUTPUT_COLOR_PRECISION = value;
    this.needsUpdate = true;
  }
  /**
   * Indicates whether the input buffer uses high precision.
   */
  get frameBufferPrecisionHigh() {
    return this.defines.FRAME_BUFFER_PRECISION_HIGH !== void 0;
  }
  set frameBufferPrecisionHigh(value) {
    if (this.frameBufferPrecisionHigh !== value) {
      if (value) {
        this.defines.FRAME_BUFFER_PRECISION_HIGH = true;
      } else {
        delete this.defines.FRAME_BUFFER_PRECISION_HIGH;
      }
      this.needsUpdate = true;
    }
  }
  /**
   * The input buffer.
   *
   * If this buffer uses high precision, the macro `FRAME_BUFFER_PRECISION_HIGH` will be defined.
   */
  get inputBuffer() {
    return this.uniforms.inputBuffer.value;
  }
  set inputBuffer(value) {
    this.frameBufferPrecisionHigh = value !== null && value.type !== UnsignedByteType2;
    this.uniforms.inputBuffer.value = value;
  }
  /**
   * The current camera near plane value.
   */
  get near() {
    const cameraParams = this.uniforms.cameraParams.value;
    return cameraParams.x;
  }
  /**
   * The current camera far plane value.
   */
  get far() {
    const cameraParams = this.uniforms.cameraParams.value;
    return cameraParams.y;
  }
  /**
   * Copies the settings of the given camera.
   *
   * Updates the `cameraParams` uniform and updates the `PERSPECTIVE_CAMERA` macro.
   *
   * @param camera - A camera.
   */
  copyCameraSettings(camera) {
    this.uniforms.projectionMatrix.value = camera.projectionMatrix;
    this.uniforms.projectionMatrixInverse.value = camera.projectionMatrixInverse;
    const cameraParams = this.uniforms.cameraParams.value;
    cameraParams.set(camera.near, camera.far, 1);
    if (camera instanceof PerspectiveCamera) {
      this.defines.PERSPECTIVE_CAMERA = true;
    } else {
      delete this.defines.PERSPECTIVE_CAMERA;
    }
    this.needsUpdate = true;
  }
  /**
   * Updates the `resolution` uniform (XY = resolution, ZW = texelSize).
   *
   * @param width - The width.
   * @param height - The height.
   */
  setSize(width, height) {
    const resolution = this.uniforms.resolution.value;
    resolution.set(width, height, 1 / width, 1 / height);
    const cameraParams = this.uniforms.cameraParams.value;
    cameraParams.z = width / height;
  }
};

// src/enums/LogLevel.ts
var LogLevel = /* @__PURE__ */ ((LogLevel2) => {
  LogLevel2[LogLevel2["ERROR"] = 0] = "ERROR";
  LogLevel2[LogLevel2["WARN"] = 1] = "WARN";
  LogLevel2[LogLevel2["INFO"] = 2] = "INFO";
  LogLevel2[LogLevel2["DEBUG"] = 3] = "DEBUG";
  return LogLevel2;
})(LogLevel || {});

// src/utils/Log.ts
var Log = class _Log {
  /**
   * The current log level. Default is {@link LogLevel.ERROR}.
   */
  static level = 0 /* ERROR */;
  /**
   * Logs an error message.
   *
   * @param data - The data to log.
   */
  static error(...data) {
    if (_Log.level >= 0 /* ERROR */) {
      console.error(...data);
    }
  }
  /**
   * Logs a warning message.
   *
   * @param data - The data to log.
   */
  static warn(...data) {
    if (_Log.level >= 1 /* WARN */) {
      console.warn(...data);
    }
  }
  /**
   * Logs an info message.
   *
   * @param data - The data to log.
   */
  static info(...data) {
    if (_Log.level >= 2 /* INFO */) {
      console.log(...data);
    }
  }
  /**
   * Logs a debug message.
   *
   * @param data - The data to log.
   */
  static debug(...data) {
    if (_Log.level >= 3 /* DEBUG */) {
      console.debug(...data);
    }
  }
  /**
   * Starts a log message group.
   */
  static group() {
    console.group();
  }
  /**
   * Finishes the current log message group.
   */
  static groupEnd() {
    console.groupEnd();
  }
  /**
   * Logs a debug message.
   */
  static trace(data) {
    console.trace(data);
  }
};

// src/utils/Resolution.ts
import { EventDispatcher as EventDispatcher4, Vector2 } from "three";
var AUTO_SIZE = -1;
var Resolution = class _Resolution extends EventDispatcher4 {
  /**
   * Triggers when the resolution is changed.
   *
   * @event
   */
  static EVENT_CHANGE = "change";
  /**
   * An auto sizing constant.
   *
   * Can be used to automatically calculate the width or height based on the original aspect ratio.
   */
  static AUTO_SIZE = AUTO_SIZE;
  /**
   * The base resolution.
  */
  baseSize;
  /**
   * The preferred resolution.
   */
  preferredSize;
  /**
   * The effective resolution.
   */
  effectiveSize;
  /**
   * @see {@link scale}
   */
  _scale;
  /**
   * Constructs a new resolution.
   *
   * @param width - The preferred width.
   * @param height - The preferred height.
   * @param scale - A resolution scale.
   */
  constructor(width = AUTO_SIZE, height = AUTO_SIZE, scale = 1) {
    super();
    this.baseSize = new Vector2(1, 1);
    this.preferredSize = new Vector2(width, height);
    this.effectiveSize = new Vector2();
    this._scale = scale;
    this.addEventListener(_Resolution.EVENT_CHANGE, () => this.updateEffectiveSize());
    this.updateEffectiveSize();
  }
  /**
   * Calculates the effective size.
   */
  updateEffectiveSize() {
    const base = this.baseSize;
    const preferred = this.preferredSize;
    const effective = this.effectiveSize;
    effective.copy(base);
    if (preferred.width !== AUTO_SIZE) {
      effective.width = preferred.width;
    } else if (preferred.height !== AUTO_SIZE) {
      effective.width = Math.round(preferred.height * (base.width / Math.max(base.height, 1)));
    }
    if (preferred.height !== AUTO_SIZE) {
      effective.height = preferred.height;
    } else if (preferred.width !== AUTO_SIZE) {
      effective.height = Math.round(preferred.width / Math.max(base.width / Math.max(base.height, 1), 1));
    }
    effective.multiplyScalar(this.scale).round();
  }
  /**
   * The effective width, calculated based on the preferred size and resolution scale.
   */
  get width() {
    return this.effectiveSize.width;
  }
  /**
   * The effective height, calculated based on the preferred size and resolution scale.
   */
  get height() {
    return this.effectiveSize.height;
  }
  /**
   * The resolution scale.
   */
  get scale() {
    return this._scale;
  }
  set scale(value) {
    if (this._scale !== value) {
      this._scale = value;
      this.preferredSize.setScalar(AUTO_SIZE);
      this.setChanged();
    }
  }
  /**
   * The base width.
   */
  get baseWidth() {
    return this.baseSize.width;
  }
  set baseWidth(value) {
    if (this.baseSize.width !== value) {
      this.baseSize.width = value;
      this.setChanged();
    }
  }
  /**
   * The base height.
   */
  get baseHeight() {
    return this.baseSize.height;
  }
  set baseHeight(value) {
    if (this.baseSize.height !== value) {
      this.baseSize.height = value;
      this.setChanged();
    }
  }
  /**
   * Sets the base size.
   *
   * @param width - The width.
   * @param height - The height.
   */
  setBaseSize(width, height) {
    if (this.baseSize.width !== width || this.baseSize.height !== height) {
      this.baseSize.set(width, height);
      this.setChanged();
    }
  }
  /**
   * The preferred width.
   */
  get preferredWidth() {
    return this.preferredSize.width;
  }
  set preferredWidth(value) {
    if (this.preferredSize.width !== value) {
      this.preferredSize.width = value;
      this.setChanged();
    }
  }
  /**
   * The preferred height.
   */
  get preferredHeight() {
    return this.preferredSize.height;
  }
  set preferredHeight(value) {
    if (this.preferredSize.height !== value) {
      this.preferredSize.height = value;
      this.setChanged();
    }
  }
  /**
   * Sets the preferred size.
   *
   * @param width - The width.
   * @param height - The height.
   */
  setPreferredSize(width, height) {
    if (this.preferredSize.width !== width || this.preferredSize.height !== height) {
      this.preferredSize.set(width, height);
      this.setChanged();
    }
  }
  /**
   * Copies the given resolution.
   *
   * @param resolution - The resolution.
   */
  copy(resolution) {
    this._scale = resolution.scale;
    this.baseSize.set(resolution.baseWidth, resolution.baseHeight);
    this.preferredSize.set(resolution.preferredWidth, resolution.preferredHeight);
    this.setChanged();
  }
  /**
   * Dispatches a `change` event.
   */
  setChanged() {
    this.dispatchEvent({ type: _Resolution.EVENT_CHANGE });
  }
};

// src/core/Output.ts
import { EventDispatcher as EventDispatcher5 } from "three";
var Output = class _Output extends EventDispatcher5 {
  /**
   * Triggers when an output resource is added, replaced or removed.
   *
   * @event
   */
  static EVENT_CHANGE = "change";
  /**
   * Identifies the default output buffer in the {@link renderTargets} collection.
   */
  static BUFFER_DEFAULT = "BUFFER_DEFAULT";
  defines;
  uniforms;
  /**
   * Output render targets.
   */
  renderTargets;
  /**
   * Constructs new output resources.
   */
  constructor() {
    super();
    const defines = new ObservableMap();
    const uniforms = new ObservableMap();
    const renderTargets = new ObservableMap();
    defines.addEventListener(ObservableMap.EVENT_CHANGE, (e) => this.dispatchEvent(e));
    uniforms.addEventListener(ObservableMap.EVENT_CHANGE, (e) => this.dispatchEvent(e));
    renderTargets.addEventListener(ObservableMap.EVENT_CHANGE, (e) => this.dispatchEvent(e));
    this.defines = defines;
    this.uniforms = uniforms;
    this.renderTargets = renderTargets;
  }
  /**
   * Alias for {@link renderTargets}.
   */
  get buffers() {
    return this.renderTargets;
  }
  /**
   * The default output buffer.
   */
  get defaultBuffer() {
    return this.renderTargets.get(_Output.BUFFER_DEFAULT) || null;
  }
  set defaultBuffer(value) {
    this.renderTargets.set(_Output.BUFFER_DEFAULT, value);
  }
};

// src/core/Pass.ts
var Pass = class _Pass extends EventDispatcher6 {
  /**
   * Triggers when this pass has changed and requires a full update.
   *
   * @event
   */
  static EVENT_CHANGE = "change";
  /**
   * A shared fullscreen triangle.
   *
   * The screen size is 2x2 units (NDC). A triangle needs to be 4x4 units to fill the screen.
   * @see https://michaldrobot.com/2014/04/01/gcn-execution-patterns-in-full-screen-passes/
   */
  static fullscreenGeometry = /* @__PURE__ */ (() => {
    const vertices = new Float32Array([-1, -1, 0, 3, -1, 0, -1, 3, 0]);
    const geometry = new BufferGeometry();
    geometry.setAttribute("position", new BufferAttribute(vertices, 3));
    return geometry;
  })();
  /**
   * A scene that contains the fullscreen mesh.
   */
  fullscreenScene;
  /**
   * A fullscreen camera.
   */
  fullscreenCamera;
  /**
   * A fullscreen mesh.
   */
  screen;
  // #region Backing Data
  /**
   * @see {@link Pass.prototype.name}
   */
  _name;
  /**
   * @see {@link renderer}
   */
  _renderer;
  /**
   * @see {@link timer}
   */
  _timer;
  /**
   * @see {@link scene}
   */
  _scene;
  /**
   * @see {@link camera}
   */
  _camera;
  /**
   * @see {@link subpasses}
   */
  _subpasses;
  // #endregion
  /**
   * A collection of objects that will be disposed when this pass is disposed.
   *
   * IO resources will be disposed separately.
   */
  disposables;
  /**
   * The current resolution.
   */
  resolution;
  /**
   * The input resources of this pass.
   */
  input;
  /**
   * The output resources of this pass.
   */
  output;
  /**
   * Indicates whether this pass is enabled.
   */
  enabled;
  /**
   * Constructs a new pass.
   *
   * @param name - A name that will be used for debugging purposes. Doesn't have to be unique.
   */
  constructor(name) {
    super();
    this.fullscreenScene = null;
    this.fullscreenCamera = null;
    this.screen = null;
    this._name = name;
    this._renderer = null;
    this._timer = null;
    this._scene = null;
    this._camera = null;
    this.disposables = /* @__PURE__ */ new Set();
    this.resolution = new Resolution();
    this.resolution.addEventListener(Resolution.EVENT_CHANGE, () => this.updateOutputBufferSize(this.resolution));
    this.resolution.addEventListener(Resolution.EVENT_CHANGE, () => this.onResolutionChange(this.resolution));
    this.input = new Input();
    this.output = new Output();
    this.input.addEventListener(Input.EVENT_CHANGE, () => this.updateFullscreenMaterial());
    this.input.addEventListener(Input.EVENT_CHANGE, () => this.onInputChange());
    this.output.addEventListener(Output.EVENT_CHANGE, () => this.onOutputChange());
    this._subpasses = [];
    this.enabled = true;
  }
  /**
   * The name of this pass.
   */
  get name() {
    return this._name;
  }
  set name(value) {
    this._name = value;
  }
  /**
   * A list of subpasses.
   *
   * Subpasses are subject to automatic resource optimizations.
   */
  get subpasses() {
    return this._subpasses;
  }
  set subpasses(value) {
    this._subpasses = value;
  }
  /**
   * A timer.
   */
  get timer() {
    return this._timer;
  }
  set timer(value) {
    this._timer = value;
    for (const pass of this.subpasses) {
      pass.timer = value;
    }
  }
  /**
   * The current renderer.
   */
  get renderer() {
    return this._renderer;
  }
  set renderer(value) {
    this._renderer = value;
    try {
      if (value !== null && value.capabilities !== void 0) {
        this.checkRequirements(value);
      }
    } catch (e) {
      Log.warn(e);
      Log.info("Disabling pass:", this);
      this.enabled = false;
    }
    for (const pass of this.subpasses) {
      pass.renderer = value;
    }
  }
  /**
   * The main scene.
   */
  get scene() {
    return this._scene;
  }
  set scene(value) {
    this._scene = value;
    for (const pass of this.subpasses) {
      pass.scene = value;
    }
  }
  /**
   * The main camera.
   */
  get camera() {
    return this._camera;
  }
  set camera(value) {
    this._camera = value;
    for (const pass of this.subpasses) {
      pass.camera = value;
    }
  }
  /**
   * The current fullscreen material.
   */
  get fullscreenMaterial() {
    return this.screen?.material;
  }
  set fullscreenMaterial(value) {
    if (this.screen !== null) {
      this.screen.material = value;
    } else {
      this.screen = new Mesh(_Pass.fullscreenGeometry, value);
      this.screen.frustumCulled = false;
      this.fullscreenScene = new Scene();
      this.fullscreenCamera = new OrthographicCamera2(-1, 1, 1, -1, 0, 1);
      this.fullscreenScene.add(this.screen);
    }
  }
  /**
   * Updates the size of the default output buffer, if it exists.
   */
  updateOutputBufferSize(resolution) {
    this.output.defaultBuffer?.setSize(resolution.width, resolution.height);
  }
  /**
   * Updates the shader input data of the fullscreen material, if it exists.
   */
  updateFullscreenMaterial() {
    const fullscreenMaterial = this.fullscreenMaterial;
    if (!(fullscreenMaterial instanceof RawShaderMaterial2 || fullscreenMaterial instanceof ShaderMaterial)) {
      return;
    }
    if (fullscreenMaterial instanceof FullscreenMaterial) {
      fullscreenMaterial.inputBuffer = this.input.defaultBuffer;
    }
    if (this.input.frameBufferPrecisionHigh) {
      fullscreenMaterial.defines.FRAME_BUFFER_PRECISION_HIGH = true;
    } else {
      delete fullscreenMaterial.defines.FRAME_BUFFER_PRECISION_HIGH;
    }
    for (const entry of this.input.defines) {
      fullscreenMaterial.defines[entry[0]] = entry[1];
    }
    for (const entry of this.input.uniforms) {
      fullscreenMaterial.uniforms[entry[0]] = entry[1];
    }
    fullscreenMaterial.needsUpdate = true;
  }
  /**
   * Checks if his pass uses convolution shaders.
   *
   * Only works on passes that use `FullscreenMaterial`.
   *
   * @param recursive - Controls whether subpasses should be checked recursively.
   * @return True if the pass uses convolution shaders.
   */
  isConvolutionPass(recursive) {
    const material = this.fullscreenMaterial;
    if (material instanceof FullscreenMaterial && /texture\s*\(\s*inputBuffer/.test(material.fragmentShader)) {
      return true;
    }
    if (recursive) {
      for (const subpass of this.subpasses) {
        if (subpass.isConvolutionPass(recursive)) {
          return true;
        }
      }
    }
    return false;
  }
  /**
   * Checks if the current renderer supports all features that are required by this pass.
   *
   * Override this method to check if the current device supports the necessary features.
   * This method should throw an error if the requirements are not met.
   *
   * @param renderer - The current renderer.
   * @throws If the device doesn't meet the requirements.
   */
  checkRequirements(renderer) {
  }
  /**
   * Performs tasks when the input resources have changed.
   *
   * Override this method to handle input changes.
   */
  onInputChange() {
  }
  /**
   * Performs tasks when the output resources have changed.
   *
   * Override this method to handle output changes.
   */
  onOutputChange() {
  }
  /**
   * Performs tasks when the resolution has changed.
   *
   * Override this method to handle resolution changes.
   *
   * @param resolution - The updated resolution of this pass.
   */
  onResolutionChange(resolution) {
  }
  /**
   * Creates a framebuffer.
   *
   * @return The framebuffer.
   */
  createFramebuffer() {
    const { width, height } = this.resolution;
    return new WebGLRenderTarget2(width, height, { depthBuffer: false });
  }
  /**
   * Dispatches a `change` event.
   */
  setChanged() {
    this.dispatchEvent({ type: _Pass.EVENT_CHANGE });
  }
  /**
   * Renders the fullscreen material to the current render target.
   */
  renderFullscreen() {
    if (this.renderer !== null && this.fullscreenMaterial !== null) {
      this.renderer.render(this.fullscreenScene, this.fullscreenCamera);
    }
  }
  dispose() {
    for (const disposable of this.disposables) {
      disposable.dispose();
    }
    for (const pass of this.subpasses) {
      pass.dispose();
    }
    this.fullscreenMaterial?.dispose();
  }
};

// src/utils/ClearFlags.ts
var ClearFlags = class {
  /**
   * A collection of GBuffer components that should be cleared.
   */
  gBufferComponents;
  /**
   * Indicates whether the depth buffer should be cleared.
   */
  depth;
  /**
   * Indicates whether the stencil buffer should be cleared.
   */
  stencil;
  /**
   * Constructs new clear flags.
   *
   * @param color - The color clear flag.
   * @param depth - The depth clear flag.
   * @param stencil - The stencil clear flag.
   */
  constructor(color2 = true, depth = true, stencil = true) {
    const gBufferComponents = /* @__PURE__ */ new Set();
    gBufferComponents.add("GBUFFER_NORMAL" /* NORMAL */);
    gBufferComponents.add("GBUFFER_METALNESS" /* METALNESS */);
    gBufferComponents.add("GBUFFER_ROUGHNESS" /* ROUGHNESS */);
    this.gBufferComponents = gBufferComponents;
    this.color = color2;
    this.depth = depth;
    this.stencil = stencil;
  }
  /**
   * Indicates whether the color buffer should be cleared.
   *
   * Alias for the {@link gBufferComponents} entry {@link GBuffer.COLOR}.
   */
  get color() {
    return this.gBufferComponents.has("GBUFFER_COLOR" /* COLOR */);
  }
  set color(value) {
    if (value) {
      this.gBufferComponents.add("GBUFFER_COLOR" /* COLOR */);
    } else {
      this.gBufferComponents.delete("GBUFFER_COLOR" /* COLOR */);
    }
  }
};

// src/utils/ClearValues.ts
import { Vector3 as Vector32 } from "three";
var ClearValues = class {
  /**
   * A clear color that overrides the clear color of the renderer. Default is `null`, meaning disabled.
   */
  color;
  /**
   * A clear alpha value that overrides the clear alpha of the renderer. Default is `null`, meaning disabled.
   */
  alpha;
  /**
   * The clear value for the normal buffer.
   */
  normal;
  /**
   * The clear value for roughness.
   */
  roughness;
  /**
   * The clear value for metalness.
   */
  metalness;
  /**
   * Constructs new clear values.
   */
  constructor() {
    this.color = null;
    this.alpha = null;
    this.normal = new Vector32(0.5, 0.5, 1);
    this.roughness = 0;
    this.metalness = 0;
  }
};

// src/passes/ClearPass.ts
var color = /* @__PURE__ */ new Color2();
var fv = /* @__PURE__ */ new Float32Array(4);
var ClearPass = class extends Pass {
  /**
   * The clear flags.
   */
  clearFlags;
  /**
   * The clear values.
   */
  clearValues;
  /**
   * Constructs a new clear pass.
   *
   * @param color - The color clear flag.
   * @param depth - The depth clear flag.
   * @param stencil - The stencil clear flag.
   */
  constructor(color2 = true, depth = true, stencil = true) {
    super("ClearPass");
    this.clearFlags = new ClearFlags(color2, depth, stencil);
    this.clearValues = new ClearValues();
  }
  /**
   * The current GBuffer component indices.
   */
  get gBufferIndices() {
    return this.output.defines;
  }
  /**
   * Clears GBuffer components.
   *
   * @see https://www.khronos.org/opengl/wiki/Framebuffer#Buffer_clearing
   * @see https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/clearBuffer
   */
  clearGBuffer() {
    const renderer = this.renderer;
    const gl = renderer.getContext();
    const flags = this.clearFlags;
    const values = this.clearValues;
    if (flags.gBufferComponents.has("GBUFFER_NORMAL" /* NORMAL */) && this.gBufferIndices.has("GBUFFER_NORMAL" /* NORMAL */)) {
      const clearNormal = values.normal;
      const index = this.gBufferIndices.get("GBUFFER_NORMAL" /* NORMAL */);
      fv[0] = clearNormal.x;
      fv[1] = clearNormal.y;
      fv[2] = clearNormal.z;
      fv[3] = 1;
      gl.clearBufferfv(gl.COLOR, index, fv);
    }
    if ((flags.gBufferComponents.has("GBUFFER_ROUGHNESS" /* ROUGHNESS */) || flags.gBufferComponents.has("GBUFFER_METALNESS" /* METALNESS */)) && (this.gBufferIndices.has("GBUFFER_ROUGHNESS" /* ROUGHNESS */) || this.gBufferIndices.has("GBUFFER_METALNESS" /* METALNESS */))) {
      const clearRoughness = values.roughness;
      const clearMetalness = values.metalness;
      const index = this.gBufferIndices.get("GBUFFER_ROUGHNESS" /* ROUGHNESS */);
      fv[0] = clearRoughness;
      fv[1] = clearMetalness;
      fv[2] = 0;
      fv[3] = 1;
      gl.clearBufferfv(gl.COLOR, index, fv);
    }
  }
  render() {
    const renderer = this.renderer;
    if (renderer === null) {
      return;
    }
    const values = this.clearValues;
    const overrideClearColor = values.color;
    const overrideClearAlpha = values.alpha;
    const hasOverrideClearColor = overrideClearColor !== null;
    const hasOverrideClearAlpha = overrideClearAlpha !== null;
    const clearAlpha = renderer.getClearAlpha();
    const flags = this.clearFlags;
    if (hasOverrideClearColor) {
      renderer.getClearColor(color);
      renderer.setClearColor(overrideClearColor);
    }
    if (hasOverrideClearAlpha) {
      renderer.setClearAlpha(overrideClearAlpha);
    }
    renderer.setRenderTarget(this.output.defaultBuffer);
    renderer.clear(flags.color, flags.depth, flags.stencil);
    if (this.output.defaultBuffer instanceof WebGLMultipleRenderTargets2) {
      this.clearGBuffer();
    }
    if (hasOverrideClearColor) {
      renderer.setClearColor(color, clearAlpha);
    } else if (hasOverrideClearAlpha) {
      renderer.setClearAlpha(clearAlpha);
    }
  }
};

// src/passes/GeometryPass.ts
import {
  DepthFormat,
  DepthStencilFormat,
  DepthTexture,
  HalfFloatType,
  LinearFilter,
  Mesh as Mesh2,
  NearestFilter,
  RGBAFormat,
  RGFormat,
  SRGBColorSpace as SRGBColorSpace2,
  UnsignedByteType as UnsignedByteType3,
  WebGLMultipleRenderTargets as WebGLMultipleRenderTargets3
} from "three";

// src/utils/Selection.ts
var Selection = class _Selection extends Set {
  /**
   * The next layer ID.
   */
  static nextId = 2;
  /**
   * @see {@link layer}
   */
  _layer;
  /**
   * Indicates whether this selection is enabled.
   */
  enabled;
  /**
   * Controls whether objects that are added to this selection should be removed from all other layers.
   */
  exclusive;
  /**
   * Constructs a new selection.
   *
   * @param iterable - A collection of objects that should be added to this selection.
   * @param layer - A dedicated render layer for selected objects. Range is `[2, 31]`. Starts at 2 if omitted.
   */
  constructor(iterable, layer) {
    super();
    if (layer === void 0) {
      if (_Selection.nextId > 31) {
        Log.warn("Layer ID exceeded 31, resetting to 2");
        _Selection.nextId = 2;
      }
      this._layer = _Selection.nextId++;
    } else {
      this._layer = layer;
    }
    this.enabled = true;
    this.exclusive = false;
    if (iterable !== void 0) {
      this.set(iterable);
    }
  }
  /**
   * The render layer for selected objects.
   */
  get layer() {
    return this._layer;
  }
  set layer(value) {
    const currentLayer = this._layer;
    for (const object of this) {
      object.layers.disable(currentLayer);
      object.layers.enable(value);
    }
    this._layer = value;
  }
  /**
   * Clears this selection.
   */
  clear() {
    const layer = this.layer;
    for (const object of this) {
      object.layers.disable(layer);
    }
    return super.clear();
  }
  /**
   * Adds an object to this selection.
   *
   * If {@link exclusive} is set to `true`, the object will also be removed from all other layers.
   *
   * @param object - The object that should be selected.
   * @return This selection.
   */
  add(object) {
    if (this.exclusive) {
      object.layers.set(this.layer);
    } else {
      object.layers.enable(this.layer);
    }
    return super.add(object);
  }
  /**
   * Removes an object from this selection.
   *
   * @param object - The object that should be deselected.
   * @return Returns true if an object has successfully been removed from this selection; otherwise false.
   */
  delete(object) {
    if (this.has(object)) {
      object.layers.disable(this.layer);
    }
    return super.delete(object);
  }
  /**
   * Clears this selection and adds the given objects.
   *
   * @param objects - The objects that should be selected.
   * @return This selection.
   */
  set(objects) {
    this.clear();
    for (const object of objects) {
      this.add(object);
    }
    return this;
  }
  /**
   * Removes an existing object from the selection. If the object doesn't exist it's added instead.
   *
   * @param object - The object.
   * @return Returns true if the object is added, false otherwise.
   */
  toggle(object) {
    let result;
    if (this.has(object)) {
      this.delete(object);
      result = false;
    } else {
      this.add(object);
      result = true;
    }
    return result;
  }
  /**
   * Sets the visibility of all selected objects.
   *
   * This method enables or disables render layer 0 of all selected objects.
   *
   * @param visible - Whether the selected objects should be visible.
   * @return This selection.
   */
  setVisible(visible) {
    for (const object of this) {
      if (visible) {
        object.layers.enable(0);
      } else {
        object.layers.disable(0);
      }
    }
    return this;
  }
};

// src/materials/shaders/copy.frag
var copy_default = "#include <pp_precision_fragment>\n#include <pp_gbuffer_output_pars_fragment>\n#include <pp_colorspace_pars_fragment>\n#include <pp_input_buffer_pars_fragment>\n#include <common>\n#include <colorspace_pars_fragment>\n#include <dithering_pars_fragment>\nin vec2 vUv;void main(){outputColor=texture(inputBuffer,vUv);\n#ifdef COLOR_SPACE_CONVERSION\n#include <colorspace_fragment>\n#endif\n#include <dithering_fragment>\n}";

// src/materials/shaders/common.vert
var common_default = "in vec3 position;out vec2 vUv;void main(){vUv=position.xy*0.5+0.5;gl_Position=vec4(position.xy,1.0,1.0);}";

// src/materials/CopyMaterial.ts
var CopyMaterial = class extends FullscreenMaterial {
  /**
   * Constructs a new copy material.
   */
  constructor() {
    super({
      name: "CopyMaterial",
      fragmentShader: copy_default,
      vertexShader: common_default,
      defines: {
        COLOR_SPACE_CONVERSION: true
      }
    });
  }
  /**
   * Indicates whether output color space conversion is enabled.
   */
  get colorSpaceConversion() {
    return this.defines.COLOR_SPACE_CONVERSION !== void 0;
  }
  set colorSpaceConversion(value) {
    if (this.colorSpaceConversion !== value) {
      if (value) {
        this.defines.COLOR_SPACE_CONVERSION = true;
      } else {
        delete this.defines.COLOR_SPACE_CONVERSION;
      }
      this.needsUpdate = true;
    }
  }
};

// src/passes/CopyPass.ts
var CopyPass = class extends Pass {
  /**
   * Constructs a new copy pass.
   *
   * @param outputBuffer - An output buffer. If not provided, a new framebuffer will be created.
   */
  constructor(outputBuffer) {
    super("CopyPass");
    this.output.defaultBuffer = outputBuffer || this.createFramebuffer();
    this.fullscreenMaterial = new CopyMaterial();
  }
  render() {
    this.renderer?.setRenderTarget(this.output.defaultBuffer);
    this.renderFullscreen();
  }
};

// src/passes/GeometryPass.ts
var GeometryPass = class extends Pass {
  selection;
  /**
   * A collection of materials that have been modified with `onBeforeCompile`.
   */
  registeredMaterials;
  /**
   * A copy pass that is used to blit the default input buffer to the output color buffer.
   */
  copyPass;
  /**
   * Controls which gBuffer components should be rendered by this pass.
   *
   * This will be automatically configured based on the requirements of other passes in the same pipeline.
   */
  gBufferComponents;
  // #region Settings
  /**
   * Indicates whether the scene background should be ignored.
   */
  ignoreBackground;
  /**
   * Indicates whether the shadow map auto update should be skipped.
   */
  skipShadowMapUpdate;
  /**
   * Indicates whether a stencil buffer should be created.
   */
  stencilBuffer;
  /**
   * Indicates whether a depth buffer should be created.
   */
  depthBuffer;
  /**
   * The texture data type of the primary color buffer.
   */
  frameBufferType;
  /**
   * @see {@link samples}
   */
  _samples;
  // #endregion
  /**
   * Constructs a new geometry pass.
   *
   * @param scene - A scene.
   * @param camera - A camera.
   * @param options - Additional options.
   */
  constructor(scene, camera, {
    stencilBuffer = false,
    depthBuffer = true,
    frameBufferType = UnsignedByteType3,
    samples = 0
  } = {}) {
    super("GeometryPass");
    this.scene = scene;
    this.camera = camera;
    this.ignoreBackground = false;
    this.skipShadowMapUpdate = false;
    this.stencilBuffer = stencilBuffer;
    this.depthBuffer = depthBuffer;
    this.frameBufferType = frameBufferType;
    this._samples = samples;
    this.selection = new Selection();
    this.selection.enabled = false;
    this.registeredMaterials = /* @__PURE__ */ new WeakSet();
    this.copyPass = new CopyPass();
    const gBufferComponents = new ObservableSet();
    gBufferComponents.addEventListener(ObservableSet.EVENT_CHANGE, () => this.updateGBuffer());
    this.gBufferComponents = gBufferComponents;
    this.updateGBuffer();
    this.updateMaterials();
  }
  get renderer() {
    return super.renderer;
  }
  set renderer(value) {
    super.renderer = value;
    this.updateOutputBufferColorSpace();
  }
  onInputChange() {
    this.copyPass.input.defaultBuffer = this.input.defaultBuffer;
  }
  /**
   * Sets the amount of MSAA samples.
   */
  get samples() {
    return this._samples;
  }
  set samples(value) {
    this._samples = value;
    if (this.output.defaultBuffer !== null) {
      this.output.defaultBuffer.samples = value;
    }
  }
  /**
   * Alias for `output.defaultBuffer`.
   */
  get gBuffer() {
    return this.output.defaultBuffer;
  }
  /**
   * The GBuffer component indices.
   */
  get gBufferIndices() {
    return this.output.defines;
  }
  /**
   * Enables rendering to GBuffer components for a given material.
   *
   * @param material - The material.
   */
  updateMaterial(material) {
    if (this.registeredMaterials.has(material)) {
      return;
    }
    this.registeredMaterials.add(material);
    const onBeforeCompile = material.onBeforeCompile.bind(this);
    material.onBeforeCompile = (shader, renderer) => {
      onBeforeCompile(shader, renderer);
      if (shader.defines === void 0 || shader.defines === null) {
        shader.defines = {};
      }
      for (const entry of this.gBufferIndices) {
        shader.defines[entry[0]] = entry[1];
      }
      shader.fragmentShader = shader.fragmentShader.replace(
        /(void main)/,
        "#include <pp_gbuffer_output_pars_fragment>\n\n$1"
      );
    };
  }
  /**
   * Enables rendering to GBuffer components for all materials in a given scene.
   *
   * Should be called when a mesh or material is added, removed or replaced at runtime.
   *
   * @param scene - The scene, or a subset of a scene.
   */
  updateMaterials(scene = this.scene) {
    scene?.traverse((node) => {
      const mesh = node instanceof Mesh2 ? node : null;
      if (mesh === null) {
        return;
      }
      for (const material of Array.isArray(mesh.material) ? mesh.material : [mesh.material]) {
        this.updateMaterial(material);
      }
    });
  }
  /**
   * Updates the color space of the output color texture.
   */
  updateOutputBufferColorSpace() {
    if (!this.gBufferComponents.has("GBUFFER_COLOR" /* COLOR */)) {
      return;
    }
    const renderTarget = this.output.defaultBuffer;
    const index = this.gBufferIndices.get("GBUFFER_COLOR" /* COLOR */);
    if (this.frameBufferType === UnsignedByteType3 && this.renderer?.outputColorSpace === SRGBColorSpace2) {
      renderTarget.texture[index].colorSpace = SRGBColorSpace2;
    }
  }
  /**
   * Updates the GBuffer configuration.
   */
  updateGBuffer() {
    const gBufferComponents = this.gBufferComponents;
    const gBufferIndices = this.gBufferIndices;
    this.output.defaultBuffer?.dispose();
    gBufferIndices.clear();
    if (gBufferComponents.size === 0) {
      this.output.defaultBuffer = null;
      return;
    }
    const exclusions = /* @__PURE__ */ new Set(["GBUFFER_DEPTH" /* DEPTH */, "GBUFFER_METALNESS" /* METALNESS */]);
    const textureCount = Array.from(gBufferComponents).filter((x) => !exclusions.has(x)).length;
    const renderTarget = new WebGLMultipleRenderTargets3(1, 1, textureCount, {
      stencilBuffer: this.stencilBuffer,
      depthBuffer: this.depthBuffer,
      samples: this.samples
    });
    const textures = renderTarget.texture;
    let index = 0;
    if (gBufferComponents.has("GBUFFER_COLOR" /* COLOR */)) {
      textures[index].name = "GBUFFER_COLOR" /* COLOR */;
      textures[index].minFilter = LinearFilter;
      textures[index].magFilter = LinearFilter;
      textures[index].type = this.frameBufferType;
      textures[index].format = RGBAFormat;
      gBufferIndices.set("GBUFFER_COLOR" /* COLOR */, index++);
    }
    if (gBufferComponents.has("GBUFFER_NORMAL" /* NORMAL */)) {
      textures[index].name = "GBUFFER_NORMAL" /* NORMAL */;
      textures[index].minFilter = NearestFilter;
      textures[index].magFilter = NearestFilter;
      textures[index].type = HalfFloatType;
      textures[index].format = RGBAFormat;
      gBufferIndices.set("GBUFFER_NORMAL" /* NORMAL */, index++);
    }
    if (gBufferComponents.has("GBUFFER_ROUGHNESS" /* ROUGHNESS */)) {
      textures[index].name = "GBUFFER_ROUGHNESS" /* ROUGHNESS */;
      textures[index].minFilter = LinearFilter;
      textures[index].magFilter = LinearFilter;
      textures[index].type = UnsignedByteType3;
      textures[index].format = RGFormat;
      gBufferIndices.set("GBUFFER_ROUGHNESS" /* ROUGHNESS */, index++);
    }
    if (gBufferComponents.has("GBUFFER_METALNESS" /* METALNESS */)) {
      gBufferIndices.set("GBUFFER_METALNESS" /* METALNESS */, gBufferIndices.get("GBUFFER_ROUGHNESS" /* ROUGHNESS */));
    }
    if (gBufferComponents.has("GBUFFER_DEPTH" /* DEPTH */)) {
      const depthTexture = new DepthTexture(1, 1);
      depthTexture.format = this.stencilBuffer ? DepthStencilFormat : DepthFormat;
      renderTarget.depthTexture = depthTexture;
    }
    this.copyPass.output.defaultBuffer = renderTarget;
    this.output.defaultBuffer = renderTarget;
    this.onResolutionChange(this.resolution);
    this.updateOutputBufferColorSpace();
  }
  render() {
    if (this.renderer === null || this.scene === null || this.camera === null) {
      return;
    }
    const selection = this.selection;
    const mask = this.camera.layers.mask;
    const background = this.scene.background;
    const shadowMapAutoUpdate = this.renderer.shadowMap.autoUpdate;
    if (this.selection.enabled) {
      this.camera.layers.set(selection.layer);
    }
    if (this.skipShadowMapUpdate) {
      this.renderer.shadowMap.autoUpdate = false;
    }
    if (this.ignoreBackground) {
      this.scene.background = null;
    }
    if (this.input.defaultBuffer !== null) {
      this.copyPass.render();
    }
    this.renderer.setRenderTarget(this.output.defaultBuffer);
    this.renderer.render(this.scene, this.camera);
    this.camera.layers.mask = mask;
    this.scene.background = background;
    this.renderer.shadowMap.autoUpdate = shadowMapAutoUpdate;
  }
};

// src/core/IOManager.ts
var IOManager = class _IOManager {
  /**
   * A collection of active render pipelines.
   */
  pipelines;
  /**
   * A collection of active render pipelines.
   */
  outputDefaultBuffers;
  /**
   * Constructs a new I/O manager.
   */
  constructor() {
    this.pipelines = /* @__PURE__ */ new Set();
    this.outputDefaultBuffers = /* @__PURE__ */ new Map();
  }
  /**
   * Updates the input and output buffers of all passes in a given pipeline.
   *
   * @param pipeline - The pipeline to update.
   */
  updatePipeline(pipeline) {
    const geoPass = _IOManager.findMainGeometryPass(pipeline);
    if (geoPass !== void 0) {
      _IOManager.gatherGBufferComponents(geoPass, pipeline);
    }
    this.updateInput(pipeline, geoPass);
    this.updateOutput(pipeline, geoPass);
    _IOManager.syncDefaultBufferType(pipeline);
  }
  /**
   * Updates the input buffers of all passes in a given pipeline.
   *
   * @param pipeline - The pipeline to update.
   * @param geoPass - The main geometry pass.
   */
  updateInput(pipeline, geoPass) {
    let previousOutputBuffer;
    for (let i = 0, j = -1, l = pipeline.passes.length; i < l; ++i, ++j) {
      const previousPass = j >= 0 ? pipeline.passes[j] : null;
      const pass = pipeline.passes[i];
      if (pass !== geoPass && geoPass !== void 0) {
        _IOManager.assignGBufferTextures(pass, geoPass);
        pass.scene = geoPass.scene;
        pass.camera = geoPass.camera;
      }
      if (previousPass === null || previousPass instanceof ClearPass) {
        continue;
      }
      previousPass.output.defines.forEach((value, key) => pass.input.defines.set(key, value));
      previousPass.output.uniforms.forEach((value, key) => pass.input.uniforms.set(key, value));
      previousOutputBuffer = previousPass.output.buffers.get(Output.BUFFER_DEFAULT) || previousOutputBuffer;
      if (previousOutputBuffer === null) {
        pass.input.defaultBuffer = null;
      } else if (previousOutputBuffer instanceof WebGLMultipleRenderTargets4) {
        if (geoPass !== void 0 && geoPass.gBufferIndices.has("GBUFFER_COLOR" /* COLOR */)) {
          const index = geoPass.gBufferIndices.get("GBUFFER_COLOR" /* COLOR */);
          pass.input.defaultBuffer = previousOutputBuffer.texture[index];
        }
      } else if (previousOutputBuffer !== void 0) {
        pass.input.defaultBuffer = previousOutputBuffer.texture;
      }
    }
  }
  /**
   * Updates the output buffers of all passes in a given pipeline.
   *
   * @param pipeline - The pipeline to update.
   */
  updateOutput(pipeline, geoPass) {
    const outputDefaultBuffers = this.outputDefaultBuffers;
    for (let i = 0, j = 1, l = pipeline.passes.length; i < l; ++i, ++j) {
      const pass = pipeline.passes[i];
      if (j < l && pass instanceof ClearPass) {
        const nextPass = pipeline.passes[j];
        nextPass.output.defines.forEach((value, key) => pass.output.defines.set(key, value));
        nextPass.output.uniforms.forEach((value, key) => pass.output.uniforms.set(key, value));
        pass.output.defaultBuffer = nextPass.output.defaultBuffer;
        continue;
      }
      if (pass instanceof GeometryPass && geoPass !== void 0 && pass !== geoPass && pass.output.defaultBuffer !== null && pass.output.defaultBuffer !== geoPass.output.defaultBuffer) {
        geoPass.output.defines.forEach((value, key) => pass.output.defines.set(key, value));
        geoPass.output.uniforms.forEach((value, key) => pass.output.uniforms.set(key, value));
        pass.output.defaultBuffer = geoPass.output.defaultBuffer;
      }
      if (j === l) {
        if (pipeline.autoRenderToScreen) {
          outputDefaultBuffers.set(pass.output, pass.output.defaultBuffer);
          pass.output.defaultBuffer = null;
        }
      } else if (pass.output.defaultBuffer === null && outputDefaultBuffers.has(pass.output)) {
        pass.output.defaultBuffer = outputDefaultBuffers.get(pass.output);
      }
    }
  }
  /**
   * Adds a render pipeline.
   *
   * @param pipeline - The pipeline to add.
   */
  addPipeline(pipeline) {
    this.pipelines.add(pipeline);
  }
  /**
   * Removes a render pipeline.
   *
   * @param pipeline - The pipeline to remove.
   */
  removePipeline(pipeline) {
    this.pipelines.delete(pipeline);
  }
  /**
   * Updates the input and output buffers of all pipelines.
   */
  update() {
    for (const pipeline of this.pipelines) {
      this.updatePipeline(pipeline);
    }
  }
  /**
   * Synchronizes the texture type of input/output default buffers.
   *
   * @param pipeline - The pipeline to update.
   */
  static syncDefaultBufferType(pipeline) {
    for (const pass of pipeline.passes) {
      if (pass.input.defaultBuffer === null || pass.output.defaultBuffer === null || pass.output.defaultBuffer instanceof WebGLMultipleRenderTargets4) {
        continue;
      }
      pass.output.defaultBuffer.texture.type = pass.input.defaultBuffer.type;
      if (!pass.input.frameBufferPrecisionHigh && pipeline.renderer?.outputColorSpace === SRGBColorSpace3) {
        pass.output.defaultBuffer.texture.colorSpace = SRGBColorSpace3;
      }
    }
  }
  /**
   * Returns the main geometry pass of the given pipeline.
   *
   * @param pipeline - A pipeline.
   * @return The geometry pass, or undefined if there is none.
   */
  static findMainGeometryPass(pipeline) {
    return pipeline.passes.find((x) => x instanceof GeometryPass);
  }
  /**
   * Collects all required GBuffer components for a given pipeline.
   *
   * @param geoPass - The primary geometry pass.
   * @param pipeline - The pipeline.
   */
  static gatherGBufferComponents(geoPass, pipeline) {
    geoPass.gBufferComponents.clear();
    for (const pass of pipeline.passes) {
      for (const component of pass.input.gBuffer) {
        geoPass.gBufferComponents.add(component);
      }
    }
  }
  /**
   * Assigns GBuffer components to a given pass.
   *
   * @param pass - A pass.
   * @param gBuffer - The GBuffer.
   * @param gBufferIndices - GBuffer component indices.
   */
  static assignGBufferTextures(pass, geoPass) {
    if (geoPass === void 0 || geoPass.gBuffer === null) {
      return;
    }
    for (const component of pass.input.gBuffer) {
      if (component === "GBUFFER_DEPTH" /* DEPTH */) {
        pass.input.buffers.set(component, geoPass.gBuffer.depthTexture);
      } else if (geoPass.gBufferIndices.has(component)) {
        const index = geoPass.gBufferIndices.get(component);
        pass.input.buffers.set(component, geoPass.gBuffer.texture[index]);
      }
    }
  }
};

// src/core/RenderPipeline.ts
import { Vector2 as Vector22 } from "three";
import { Timer } from "three/addons/misc/Timer.js";

// src/shader-chunks/ShaderChunkExtensions.ts
import { ShaderChunk } from "three";

// src/shader-chunks/shaders/camera-pars.frag
var camera_pars_default = "uniform mat4 projectionMatrix;uniform mat4 projectionMatrixInverse;uniform vec3 cameraParams;";

// src/shader-chunks/shaders/colorspace-pars.frag
var colorspace_pars_default = "#if OUTPUT_COLOR_SPACE == 1\n#define linearToOutputTexel(texel) sRGBTransferOETF(texel)\n#else\n#define linearToOutputTexel(texel) texel\n#endif\n";

// src/shader-chunks/shaders/colorspace-conversion-pars.frag
var colorspace_conversion_pars_default = "vec4 sRGBToLinear(const in vec4 value){return vec4(mix(pow(value.rgb*0.9478672986+vec3(0.0521327014),vec3(2.4)),value.rgb*0.0773993808,vec3(lessThanEqual(value.rgb,vec3(0.04045)))),value.a);}vec3 RGBToHCV(const in vec3 RGB){vec4 P=mix(vec4(RGB.bg,-1.0,2.0/3.0),vec4(RGB.gb,0.0,-1.0/3.0),step(RGB.b,RGB.g));vec4 Q=mix(vec4(P.xyw,RGB.r),vec4(RGB.r,P.yzx),step(P.x,RGB.r));float C=Q.x-min(Q.w,Q.y);float H=abs((Q.w-Q.y)/(6.0*C+EPSILON)+Q.z);return vec3(H,C,Q.x);}vec3 RGBToHSL(const in vec3 RGB){vec3 HCV=RGBToHCV(RGB);float L=HCV.z-HCV.y*0.5;float S=HCV.y/(1.0-abs(L*2.0-1.0)+EPSILON);return vec3(HCV.x,S,L);}vec3 HueToRGB(const in float H){float R=abs(H*6.0-3.0)-1.0;float G=2.0-abs(H*6.0-2.0);float B=2.0-abs(H*6.0-4.0);return clamp(vec3(R,G,B),0.0,1.0);}vec3 HSLToRGB(const in vec3 HSL){vec3 RGB=HueToRGB(HSL.x);float C=(1.0-abs(2.0*HSL.z-1.0))*HSL.y;return(RGB-0.5)*C+HSL.z;}";

// src/shader-chunks/shaders/default-output-pars.frag
var default_output_pars_default = "layout(location=0)out OUTPUT_COLOR_PRECISION vec4 outputColor;\n#define gl_FragColor outputColor\n";

// src/shader-chunks/shaders/depth-buffer-pars.frag
var depth_buffer_pars_default = "#ifdef GL_FRAGMENT_PRECISION_HIGH\nuniform highp sampler2D depthBuffer;\n#else\nuniform mediump sampler2D depthBuffer;\n#endif\n";

// src/shader-chunks/shaders/depth-precision-pars.frag
var depth_precision_pars_default = "#ifdef GL_FRAGMENT_PRECISION_HIGH\n#define DEPTH_PRECISION highp\n#else\n#define DEPTH_PRECISION mediump\n#endif\n";

// src/shader-chunks/shaders/depth-utils-pars.frag
var depth_utils_pars_default = "#ifdef PERSPECTIVE_CAMERA\n#define getViewZ(depth, near, far) perspectiveDepthToViewZ(depth, near, far)\n#else\n#define getViewZ(depth, near, far) orthographicDepthToViewZ(depth, near, far)\n#endif\nfloat readDepth(sampler2D depthBuffer,const in vec2 uv,const in float near,const in float far){float depth=texture(depthBuffer,uv).r;\n#ifdef LOG_DEPTH\nfloat d=pow(2.0,depth*log2(far+1.0))-1.0;float a=far/(far-near);float b=far*near/(near-far);depth=a+b/d;\n#endif\nreturn depth;}vec3 getViewPosition(const in vec2 screenPosition,const in float depth,const in float viewZ,const in mat4 projectionMatrix,const in mat4 inverseProjectionMatrix){vec4 clipPosition=vec4(vec3(screenPosition,depth)*2.0-1.0,1.0);float clipW=projectionMatrix[2][3]*viewZ+projectionMatrix[3][3];clipPosition*=clipW;return(inverseProjectionMatrix*clipPosition).xyz;}";

// src/shader-chunks/shaders/frame-buffer-precision-pars.frag
var frame_buffer_precision_pars_default = "#ifdef FRAME_BUFFER_PRECISION_HIGH\n#define FRAME_BUFFER_PRECISION mediump\n#else\n#define FRAME_BUFFER_PRECISION lowp\n#endif\n";

// src/shader-chunks/shaders/gbuffer-output-pars.frag
var gbuffer_output_pars_default = "#ifndef gl_FragColor\n#ifndef GBUFFER_COLOR\n#define GBUFFER_COLOR 0\n#endif\n#ifdef GBUFFER_COLOR\nlayout(location=GBUFFER_COLOR)out OUTPUT_COLOR_PRECISION vec4 outputColor;\n#define gl_FragColor outputColor\n#endif\n#endif\n#ifndef RENDER_TO_SCREEN\n#ifdef GBUFFER_NORMAL\nlayout(location=GBUFFER_NORMAL)out mediump vec4 outputNormal;\n#endif\n#if defined(GBUFFER_ROUGHNESS)\nlayout(location=GBUFFER_ROUGHNESS)out lowp vec2 outputRoughMetal;\n#elif defined(GBUFFER_METALNESS)\nlayout(location=GBUFFER_METALNESS)out lowp vec2 outputRoughMetal;\n#endif\n#endif\n";

// src/shader-chunks/shaders/input-buffer-pars.frag
var input_buffer_pars_default = "#ifdef FRAME_BUFFER_PRECISION_HIGH\nuniform mediump sampler2D inputBuffer;\n#else\nuniform lowp sampler2D inputBuffer;\n#endif\n";

// src/shader-chunks/shaders/precision.frag
var precision_default = "#ifdef GL_FRAGMENT_PRECISION_HIGH\nprecision highp float;\n#else\nprecision mediump float;\n#endif\n";

// src/shader-chunks/shaders/resolution-pars.frag
var resolution_pars_default = "uniform vec4 resolution;";

// src/shader-chunks/shaders/gbuffer-normal.frag
var gbuffer_normal_default = "#ifdef GBUFFER_NORMAL\noutputNormal=vec4(normal,0.0);\n#endif\n";

// src/shader-chunks/shaders/gbuffer-roughness.frag
var gbuffer_roughness_default = "#ifdef GBUFFER_ROUGHNESS\noutputRoughMetal.r=roughnessFactor;\n#endif\n";

// src/shader-chunks/shaders/gbuffer-metalness.frag
var gbuffer_metalness_default = "#ifdef GBUFFER_METALNESS\noutputRoughMetal.g=metalness;\n#endif\n";

// src/shader-chunks/ShaderChunkExtensions.ts
var ShaderChunkExtensions = class {
  /**
   * Registers custom shader chunks.
   */
  static register() {
    if (Object.hasOwn(ShaderChunk, "pp_extensions")) {
      return;
    }
    Object.defineProperties(ShaderChunk, {
      "pp_extensions": { value: null },
      // Serves as a registration indicator.
      "pp_camera_pars_fragment": { value: camera_pars_default },
      "pp_colorspace_pars_fragment": { value: colorspace_pars_default },
      "pp_colorspace_conversion_pars_fragment": { value: colorspace_conversion_pars_default },
      "pp_default_output_pars_fragment": { value: default_output_pars_default },
      "pp_depth_buffer_pars_fragment": { value: depth_buffer_pars_default },
      "pp_depth_precision_pars_fragment": { value: depth_precision_pars_default },
      "pp_depth_utils_pars_fragment": { value: depth_utils_pars_default },
      "pp_frame_buffer_precision_pars_fragment": { value: frame_buffer_precision_pars_default },
      "pp_gbuffer_output_pars_fragment": { value: gbuffer_output_pars_default },
      "pp_input_buffer_pars_fragment": { value: input_buffer_pars_default },
      "pp_precision_fragment": { value: precision_default },
      "pp_resolution_pars_fragment": { value: resolution_pars_default }
    });
    ShaderChunk.normal_fragment_maps += "\n" + gbuffer_normal_default;
    ShaderChunk.roughnessmap_fragment += "\n" + gbuffer_roughness_default;
    ShaderChunk.metalnessmap_fragment += "\n" + gbuffer_metalness_default;
  }
};

// src/core/RenderPipeline.ts
var v = /* @__PURE__ */ new Vector22();
var RenderPipeline = class _RenderPipeline {
  /**
   * A shared I/O manager.
   */
  static ioManager = /* @__PURE__ */ new IOManager();
  /**
   * A timer.
   */
  _timer;
  /**
   * @see {@link passes}
   */
  _passes;
  /**
   * The current renderer.
   */
  _renderer;
  /**
   * The current resolution.
   *
   * @see {@link updateStyle}
   */
  resolution;
  /**
   * Determines whether the style of the canvas should be updated when the resolution is changed. Default is `true`.
   */
  updateStyle;
  /**
   * Determines whether the last pass should automatically render to screen. Default is `true`.
   */
  autoRenderToScreen;
  /**
   * Constructs a new render pipeline.
   *
   * @param renderer - A renderer.
   */
  constructor(renderer = null) {
    ShaderChunkExtensions.register();
    _RenderPipeline.ioManager.addPipeline(this);
    this._timer = new Timer();
    this._passes = [];
    this._renderer = null;
    this.renderer = renderer;
    this.resolution = new Resolution();
    this.resolution.addEventListener("change", () => this.onResolutionChange());
    this.updateStyle = true;
    this.autoRenderToScreen = true;
  }
  /**
   * The renderer.
   */
  get renderer() {
    return this._renderer;
  }
  set renderer(value) {
    this._renderer = value;
    for (const pass of this.passes) {
      pass.renderer = value;
    }
    if (value !== null) {
      value.autoClear = false;
      if (this.passes.length > 0) {
        this.onResolutionChange();
        _RenderPipeline.ioManager.update();
      }
    }
  }
  /**
   * The internal timer.
   */
  get timer() {
    return this._timer;
  }
  /**
   * A list of all registered passes.
   */
  get passes() {
    return this._passes;
  }
  /**
   * Registers a pass.
   *
   * @param pass - The pass.
   */
  registerPass(pass) {
    if (this.renderer !== null) {
      this.renderer.getDrawingBufferSize(v);
      pass.resolution.setBaseSize(v.width, v.height);
    }
    pass.renderer = this.renderer;
    pass.timer = this.timer;
  }
  /**
   * Unregisters a pass.
   *
   * @param pass - The pass.
   */
  unregisterPass(pass) {
    pass.renderer = null;
    pass.timer = null;
  }
  /**
   * Adds a pass.
   *
   * @param pass - The pass.
   */
  addPass(pass) {
    const passes = this._passes;
    if (passes.indexOf(pass) !== -1) {
      throw new Error(`Unable to add pass "${pass.name}" because it was already added`);
    }
    this.registerPass(pass);
    passes.push(pass);
    _RenderPipeline.ioManager.update();
  }
  /**
   * Removes a pass.
   *
   * @param pass - The pass.
   */
  removePass(pass) {
    const passes = this._passes;
    const index = passes.indexOf(pass);
    const exists = index !== -1;
    const removed = exists && passes.splice(index, 1).length > 0;
    if (removed) {
      this.unregisterPass(pass);
      _RenderPipeline.ioManager.update();
    }
  }
  /**
   * Removes all passes.
   */
  removeAllPasses() {
    for (const pass of this.passes) {
      this.unregisterPass(pass);
    }
    this._passes = [];
    _RenderPipeline.ioManager.update();
  }
  /**
   * Renders this pipeline.
   *
   * This method should be called once per frame via `requestAnimationFrame`.
   *
   * @see https://developer.mozilla.org/en-US/docs/Web/API/window/requestAnimationFrame
   * @param timestamp - The current time in milliseconds.
   */
  render(timestamp) {
    if (this.renderer === null) {
      return;
    }
    this._timer.update(
      /* timestamp */
    );
    for (const pass of this.passes) {
      if (pass.enabled) {
        pass.render();
      }
    }
  }
  /**
   * Handles resolution change events.
   *
   * @param resolution - The resolution.
   */
  onResolutionChange(resolution = this.resolution) {
    if (this.renderer === null) {
      Log.debug("Unable to update the render size because the renderer is null");
      return;
    }
    const width = resolution.width;
    const height = resolution.height;
    const logicalSize = this.renderer.getSize(v);
    if (logicalSize.width !== width || logicalSize.height !== height) {
      this.renderer.setSize(width, height, this.updateStyle);
    }
    const effectiveSize = this.renderer.getDrawingBufferSize(v);
    for (const pass of this.passes) {
      pass.resolution.setBaseSize(effectiveSize.width, effectiveSize.height);
    }
  }
  /**
   * Sets the render size.
   *
   * @param width - The width.
   * @param height - The height.
   * @param updateStyle - Whether the style of the canvas should be updated. Default is `true`.
   */
  setSize(width, height, updateStyle = true) {
    this.updateStyle = updateStyle;
    this.resolution.setBaseSize(width, height);
  }
  dispose() {
    _RenderPipeline.ioManager.removePipeline(this);
    for (const pass of this.passes) {
      pass.dispose();
    }
    this.removeAllPasses();
    this._timer.dispose();
  }
};

// src/enums/ColorChannel.ts
var ColorChannel = /* @__PURE__ */ ((ColorChannel2) => {
  ColorChannel2[ColorChannel2["RED"] = 0] = "RED";
  ColorChannel2[ColorChannel2["GREEN"] = 1] = "GREEN";
  ColorChannel2[ColorChannel2["BLUE"] = 2] = "BLUE";
  ColorChannel2[ColorChannel2["ALPHA"] = 3] = "ALPHA";
  return ColorChannel2;
})(ColorChannel || {});

// src/enums/DepthCopyMode.ts
var DepthCopyMode = /* @__PURE__ */ ((DepthCopyMode2) => {
  DepthCopyMode2[DepthCopyMode2["FULL"] = 0] = "FULL";
  DepthCopyMode2[DepthCopyMode2["SINGLE"] = 1] = "SINGLE";
  return DepthCopyMode2;
})(DepthCopyMode || {});

// src/enums/DepthTestStrategy.ts
var DepthTestStrategy = /* @__PURE__ */ ((DepthTestStrategy2) => {
  DepthTestStrategy2[DepthTestStrategy2["DEFAULT"] = 0] = "DEFAULT";
  DepthTestStrategy2[DepthTestStrategy2["KEEP_MAX_DEPTH"] = 1] = "KEEP_MAX_DEPTH";
  DepthTestStrategy2[DepthTestStrategy2["DISCARD_MAX_DEPTH"] = 2] = "DISCARD_MAX_DEPTH";
  return DepthTestStrategy2;
})(DepthTestStrategy || {});

// src/enums/EdgeDetectionMode.ts
var EdgeDetectionMode = /* @__PURE__ */ ((EdgeDetectionMode2) => {
  EdgeDetectionMode2[EdgeDetectionMode2["DEPTH"] = 0] = "DEPTH";
  EdgeDetectionMode2[EdgeDetectionMode2["LUMA"] = 1] = "LUMA";
  EdgeDetectionMode2[EdgeDetectionMode2["COLOR"] = 2] = "COLOR";
  return EdgeDetectionMode2;
})(EdgeDetectionMode || {});

// src/enums/EffectShaderSection.ts
var EffectShaderSection = /* @__PURE__ */ ((EffectShaderSection2) => {
  EffectShaderSection2["FRAGMENT_HEAD_EFFECTS"] = "$FRAGMENT_HEAD_EFFECTS";
  EffectShaderSection2["FRAGMENT_HEAD_GBUFFER"] = "$FRAGMENT_HEAD_GBUFFER";
  EffectShaderSection2["FRAGMENT_HEAD_GDATA"] = "$FRAGMENT_HEAD_GDATA";
  EffectShaderSection2["FRAGMENT_MAIN_UV"] = "$FRAGMENT_MAIN_UV";
  EffectShaderSection2["FRAGMENT_MAIN_GDATA"] = "$FRAGMENT_MAIN_GDATA";
  EffectShaderSection2["FRAGMENT_MAIN_IMAGE"] = "$FRAGMENT_MAIN_IMAGE";
  EffectShaderSection2["VERTEX_HEAD"] = "$VERTEX_HEAD";
  EffectShaderSection2["VERTEX_MAIN_SUPPORT"] = "$VERTEX_MAIN_SUPPORT";
  return EffectShaderSection2;
})(EffectShaderSection || {});

// src/enums/GData.ts
var GData = /* @__PURE__ */ ((GData2) => {
  GData2["COLOR"] = "color";
  GData2["DEPTH"] = "depth";
  GData2["NORMAL"] = "normal";
  GData2["ROUGHNESS"] = "roughness";
  GData2["METALNESS"] = "metalness";
  GData2["LUMINANCE"] = "luminance";
  return GData2;
})(GData || {});

// src/enums/GlitchMode.ts
var GlitchMode = /* @__PURE__ */ ((GlitchMode2) => {
  GlitchMode2[GlitchMode2["DISABLED"] = 0] = "DISABLED";
  GlitchMode2[GlitchMode2["SPORADIC"] = 1] = "SPORADIC";
  GlitchMode2[GlitchMode2["CONSTANT_MILD"] = 2] = "CONSTANT_MILD";
  GlitchMode2[GlitchMode2["CONSTANT_WILD"] = 3] = "CONSTANT_WILD";
  return GlitchMode2;
})(GlitchMode || {});

// src/enums/KernelSize.ts
var KernelSize = /* @__PURE__ */ ((KernelSize2) => {
  KernelSize2[KernelSize2["VERY_SMALL"] = 0] = "VERY_SMALL";
  KernelSize2[KernelSize2["SMALL"] = 1] = "SMALL";
  KernelSize2[KernelSize2["MEDIUM"] = 2] = "MEDIUM";
  KernelSize2[KernelSize2["LARGE"] = 3] = "LARGE";
  KernelSize2[KernelSize2["VERY_LARGE"] = 4] = "VERY_LARGE";
  KernelSize2[KernelSize2["HUGE"] = 5] = "HUGE";
  return KernelSize2;
})(KernelSize || {});

// src/enums/MaskFunction.ts
var MaskFunction = /* @__PURE__ */ ((MaskFunction2) => {
  MaskFunction2[MaskFunction2["DISCARD"] = 0] = "DISCARD";
  MaskFunction2[MaskFunction2["MULTIPLY"] = 1] = "MULTIPLY";
  return MaskFunction2;
})(MaskFunction || {});

// src/enums/PredicationMode.ts
var PredicationMode = /* @__PURE__ */ ((PredicationMode2) => {
  PredicationMode2[PredicationMode2["DISABLED"] = 0] = "DISABLED";
  PredicationMode2[PredicationMode2["DEPTH"] = 1] = "DEPTH";
  PredicationMode2[PredicationMode2["CUSTOM"] = 2] = "CUSTOM";
  return PredicationMode2;
})(PredicationMode || {});

// src/enums/SMAAPreset.ts
var SMAAPreset = /* @__PURE__ */ ((SMAAPreset2) => {
  SMAAPreset2[SMAAPreset2["LOW"] = 0] = "LOW";
  SMAAPreset2[SMAAPreset2["MEDIUM"] = 1] = "MEDIUM";
  SMAAPreset2[SMAAPreset2["HIGH"] = 2] = "HIGH";
  SMAAPreset2[SMAAPreset2["ULTRA"] = 3] = "ULTRA";
  return SMAAPreset2;
})(SMAAPreset || {});

// src/enums/ToneMapping.ts
var ToneMapping = /* @__PURE__ */ ((ToneMapping2) => {
  ToneMapping2[ToneMapping2["REINHARD"] = 0] = "REINHARD";
  ToneMapping2[ToneMapping2["OPTIMIZED_CINEON"] = 1] = "OPTIMIZED_CINEON";
  ToneMapping2[ToneMapping2["ACES_FILMIC"] = 2] = "ACES_FILMIC";
  ToneMapping2[ToneMapping2["AGX"] = 3] = "AGX";
  return ToneMapping2;
})(ToneMapping || {});

// src/enums/VignetteTechnique.ts
var VignetteTechnique = /* @__PURE__ */ ((VignetteTechnique2) => {
  VignetteTechnique2[VignetteTechnique2["DEFAULT"] = 0] = "DEFAULT";
  VignetteTechnique2[VignetteTechnique2["ESKIL"] = 1] = "ESKIL";
  return VignetteTechnique2;
})(VignetteTechnique || {});

// src/effects/blending/BlendFunction.ts
var BlendFunction = class _BlendFunction {
  /**
   * The next blend function ID.
   */
  static nextId = 0;
  /**
   * A unique blend function ID.
   */
  id;
  /**
   * A unique blend function name.
   */
  name;
  /**
   * The shader code.
   */
  shader;
  /**
   * Indicates whether this blend function supports HDR colors.
   *
   * Shaders that assume a color value range of [0, 1] are not compatible with HDR.
   */
  supportsHDR;
  /**
   * Constructs a new blend function.
   *
   * @param name - A unique blend function name.
   * @param shader - The shader code.
   * @param supportsHDR - Indicates whether this blend function supports HDR colors.
   */
  constructor(name, shader, supportsHDR = false) {
    this.id = _BlendFunction.nextId++;
    this.name = name;
    this.shader = shader;
    this.supportsHDR = supportsHDR;
  }
};

// src/effects/blending/BlendMode.ts
import { EventDispatcher as EventDispatcher7, Uniform as Uniform4 } from "three";
var BlendMode = class _BlendMode extends EventDispatcher7 {
  /**
   * Triggers when the blend function is changed.
   *
   * @event
   */
  static EVENT_CHANGE = "change";
  /**
   * @see {@link blendFunction}
   */
  _blendFunction;
  /**
   * A uniform that controls the opacity of this blend mode.
   *
   * @see {@link opacity}
   */
  opacityUniform;
  /**
   * Constructs a new blend mode.
   *
   * @param blendFunction - The blend function.
   * @param opacity - The opacity of the new color that will be blended with the base color.
   */
  constructor(blendFunction, opacity = 1) {
    super();
    this._blendFunction = blendFunction;
    this.opacityUniform = new Uniform4(opacity);
  }
  /**
   * A convenience accessor for the opacity uniform value.
   *
   * @see {@link opacityUniform}
   */
  get opacity() {
    return this.opacityUniform.value;
  }
  set opacity(value) {
    this.opacityUniform.value = value;
  }
  /**
   * The blend function.
   */
  get blendFunction() {
    return this._blendFunction;
  }
  set blendFunction(value) {
    this._blendFunction = value;
    this.dispatchEvent({ type: _BlendMode.EVENT_CHANGE });
  }
};

// src/effects/blending/blend-functions/shaders/add.frag
var add_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){return mix(x,vec4(x.rgb+y.rgb,y.a),opacity);}";

// src/effects/blending/blend-functions/AddBlendFunction.ts
var AddBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new add blend function.
   */
  constructor() {
    super("add", add_default, true);
  }
};

// src/effects/blending/blend-functions/shaders/alpha.frag
var alpha_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){return mix(x,y,min(y.a,opacity));}";

// src/effects/blending/blend-functions/AlphaBlendFunction.ts
var AlphaBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new alpha blend function.
   */
  constructor() {
    super("alpha", alpha_default, true);
  }
};

// src/effects/blending/blend-functions/shaders/average.frag
var average_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){return mix(x,vec4((x.rgb+y.rgb)*0.5,y.a),opacity);}";

// src/effects/blending/blend-functions/AverageBlendFunction.ts
var AverageBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new average blend function.
   */
  constructor() {
    super("average", average_default, true);
  }
};

// src/effects/blending/blend-functions/shaders/color.frag
var color_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){vec3 xHSL=RGBToHSL(x.rgb);vec3 yHSL=RGBToHSL(y.rgb);vec3 z=HSLToRGB(vec3(yHSL.xy,xHSL.z));return mix(x,vec4(z,y.a),opacity);}";

// src/effects/blending/blend-functions/ColorBlendFunction.ts
var ColorBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new color blend function.
   */
  constructor() {
    super("color", color_default);
  }
};

// src/effects/blending/blend-functions/shaders/color-burn.frag
var color_burn_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){vec3 a=x.rgb,b=y.rgb;vec3 z=mix(step(0.0,b)*(1.0-min(vec3(1.0),(1.0-a)/b)),vec3(1.0),step(1.0,a));return mix(x,vec4(z,y.a),opacity);}";

// src/effects/blending/blend-functions/ColorBurnBlendFunction.ts
var ColorBurnBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new color burn blend function.
   */
  constructor() {
    super("color-burn", color_burn_default);
  }
};

// src/effects/blending/blend-functions/shaders/color-dodge.frag
var color_dodge_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){vec3 a=x.rgb,b=y.rgb;vec3 z=step(0.0,a)*mix(min(vec3(1.0),a/max(1.0-b,1e-9)),vec3(1.0),step(1.0,b));return mix(x,vec4(z,y.a),opacity);}";

// src/effects/blending/blend-functions/ColorDodgeBlendFunction.ts
var ColorDodgeBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new color dodge blend function.
   */
  constructor() {
    super("color-dodge", color_dodge_default);
  }
};

// src/effects/blending/blend-functions/shaders/darken.frag
var darken_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){return mix(x,vec4(min(x.rgb,y.rgb),y.a),opacity);}";

// src/effects/blending/blend-functions/DarkenBlendFunction.ts
var DarkenBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new darken blend function.
   */
  constructor() {
    super("darken", darken_default, true);
  }
};

// src/effects/blending/blend-functions/shaders/difference.frag
var difference_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){return mix(x,vec4(abs(x.rgb-y.rgb),y.a),opacity);}";

// src/effects/blending/blend-functions/DifferenceBlendFunction.ts
var DifferenceBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new difference blend function.
   */
  constructor() {
    super("difference", difference_default, true);
  }
};

// src/effects/blending/blend-functions/shaders/divide.frag
var divide_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){return mix(x,vec4(x.rgb/max(y.rgb,1e-12),y.a),opacity);}";

// src/effects/blending/blend-functions/DivideBlendFunction.ts
var DivideBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new divide blend function.
   */
  constructor() {
    super("divide", divide_default, true);
  }
};

// src/effects/blending/blend-functions/DstBlendFunction.ts
var DstBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new DST blend function.
   */
  constructor() {
    super("dst", null, true);
  }
};

// src/effects/blending/blend-functions/shaders/exclusion.frag
var exclusion_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){return mix(x,vec4((x.rgb+y.rgb-2.0*x.rgb*y.rgb),y.a),opacity);}";

// src/effects/blending/blend-functions/ExclusionBlendFunction.ts
var ExclusionBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new exclusion blend function.
   */
  constructor() {
    super("exclusion", exclusion_default);
  }
};

// src/effects/blending/blend-functions/shaders/hard-light.frag
var hard_light_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){vec3 a=min(x.rgb,1.0);vec3 b=min(y.rgb,1.0);vec3 z=mix(2.0*a*b,1.0-2.0*(1.0-a)*(1.0-b),step(0.5,b));return mix(x,vec4(z,y.a),opacity);}";

// src/effects/blending/blend-functions/HardLightBlendFunction.ts
var HardLightBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new hard light blend function.
   */
  constructor() {
    super("hard-light", hard_light_default);
  }
};

// src/effects/blending/blend-functions/shaders/hard-mix.frag
var hard_mix_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){return mix(x,vec4(step(1.0,x.rgb+y.rgb),y.a),opacity);}";

// src/effects/blending/blend-functions/HardMixBlendFunction.ts
var HardMixBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new hard mix blend function.
   */
  constructor() {
    super("hard-mix", hard_mix_default);
  }
};

// src/effects/blending/blend-functions/shaders/hue.frag
var hue_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){vec3 xHSL=RGBToHSL(x.rgb);vec3 yHSL=RGBToHSL(y.rgb);vec3 z=HSLToRGB(vec3(yHSL.x,xHSL.yz));return mix(x,vec4(z,y.a),opacity);}";

// src/effects/blending/blend-functions/HueBlendFunction.ts
var HueBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new hue blend function.
   */
  constructor() {
    super("hue", hue_default);
  }
};

// src/effects/blending/blend-functions/shaders/invert.frag
var invert_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){return mix(x,vec4(1.0-y.rgb,y.a),opacity);}";

// src/effects/blending/blend-functions/InvertBlendFunction.ts
var InvertBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new invert blend function.
   */
  constructor() {
    super("invert", invert_default);
  }
};

// src/effects/blending/blend-functions/shaders/invert-rgb.frag
var invert_rgb_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){return mix(x,vec4(y.rgb*(1.0-x.rgb),y.a),opacity);}";

// src/effects/blending/blend-functions/InvertRGBBlendFunction.ts
var InvertRGBBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new invert RGB blend function.
   */
  constructor() {
    super("invert-rgb", invert_rgb_default);
  }
};

// src/effects/blending/blend-functions/shaders/lighten.frag
var lighten_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){return mix(x,vec4(max(x.rgb,y.rgb),y.a),opacity);}";

// src/effects/blending/blend-functions/LightenBlendFunction.ts
var LightenBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new lighten blend function.
   */
  constructor() {
    super("lighten", lighten_default, true);
  }
};

// src/effects/blending/blend-functions/shaders/linear-burn.frag
var linear_burn_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){return mix(x,vec4(clamp(y.rgb+x.rgb-1.0,0.0,1.0),y.a),opacity);}";

// src/effects/blending/blend-functions/LinearBurnBlendFunction.ts
var LinearBurnBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new linear burn blend function.
   */
  constructor() {
    super("linear-burn", linear_burn_default);
  }
};

// src/effects/blending/blend-functions/shaders/linear-dodge.frag
var linear_dodge_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){return mix(x,vec4(min(x.rgb+y.rgb,1.0),y.a),opacity);}";

// src/effects/blending/blend-functions/LinearDodgeBlendFunction.ts
var LinearDodgeBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new linear dodge blend function.
   */
  constructor() {
    super("linear-dodge", linear_dodge_default);
  }
};

// src/effects/blending/blend-functions/shaders/linear-light.frag
var linear_light_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){return mix(x,vec4(clamp(2.0*y.rgb+x.rgb-1.0,0.0,1.0),y.a),opacity);}";

// src/effects/blending/blend-functions/LinearLightBlendFunction.ts
var LinearLightBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new linear light blend function.
   */
  constructor() {
    super("linear-light", linear_light_default);
  }
};

// src/effects/blending/blend-functions/shaders/luminosity.frag
var luminosity_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){vec3 xHSL=RGBToHSL(x.rgb);vec3 yHSL=RGBToHSL(y.rgb);vec3 z=HSLToRGB(vec3(xHSL.xy,yHSL.z));return mix(x,vec4(z,y.a),opacity);}";

// src/effects/blending/blend-functions/LuminosityBlendFunction.ts
var LuminosityBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new luminosity blend function.
   */
  constructor() {
    super("luminosity", luminosity_default);
  }
};

// src/effects/blending/blend-functions/shaders/mix.frag
var mix_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){return mix(x,y,opacity);}";

// src/effects/blending/blend-functions/MixBlendFunction.ts
var MixBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new mix blend function.
   */
  constructor() {
    super("mix", mix_default, true);
  }
};

// src/effects/blending/blend-functions/shaders/multiply.frag
var multiply_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){return mix(x,vec4(x.rgb*y.rgb,y.a),opacity);}";

// src/effects/blending/blend-functions/MultiplyBlendFunction.ts
var MultiplyBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new multiply blend function.
   */
  constructor() {
    super("multiply", multiply_default, true);
  }
};

// src/effects/blending/blend-functions/shaders/negation.frag
var negation_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){return mix(x,vec4(1.0-abs(1.0-x.rgb-y.rgb),y.a),opacity);}";

// src/effects/blending/blend-functions/NegationBlendFunction.ts
var NegationBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new negation blend function.
   */
  constructor() {
    super("negation", negation_default);
  }
};

// src/effects/blending/blend-functions/shaders/overlay.frag
var overlay_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){vec3 z=mix(2.0*y.rgb*x.rgb,1.0-2.0*(1.0-y.rgb)*(1.0-x.rgb),step(0.5,x.rgb));return mix(x,vec4(z,y.a),opacity);}";

// src/effects/blending/blend-functions/OverlayBlendFunction.ts
var OverlayBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new overlay blend function.
   */
  constructor() {
    super("overlay", overlay_default);
  }
};

// src/effects/blending/blend-functions/shaders/pin-light.frag
var pin_light_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){vec3 y2=2.0*y.rgb;vec3 z=mix(mix(y2,x.rgb,step(0.5*x.rgb,y.rgb)),max(y2-1.0,vec3(0.0)),step(x.rgb,y2-1.0));return mix(x,vec4(z,y.a),opacity);}";

// src/effects/blending/blend-functions/PinLightBlendFunction.ts
var PinLightBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new pin light blend function.
   */
  constructor() {
    super("pin-light", pin_light_default);
  }
};

// src/effects/blending/blend-functions/shaders/reflect.frag
var reflect_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){vec3 z=mix(min(x.rgb*x.rgb/max(1.0-y.rgb,1e-12),1.0),y.rgb,step(1.0,y.rgb));return mix(x,vec4(z,y.a),opacity);}";

// src/effects/blending/blend-functions/ReflectBlendFunction.ts
var ReflectBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new reflect blend function.
   */
  constructor() {
    super("reflect", reflect_default);
  }
};

// src/effects/blending/blend-functions/shaders/saturation.frag
var saturation_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){vec3 xHSL=RGBToHSL(x.rgb);vec3 yHSL=RGBToHSL(y.rgb);vec3 z=HSLToRGB(vec3(xHSL.x,yHSL.y,xHSL.z));return mix(x,vec4(z,y.a),opacity);}";

// src/effects/blending/blend-functions/SaturationBlendFunction.ts
var SaturationBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new saturation blend function.
   */
  constructor() {
    super("saturation", saturation_default);
  }
};

// src/effects/blending/blend-functions/shaders/src.frag
var src_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){return y;}";

// src/effects/blending/blend-functions/SrcBlendFunction.ts
var SrcBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new SRC blend function.
   */
  constructor() {
    super("src", src_default, true);
  }
};

// src/effects/blending/blend-functions/shaders/screen.frag
var screen_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){return mix(x,vec4(x.rgb+y.rgb-min(x.rgb*y.rgb,1.0),y.a),opacity);}";

// src/effects/blending/blend-functions/ScreenBlendFunction.ts
var ScreenBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new screen blend function.
   */
  constructor() {
    super("screen", screen_default);
  }
};

// src/effects/blending/blend-functions/shaders/soft-light.frag
var soft_light_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){vec3 a=x.rgb;vec3 b=y.rgb;vec3 y2=2.0*b;vec3 w=step(0.5,b);vec3 c=a-(1.0-y2)*a*(1.0-a);vec3 d=mix(a+(y2-1.0)*(sqrt(a)-a),a+(y2-1.0)*a*((16.0*a-12.0)*a+3.0),w*(1.0-step(0.25,a)));vec3 z=mix(c,d,w);return mix(x,vec4(z,y.a),opacity);}";

// src/effects/blending/blend-functions/SoftLightBlendFunction.ts
var SoftLightBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new soft light blend function.
   */
  constructor() {
    super("soft-light", soft_light_default);
  }
};

// src/effects/blending/blend-functions/shaders/subtract.frag
var subtract_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){return mix(x,vec4(max(x.rgb+y.rgb-1.0,0.0),y.a),opacity);}";

// src/effects/blending/blend-functions/SubtractBlendFunction.ts
var SubtractBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new subtract blend function.
   */
  constructor() {
    super("subtract", subtract_default);
  }
};

// src/effects/blending/blend-functions/shaders/vivid-light.frag
var vivid_light_default = "vec4 blend(const in vec4 x,const in vec4 y,const in float opacity){vec3 z=mix(max(1.0-min((1.0-x.rgb)/(2.0*y.rgb),1.0),0.0),min(x.rgb/(2.0*(1.0-y.rgb)),1.0),step(0.5,y.rgb));return mix(x,vec4(z,y.a),opacity);}";

// src/effects/blending/blend-functions/VividLightBlendFunction.ts
var VividLightBlendFunction = class extends BlendFunction {
  /**
   * Constructs a new vivid light blend function.
   */
  constructor() {
    super("vivid-light", vivid_light_default);
  }
};

// src/effects/Effect.ts
import { NoColorSpace } from "three";
var Effect = class extends Pass {
  /**
   * The blend mode.
   */
  blendMode;
  /**
   * @see {@link fragmentShader}
   */
  _fragmentShader;
  /**
   * @see {@link vertexShader}
   */
  _vertexShader;
  /**
   * @see {@link inputColorSpace}
   */
  _inputColorSpace;
  /**
   * @see {@link outputColorSpace}
   */
  _outputColorSpace;
  /**
   * Constructs a new effect.
   *
   * @param name - A name that will be used for debugging purposes. Doesn't have to be unique.
   */
  constructor(name) {
    super(name);
    this.blendMode = new BlendMode(new SrcBlendFunction());
    this.blendMode.addEventListener(Pass.EVENT_CHANGE, () => this.setChanged());
    this._fragmentShader = null;
    this._vertexShader = null;
    this._inputColorSpace = NoColorSpace;
    this._outputColorSpace = NoColorSpace;
  }
  /**
   * The fragment shader.
   */
  get fragmentShader() {
    return this._fragmentShader;
  }
  set fragmentShader(value) {
    this._fragmentShader = value;
    this.setChanged();
  }
  /**
   * The fragment shader.
   */
  get vertexShader() {
    return this._vertexShader;
  }
  set vertexShader(value) {
    this._vertexShader = value;
    this.setChanged();
  }
  /**
   * The input color space. Default is `NoColorSpace`, meaning no change.
   *
   * Ensures that the input colors are in the specified color space, converting them if necessary.
   */
  get inputColorSpace() {
    return this._inputColorSpace;
  }
  set inputColorSpace(value) {
    this._inputColorSpace = value;
    this.setChanged();
  }
  /**
   * The output color space. Default is `NoColorSpace`, meaning no change.
   *
   * Should only be defined if this effect converts the input colors to a different color space.
   */
  get outputColorSpace() {
    return this._outputColorSpace;
  }
  set outputColorSpace(value) {
    this._outputColorSpace = value;
    this.setChanged();
  }
  /**
   * Indicates whether this effect defines a `mainImage` function in its fragment shader.
   */
  get hasMainImageFunction() {
    const regExp = /vec4\s+mainImage\s*\(.*vec4\s+\w+,.*vec2\s+\w+,.*GData\s+\w+\)/;
    return this.fragmentShader !== null && regExp.test(this.fragmentShader);
  }
  /**
   * Indicates whether this effect defines a `mainUv` function in its fragment shader.
   */
  get hasMainUvFunction() {
    const regExp = /void\s+mainUv\s*\(.*inout\s+vec2\s+\w+\)/;
    return this.fragmentShader !== null && regExp.test(this.fragmentShader);
  }
  /**
   * Indicates whether this effect defines a `mainSupport` function in its vertex shader.
   */
  get hasMainSupportFunction() {
    const regExp = /void\s+mainSupport\s*\(.*vec2\s+\w+\)/;
    return this.vertexShader !== null && regExp.test(this.vertexShader);
  }
  render() {
  }
};

// src/effects/shaders/fxaa.frag
var fxaa_default = "#define QUALITY(q) ((q) < 5 ? 1.0 : ((q) > 5 ? ((q) < 10 ? 2.0 : ((q) < 11 ? 4.0 : 8.0)) : 1.5))\n#define ONE_OVER_TWELVE 0.08333333333333333\nin vec2 vUvDown;in vec2 vUvUp;in vec2 vUvLeft;in vec2 vUvRight;in vec2 vUvDownLeft;in vec2 vUvUpRight;in vec2 vUvUpLeft;in vec2 vUvDownRight;vec4 fxaa(sampler2D inputBuffer,const in vec4 inputColor,const in vec2 uv){float lumaCenter=luminance(inputColor.rgb);float lumaDown=luminance(texture(inputBuffer,vUvDown).rgb);float lumaUp=luminance(texture(inputBuffer,vUvUp).rgb);float lumaLeft=luminance(texture(inputBuffer,vUvLeft).rgb);float lumaRight=luminance(texture(inputBuffer,vUvRight).rgb);float lumaMin=min(lumaCenter,min(min(lumaDown,lumaUp),min(lumaLeft,lumaRight)));float lumaMax=max(lumaCenter,max(max(lumaDown,lumaUp),max(lumaLeft,lumaRight)));float lumaRange=lumaMax-lumaMin;if(lumaRange<max(EDGE_THRESHOLD_MIN,lumaMax*EDGE_THRESHOLD_MAX)){return inputColor;}float lumaDownLeft=luminance(texture(inputBuffer,vUvDownLeft).rgb);float lumaUpRight=luminance(texture(inputBuffer,vUvUpRight).rgb);float lumaUpLeft=luminance(texture(inputBuffer,vUvUpLeft).rgb);float lumaDownRight=luminance(texture(inputBuffer,vUvDownRight).rgb);float lumaDownUp=lumaDown+lumaUp;float lumaLeftRight=lumaLeft+lumaRight;float lumaLeftCorners=lumaDownLeft+lumaUpLeft;float lumaDownCorners=lumaDownLeft+lumaDownRight;float lumaRightCorners=lumaDownRight+lumaUpRight;float lumaUpCorners=lumaUpRight+lumaUpLeft;float edgeHorizontal=(abs(-2.0*lumaLeft+lumaLeftCorners)+abs(-2.0*lumaCenter+lumaDownUp)*2.0+abs(-2.0*lumaRight+lumaRightCorners));float edgeVertical=(abs(-2.0*lumaUp+lumaUpCorners)+abs(-2.0*lumaCenter+lumaLeftRight)*2.0+abs(-2.0*lumaDown+lumaDownCorners));bool isHorizontal=(edgeHorizontal>=edgeVertical);float stepLength=isHorizontal?resolution.zw.y:resolution.zw.x;float luma1=isHorizontal?lumaDown:lumaLeft;float luma2=isHorizontal?lumaUp:lumaRight;float gradient1=abs(luma1-lumaCenter);float gradient2=abs(luma2-lumaCenter);bool is1Steepest=gradient1>=gradient2;float gradientScaled=0.25*max(gradient1,gradient2);float lumaLocalAverage=0.0;if(is1Steepest){stepLength=-stepLength;lumaLocalAverage=0.5*(luma1+lumaCenter);}else{lumaLocalAverage=0.5*(luma2+lumaCenter);}vec2 currentUv=uv;if(isHorizontal){currentUv.y+=stepLength*0.5;}else{currentUv.x+=stepLength*0.5;}vec2 offset=isHorizontal?vec2(resolution.zw.x,0.0):vec2(0.0,resolution.zw.y);vec2 uv1=currentUv-offset*QUALITY(0);vec2 uv2=currentUv+offset*QUALITY(0);float lumaEnd1=luminance(texture(inputBuffer,uv1).rgb);float lumaEnd2=luminance(texture(inputBuffer,uv2).rgb);lumaEnd1-=lumaLocalAverage;lumaEnd2-=lumaLocalAverage;bool reached1=abs(lumaEnd1)>=gradientScaled;bool reached2=abs(lumaEnd2)>=gradientScaled;bool reachedBoth=reached1&&reached2;if(!reached1){uv1-=offset*QUALITY(1);}if(!reached2){uv2+=offset*QUALITY(1);}if(!reachedBoth){for(int i=2;i<SAMPLES;++i){if(!reached1){lumaEnd1=luminance(texture(inputBuffer,uv1).rgb);lumaEnd1=lumaEnd1-lumaLocalAverage;}if(!reached2){lumaEnd2=luminance(texture(inputBuffer,uv2).rgb);lumaEnd2=lumaEnd2-lumaLocalAverage;}reached1=abs(lumaEnd1)>=gradientScaled;reached2=abs(lumaEnd2)>=gradientScaled;reachedBoth=reached1&&reached2;if(!reached1){uv1-=offset*QUALITY(i);}if(!reached2){uv2+=offset*QUALITY(i);}if(reachedBoth){break;}}}float distance1=isHorizontal?(uv.x-uv1.x):(uv.y-uv1.y);float distance2=isHorizontal?(uv2.x-uv.x):(uv2.y-uv.y);bool isDirection1=distance1<distance2;float distanceFinal=min(distance1,distance2);float edgeThickness=(distance1+distance2);bool isLumaCenterSmaller=lumaCenter<lumaLocalAverage;bool correctVariation1=(lumaEnd1<0.0)!=isLumaCenterSmaller;bool correctVariation2=(lumaEnd2<0.0)!=isLumaCenterSmaller;bool correctVariation=isDirection1?correctVariation1:correctVariation2;float pixelOffset=-distanceFinal/edgeThickness+0.5;float finalOffset=correctVariation?pixelOffset:0.0;float lumaAverage=ONE_OVER_TWELVE*(2.0*(lumaDownUp+lumaLeftRight)+lumaLeftCorners+lumaRightCorners);float subPixelOffset1=clamp(abs(lumaAverage-lumaCenter)/lumaRange,0.0,1.0);float subPixelOffset2=(-2.0*subPixelOffset1+3.0)*subPixelOffset1*subPixelOffset1;float subPixelOffsetFinal=subPixelOffset2*subPixelOffset2*SUBPIXEL_QUALITY;finalOffset=max(finalOffset,subPixelOffsetFinal);vec2 finalUv=uv;if(isHorizontal){finalUv.y+=finalOffset*stepLength;}else{finalUv.x+=finalOffset*stepLength;}return texture(inputBuffer,finalUv);}vec4 mainImage(const in vec4 inputColor,const in vec2 uv,const in GData gData){return fxaa(gBuffer.color,inputColor,uv);}";

// src/effects/shaders/fxaa.vert
var fxaa_default2 = "out vec2 vUvDown;out vec2 vUvUp;out vec2 vUvLeft;out vec2 vUvRight;out vec2 vUvDownLeft;out vec2 vUvUpRight;out vec2 vUvUpLeft;out vec2 vUvDownRight;void mainSupport(const in vec2 uv){vUvDown=uv+vec2(0.0,-1.0)*resolution.zw;vUvUp=uv+vec2(0.0,1.0)*resolution.zw;vUvRight=uv+vec2(1.0,0.0)*resolution.zw;vUvLeft=uv+vec2(-1.0,0.0)*resolution.zw;vUvDownLeft=uv+vec2(-1.0,-1.0)*resolution.zw;vUvUpRight=uv+vec2(1.0,1.0)*resolution.zw;vUvUpLeft=uv+vec2(-1.0,1.0)*resolution.zw;vUvDownRight=uv+vec2(1.0,-1.0)*resolution.zw;}";

// src/effects/FXAAEffect.ts
var FXAAEffect = class extends Effect {
  /**
   * Constructs a new FXAA effect.
   */
  constructor() {
    super("FXAAEffect");
    this.fragmentShader = fxaa_default;
    this.vertexShader = fxaa_default2;
    this.minEdgeThreshold = 0.0312;
    this.maxEdgeThreshold = 0.125;
    this.subpixelQuality = 0.75;
    this.samples = 12;
  }
  /**
   * The minimum edge detection threshold. Range is [0.0, 1.0].
   */
  get minEdgeThreshold() {
    return this.input.defines.get("EDGE_THRESHOLD_MIN");
  }
  set minEdgeThreshold(value) {
    this.input.defines.set("EDGE_THRESHOLD_MIN", value);
    this.setChanged();
  }
  /**
   * The maximum edge detection threshold. Range is [0.0, 1.0].
   */
  get maxEdgeThreshold() {
    return this.input.defines.get("EDGE_THRESHOLD_MAX");
  }
  set maxEdgeThreshold(value) {
    this.input.defines.set("EDGE_THRESHOLD_MAX", value);
    this.setChanged();
  }
  /**
   * The subpixel blend quality. Range is [0.0, 1.0].
   */
  get subpixelQuality() {
    return this.input.defines.get("SUBPIXEL_QUALITY");
  }
  set subpixelQuality(value) {
    this.input.defines.set("SUBPIXEL_QUALITY", value);
    this.setChanged();
  }
  /**
   * The maximum amount of edge detection samples.
   */
  get samples() {
    return this.input.defines.get("SAMPLES");
  }
  set samples(value) {
    this.input.defines.set("SAMPLES", value);
    this.setChanged();
  }
};

// src/effects/shaders/tone-mapping.frag
var tone_mapping_default = "#include <tonemapping_pars_fragment>\nvec4 mainImage(const in vec4 inputColor,const in vec2 uv,const in GData gData){return vec4(toneMapping(inputColor.rgb),inputColor.a);}";

// src/effects/ToneMappingEffect.ts
var ToneMappingEffect = class extends Effect {
  /**
   * Constructs a new tone mapping effect.
   *
   * @param options - The options.
   */
  constructor({ toneMapping = 3 /* AGX */ } = {}) {
    super("ToneMappingEffect");
    this.fragmentShader = tone_mapping_default;
    this.toneMapping = toneMapping;
  }
  /**
   * The tone mapping mode.
   */
  get toneMapping() {
    return this.input.defines.get("TONE_MAPPING");
  }
  set toneMapping(value) {
    if (this.toneMapping !== value) {
      const defines = this.input.defines;
      defines.clear();
      defines.set("TONE_MAPPING", value);
      switch (value) {
        case 0 /* REINHARD */:
          defines.set("toneMapping(texel)", "ReinhardToneMapping(texel)");
          break;
        case 1 /* OPTIMIZED_CINEON */:
          defines.set("toneMapping(texel)", "OptimizedCineonToneMapping(texel)");
          break;
        case 2 /* ACES_FILMIC */:
          defines.set("toneMapping(texel)", "ACESFilmicToneMapping(texel)");
          break;
        case 3 /* AGX */:
          defines.set("toneMapping(texel)", "AgXToneMapping(texel)");
          break;
        default:
          defines.set("toneMapping(texel)", "texel");
          break;
      }
      this.setChanged();
    }
  }
};

// src/effects/VignetteEffect.ts
import { Color as Color3, Uniform as Uniform5, Vector2 as Vector23 } from "three";

// src/effects/shaders/vignette.frag
var vignette_default = "uniform vec2 offsetFeather;uniform vec3 color;vec4 mainImage(const in vec4 inputColor,const in vec2 uv,const in GData gData){const vec2 center=vec2(0.5);vec3 result=inputColor.rgb;\n#if VIGNETTE_TECHNIQUE == 0\nfloat d=distance(uv,center);float feather=1.0-offsetFeather.y;float factor=smoothstep(feather*0.799,0.8,d*(offsetFeather.x+feather));result=mix(result,color,factor);\n#else\nvec2 coord=(uv-center)*offsetFeather.xx;result=mix(result,offsetFeather.yyy*color,dot(coord,coord));\n#endif\nreturn vec4(result,inputColor.a);}";

// src/effects/VignetteEffect.ts
var VignetteEffect = class extends Effect {
  /**
   * Constructs a new vignette effect.
   *
   * @param options - The options.
   */
  constructor({
    technique = 0 /* DEFAULT */,
    offset = 0.5,
    feather = 0.5,
    color: color2 = 0
  } = {}) {
    super("VignetteEffectOptions");
    this.fragmentShader = vignette_default;
    this.technique = technique;
    const uniforms = this.input.uniforms;
    uniforms.set("offsetFeather", new Uniform5(new Vector23(offset, feather)));
    uniforms.set("color", new Uniform5(new Color3(color2)));
  }
  /**
   * The Vignette technique.
   */
  get technique() {
    return this.input.defines.get("VIGNETTE_TECHNIQUE");
  }
  set technique(value) {
    if (this.technique !== value) {
      this.input.defines.set("VIGNETTE_TECHNIQUE", value);
      this.setChanged();
    }
  }
  /**
   * The Vignette offset.
   */
  get offset() {
    const offsetFeather = this.input.uniforms.get("offsetFeather").value;
    return offsetFeather.x;
  }
  set offset(value) {
    const offsetFeather = this.input.uniforms.get("offsetFeather").value;
    offsetFeather.x = value;
  }
  /**
   * The Vignette softness.
   */
  get feather() {
    const offsetFeather = this.input.uniforms.get("offsetFeather").value;
    return offsetFeather.y;
  }
  set feather(value) {
    const offsetFeather = this.input.uniforms.get("offsetFeather").value;
    offsetFeather.y = value;
  }
  /**
   * The Vignette color.
   */
  get color() {
    return this.input.uniforms.get("color").value;
  }
  set color(value) {
    const color2 = this.input.uniforms.get("color").value;
    color2.set(value);
  }
};

// src/materials/AdaptiveLuminanceMaterial.ts
import { Uniform as Uniform6 } from "three";

// src/materials/shaders/adaptive-luminance.frag
var adaptive_luminance_default = "#include <pp_precision_fragment>\n#include <pp_default_output_pars_fragment>\n#include <packing>\n#define packFloatToRGBA(v) packDepthToRGBA(v)\n#define unpackRGBAToFloat(v) unpackRGBAToDepth(v)\nuniform lowp sampler2D luminanceBuffer0;uniform lowp sampler2D luminanceBuffer1;uniform float minLuminance;uniform float deltaTime;uniform float tau;in vec2 vUv;void main(){float l0=unpackRGBAToFloat(texture(luminanceBuffer0,vUv));float l1=textureLod(luminanceBuffer1,vUv,MIP_LEVEL_1X1).r;l0=max(minLuminance,l0);l1=max(minLuminance,l1);float adaptedLum=l0+(l1-l0)*(1.0-exp(-deltaTime*tau));outputColor=(adaptedLum==1.0)?vec4(1.0):packFloatToRGBA(adaptedLum);}";

// src/materials/AdaptiveLuminanceMaterial.ts
var AdaptiveLuminanceMaterial = class extends FullscreenMaterial {
  /**
   * Constructs a new adaptive luminance material.
   */
  constructor() {
    super({
      name: "AdaptiveLuminanceMaterial",
      fragmentShader: adaptive_luminance_default,
      vertexShader: common_default,
      defines: {
        MIP_LEVEL_1X1: 0
      },
      uniforms: {
        luminanceBuffer0: new Uniform6(null),
        luminanceBuffer1: new Uniform6(null),
        minLuminance: new Uniform6(0.01),
        deltaTime: new Uniform6(0),
        tau: new Uniform6(1)
      },
      extensions: {
        shaderTextureLOD: true
      }
    });
  }
  /**
   * The primary luminance buffer that contains the downsampled average luminance.
   */
  set luminanceBuffer0(value) {
    this.uniforms.luminanceBuffer0.value = value;
  }
  /**
   * The secondary luminance buffer.
   */
  set luminanceBuffer1(value) {
    this.uniforms.luminanceBuffer1.value = value;
  }
  /**
   * The 1x1 mipmap level.
   *
   * This level is used to identify the smallest mipmap of the primary luminance buffer.
   */
  set mipLevel1x1(value) {
    this.defines.MIP_LEVEL_1X1 = value;
    this.needsUpdate = true;
  }
  /**
   * The delta time.
   */
  set deltaTime(value) {
    this.uniforms.deltaTime.value = value;
  }
  /**
   * The lowest possible luminance value.
   */
  get minLuminance() {
    return this.uniforms.minLuminance.value;
  }
  set minLuminance(value) {
    this.uniforms.minLuminance.value = value;
  }
  /**
   * The luminance adaptation rate.
   */
  get adaptationRate() {
    return this.uniforms.tau.value;
  }
  set adaptationRate(value) {
    this.uniforms.tau.value = value;
  }
};

// src/materials/BokehMaterial.ts
import { Uniform as Uniform7 } from "three";

// src/materials/shaders/convolution.bokeh.frag
var convolution_bokeh_default = "#include <pp_precision_fragment>\n#include <pp_default_output_pars_fragment>\n#include <pp_input_buffer_pars_fragment>\n#include <pp_resolution_pars_fragment>\n#if PASS == 1\nuniform vec4 kernel64[32];\n#else\nuniform vec4 kernel16[8];\n#endif\nuniform lowp sampler2D cocBuffer;uniform float scale;in vec2 vUv;void main(){\n#ifdef FOREGROUND\nvec2 cocNearFar=texture(cocBuffer,vUv).rg*scale;float coc=cocNearFar.x;\n#else\nfloat coc=texture(cocBuffer,vUv).g*scale;\n#endif\nif(coc==0.0){outputColor=texture(inputBuffer,vUv);}else{\n#ifdef FOREGROUND\nvec2 step=resolution.zw*max(cocNearFar.x,cocNearFar.y);\n#else\nvec2 step=resolution.zw*coc;\n#endif\n#if PASS == 1\nvec4 acc=vec4(0.0);for(int i=0;i<32;++i){vec4 kernel=kernel64[i];vec2 uv=step*kernel.xy+vUv;acc+=texture(inputBuffer,uv);uv=step*kernel.zw+vUv;acc+=texture(inputBuffer,uv);}outputColor=acc/64.0;\n#else\nvec4 maxValue=texture(inputBuffer,vUv);for(int i=0;i<8;++i){vec4 kernel=kernel16[i];vec2 uv=step*kernel.xy+vUv;maxValue=max(texture(inputBuffer,uv),maxValue);uv=step*kernel.zw+vUv;maxValue=max(texture(inputBuffer,uv),maxValue);}outputColor=maxValue;\n#endif\n}}";

// src/materials/BokehMaterial.ts
var BokehMaterial = class extends FullscreenMaterial {
  /**
   * Constructs a new bokeh material.
   *
   * @param fill - Enables or disables the bokeh highlight fill mode.
   * @param foreground - Determines whether this material will be applied to foreground colors.
   */
  constructor(fill = false, foreground = false) {
    super({
      name: "BokehMaterial",
      fragmentShader: convolution_bokeh_default,
      vertexShader: common_default,
      defines: {
        PASS: fill ? 2 : 1
      },
      uniforms: {
        cocBuffer: new Uniform7(null),
        kernel64: new Uniform7(null),
        kernel16: new Uniform7(null),
        scale: new Uniform7(1)
      }
    });
    if (foreground) {
      this.defines.FOREGROUND = true;
    }
    this.generateKernel();
  }
  /**
   * The circle of confusion buffer.
   */
  set cocBuffer(value) {
    this.uniforms.cocBuffer.value = value;
  }
  /**
   * The blur scale.
   */
  get scale() {
    return this.uniforms.scale.value;
  }
  set scale(value) {
    this.uniforms.scale.value = value;
  }
  /**
   * Generates the blur kernel.
   */
  generateKernel() {
    const GOLDEN_ANGLE = 2.39996323;
    const points64 = new Float64Array(128);
    const points16 = new Float64Array(32);
    let i64 = 0, i16 = 0;
    for (let i = 0, sqrt80 = Math.sqrt(80); i < 80; ++i) {
      const theta = i * GOLDEN_ANGLE;
      const r = Math.sqrt(i) / sqrt80;
      const u = r * Math.cos(theta), v2 = r * Math.sin(theta);
      if (i % 5 === 0) {
        points16[i16++] = u;
        points16[i16++] = v2;
      } else {
        points64[i64++] = u;
        points64[i64++] = v2;
      }
    }
    this.uniforms.kernel64.value = points64;
    this.uniforms.kernel16.value = points16;
  }
};

// src/materials/BoxBlurMaterial.ts
import { Uniform as Uniform8 } from "three";

// src/utils/functions/camera.ts
function orthographicDepthToViewZ(depth, near, far) {
  return depth * (near - far) - near;
}
function viewZToOrthographicDepth(viewZ, near, far) {
  return Math.min(Math.max((viewZ + near) / (near - far), 0), 1);
}

// src/materials/shaders/convolution.box.frag
var convolution_box_default = "#include <pp_precision_fragment>\n#include <pp_default_output_pars_fragment>\n#include <pp_input_buffer_pars_fragment>\n#ifdef BILATERAL\n#include <pp_camera_pars_fragment>\n#ifdef NORMAL_DEPTH\n#ifdef GL_FRAGMENT_PRECISION_HIGH\nuniform highp sampler2D normalDepthBuffer;\n#else\nuniform mediump sampler2D normalDepthBuffer;\n#endif\n#define getDepth(uv) texture(normalDepthBuffer, uv).a\n#else\n#include <pp_depth_buffer_pars_fragment>\n#define getDepth(uv) texture(depthBuffer, uv).r\n#endif\n#include <packing>\n#ifdef PERSPECTIVE_CAMERA\n#define getViewZ(depth) perspectiveDepthToViewZ(depth, cameraParams.x, cameraParams.y)\n#define linearDepth(uv) viewZToOrthographicDepth(getViewZ(getDepth(uv)), cameraParams.x, cameraParams.y)\n#else\n#define getViewZ(depth) orthographicDepthToViewZ(depth, cameraParams.x, cameraParams.y)\n#define linearDepth(uv) getDepth(uv)\n#endif\n#endif\n#define getTexel(uv) texture(inputBuffer, uv)\n#if KERNEL_SIZE == 3\nin vec2 vUv00,vUv01,vUv02;in vec2 vUv03,vUv04,vUv05;in vec2 vUv06,vUv07,vUv08;\n#elif KERNEL_SIZE == 5 && MAX_VARYING_VECTORS >= 13\nin vec2 vUv00,vUv01,vUv02,vUv03,vUv04;in vec2 vUv05,vUv06,vUv07,vUv08,vUv09;in vec2 vUv10,vUv11,vUv12,vUv13,vUv14;in vec2 vUv15,vUv16,vUv17,vUv18,vUv19;in vec2 vUv20,vUv21,vUv22,vUv23,vUv24;\n#else\n#include <pp_resolution_pars_fragment>\nuniform float scale;in vec2 vUv;\n#endif\nvoid main(){\n#if KERNEL_SIZE == 3\nvec4 c[]=vec4[KERNEL_SIZE_SQ](getTexel(vUv00),getTexel(vUv01),getTexel(vUv02),getTexel(vUv03),getTexel(vUv04),getTexel(vUv05),getTexel(vUv06),getTexel(vUv07),getTexel(vUv08));\n#ifdef BILATERAL\nfloat z[]=float[KERNEL_SIZE_SQ](linearDepth(vUv00),linearDepth(vUv01),linearDepth(vUv02),linearDepth(vUv03),linearDepth(vUv04),linearDepth(vUv05),linearDepth(vUv06),linearDepth(vUv07),linearDepth(vUv08));\n#endif\n#elif KERNEL_SIZE == 5 && MAX_VARYING_VECTORS >= 13\nvec4 c[]=vec4[KERNEL_SIZE_SQ](getTexel(vUv00),getTexel(vUv01),getTexel(vUv02),getTexel(vUv03),getTexel(vUv04),getTexel(vUv05),getTexel(vUv06),getTexel(vUv07),getTexel(vUv08),getTexel(vUv09),getTexel(vUv10),getTexel(vUv11),getTexel(vUv12),getTexel(vUv13),getTexel(vUv14),getTexel(vUv15),getTexel(vUv16),getTexel(vUv17),getTexel(vUv18),getTexel(vUv19),getTexel(vUv20),getTexel(vUv21),getTexel(vUv22),getTexel(vUv23),getTexel(vUv24));\n#ifdef BILATERAL\nfloat z[]=float[KERNEL_SIZE_SQ](linearDepth(vUv00),linearDepth(vUv01),linearDepth(vUv02),linearDepth(vUv03),linearDepth(vUv04),linearDepth(vUv05),linearDepth(vUv06),linearDepth(vUv07),linearDepth(vUv08),linearDepth(vUv09),linearDepth(vUv10),linearDepth(vUv11),linearDepth(vUv12),linearDepth(vUv13),linearDepth(vUv14),linearDepth(vUv15),linearDepth(vUv16),linearDepth(vUv17),linearDepth(vUv18),linearDepth(vUv19),linearDepth(vUv20),linearDepth(vUv21),linearDepth(vUv22),linearDepth(vUv23),linearDepth(vUv24));\n#endif\n#endif\nvec4 result=vec4(0.0);\n#ifdef BILATERAL\nfloat w=0.0;\n#if KERNEL_SIZE == 3 || (KERNEL_SIZE == 5 && MAX_VARYING_VECTORS >= 13)\nfloat centerDepth=z[KERNEL_SIZE_SQ_HALF];for(int i=0;i<KERNEL_SIZE_SQ;++i){float d=step(abs(z[i]-centerDepth),DISTANCE_THRESHOLD);result+=c[i]*d;w+=d;}\n#else\nfloat centerDepth=linearDepth(vUv);vec2 s=resolution.zw*scale;for(int x=-KERNEL_SIZE_HALF;x<=KERNEL_SIZE_HALF;++x){for(int y=-KERNEL_SIZE_HALF;y<=KERNEL_SIZE_HALF;++y){vec2 coords=vUv+vec2(x,y)*s;vec4 c=getTexel(coords);float z=(x==0&&y==0)?centerDepth:linearDepth(coords);float d=step(abs(z-centerDepth),DISTANCE_THRESHOLD);result+=c*d;w+=d;}}\n#endif\noutputColor=result/max(w,1.0);\n#else\n#if KERNEL_SIZE == 3 || (KERNEL_SIZE == 5 && MAX_VARYING_VECTORS >= 13)\nfor(int i=0;i<KERNEL_SIZE_SQ;++i){result+=c[i];}\n#else\nvec2 s=resolution.zw*scale;for(int x=-KERNEL_SIZE_HALF;x<=KERNEL_SIZE_HALF;++x){for(int y=-KERNEL_SIZE_HALF;y<=KERNEL_SIZE_HALF;++y){result+=getTexel(uv+vec2(x,y)*s);}}\n#endif\noutputColor=result*INV_KERNEL_SIZE_SQ;\n#endif\n}";

// src/materials/shaders/convolution.box.vert
var convolution_box_default2 = "#include <pp_resolution_pars_fragment>\nuniform float scale;\n#if KERNEL_SIZE == 3\nout vec2 vUv00,vUv01,vUv02;out vec2 vUv03,vUv04,vUv05;out vec2 vUv06,vUv07,vUv08;\n#elif KERNEL_SIZE == 5 && MAX_VARYING_VECTORS >= 13\nout vec2 vUv00,vUv01,vUv02,vUv03,vUv04;out vec2 vUv05,vUv06,vUv07,vUv08,vUv09;out vec2 vUv10,vUv11,vUv12,vUv13,vUv14;out vec2 vUv15,vUv16,vUv17,vUv18,vUv19;out vec2 vUv20,vUv21,vUv22,vUv23,vUv24;\n#else\nout vec2 vUv;\n#endif\nvoid main(){vec2 uv=position.xy*0.5+0.5;\n#if KERNEL_SIZE == 3\nvec2 s=resolution.zw*scale;vUv00=uv+s*vec2(-1.0,-1.0);vUv01=uv+s*vec2(0.0,-1.0);vUv02=uv+s*vec2(1.0,-1.0);vUv03=uv+s*vec2(-1.0,0.0);vUv04=uv;vUv05=uv+s*vec2(1.0,0.0);vUv06=uv+s*vec2(-1.0,1.0);vUv07=uv+s*vec2(0.0,1.0);vUv08=uv+s*vec2(1.0,1.0);\n#elif KERNEL_SIZE == 5\nvec2 s=resolution.zw*scale;vUv00=uv+s*vec2(-2.0,-2.0);vUv01=uv+s*vec2(-1.0,-2.0);vUv02=uv+s*vec2(0.0,-2.0);vUv03=uv+s*vec2(1.0,-2.0);vUv04=uv+s*vec2(2.0,-2.0);vUv05=uv+s*vec2(-2.0,-1.0);vUv06=uv+s*vec2(-1.0,-1.0);vUv07=uv+s*vec2(0.0,-1.0);vUv08=uv+s*vec2(1.0,-1.0);vUv09=uv+s*vec2(2.0,-1.0);vUv10=uv+s*vec2(-2.0,0.0);vUv11=uv+s*vec2(-1.0,0.0);vUv12=uv;vUv13=uv+s*vec2(1.0,0.0);vUv14=uv+s*vec2(2.0,0.0);vUv15=uv+s*vec2(-2.0,1.0);vUv16=uv+s*vec2(-1.0,1.0);vUv17=uv+s*vec2(0.0,1.0);vUv18=uv+s*vec2(1.0,1.0);vUv19=uv+s*vec2(2.0,1.0);vUv20=uv+s*vec2(-2.0,2.0);vUv21=uv+s*vec2(-1.0,2.0);vUv22=uv+s*vec2(0.0,2.0);vUv23=uv+s*vec2(1.0,2.0);vUv24=uv+s*vec2(2.0,2.0);\n#else\nvUv=uv;\n#endif\ngl_Position=vec4(position.xy,1.0,1.0);}";

// src/materials/BoxBlurMaterial.ts
var BoxBlurMaterial = class extends FullscreenMaterial {
  /**
   * Constructs a new box blur material.
   *
   * @param options - The options.
   */
  constructor({ bilateral = false, kernelSize = 5 } = {}) {
    super({
      name: "BoxBlurMaterial",
      fragmentShader: convolution_box_default,
      vertexShader: convolution_box_default2,
      defines: {
        DISTANCE_THRESHOLD: 0.1
      },
      uniforms: {
        depthBuffer: new Uniform8(null),
        normalDepthBuffer: new Uniform8(null),
        scale: new Uniform8(1)
      }
    });
    this.bilateral = bilateral;
    this.kernelSize = kernelSize;
    this.maxVaryingVectors = 8;
  }
  /**
   * The maximum amount of varying vectors.
   *
   * Should be synced with `renderer.capabilities.maxVaryings`. Default is `8` (minimum).
   */
  set maxVaryingVectors(value) {
    this.defines.MAX_VARYING_VECTORS = value;
  }
  /**
   * The kernel size.
   *
   * - Must be an odd number
   * - Kernel size `3` and `5` use optimized code paths
   * - Default is `5`
   */
  get kernelSize() {
    return this.defines.KERNEL_SIZE;
  }
  set kernelSize(value) {
    if (value % 2 === 0) {
      throw new Error("The kernel size must be an odd number");
    }
    this.defines.KERNEL_SIZE = value;
    this.defines.KERNEL_SIZE_HALF = Math.floor(value / 2);
    this.defines.KERNEL_SIZE_SQ = value ** 2;
    this.defines.KERNEL_SIZE_SQ_HALF = Math.floor(value ** 2 / 2);
    this.defines.INV_KERNEL_SIZE_SQ = 1 / value ** 2;
    this.needsUpdate = true;
  }
  /**
   * The blur scale.
   */
  get scale() {
    return this.uniforms.scale.value;
  }
  set scale(value) {
    this.uniforms.scale.value = value;
  }
  /**
   * The depth buffer.
   */
  set depthBuffer(value) {
    this.uniforms.depthBuffer.value = value;
  }
  /**
   * A combined normal-depth buffer. Overrides {@link depthBuffer} if set.
   */
  set normalDepthBuffer(value) {
    this.uniforms.normalDepthBuffer.value = value;
    if (value !== null) {
      this.defines.NORMAL_DEPTH = true;
    } else {
      delete this.defines.NORMAL_DEPTH;
    }
    this.needsUpdate = true;
  }
  /**
   * Indicates whether bilateral filtering is enabled.
   */
  get bilateral() {
    return this.defines.BILATERAL !== void 0;
  }
  set bilateral(value) {
    if (value !== null) {
      this.defines.BILATERAL = true;
    } else {
      delete this.defines.BILATERAL;
    }
    this.needsUpdate = true;
  }
  /**
   * The bilateral filter distance threshold in world units.
   */
  get worldDistanceThreshold() {
    return -orthographicDepthToViewZ(this.defines.DISTANCE_THRESHOLD, this.near, this.far);
  }
  set worldDistanceThreshold(value) {
    const threshold = viewZToOrthographicDepth(-value, this.near, this.far);
    this.defines.DISTANCE_THRESHOLD = threshold;
    this.needsUpdate = true;
  }
};

// src/materials/CircleOfConfusionMaterial.ts
import { Uniform as Uniform9 } from "three";

// src/materials/shaders/circle-of-confusion.frag
var circle_of_confusion_default = "#include <pp_precision_fragment>\n#include <common>\n#include <pp_camera_pars_fragment>\n#include <pp_default_output_pars_fragment>\n#include <pp_depth_buffer_pars_fragment>\n#include <pp_depth_utils_pars_fragment>\nuniform float focusDistance;uniform float focusRange;in vec2 vUv;void main(){float depth=readDepth(vUv);\n#ifdef PERSPECTIVE_CAMERA\nfloat viewZ=perspectiveDepthToViewZ(depth,cameraParams.x,cameraParams.y);depth=viewZToOrthographicDepth(viewZ,cameraParams.x,cameraParams.y);\n#endif\nfloat signedDistance=depth-focusDistance;float magnitude=smoothstep(0.0,focusRange,abs(signedDistance));outputColor.rg=magnitude*vec2(step(signedDistance,0.0),step(0.0,signedDistance));}";

// src/materials/CircleOfConfusionMaterial.ts
var CircleOfConfusionMaterial = class extends FullscreenMaterial {
  /**
   * Constructs a new circle of confusion material.
   */
  constructor() {
    super({
      name: "CircleOfConfusionMaterial",
      fragmentShader: circle_of_confusion_default,
      vertexShader: common_default,
      uniforms: {
        depthBuffer: new Uniform9(null),
        focusDistance: new Uniform9(0),
        focusRange: new Uniform9(0)
      }
    });
  }
  /**
   * The depth buffer.
   */
  set depthBuffer(value) {
    this.uniforms.depthBuffer.value = value;
  }
  /**
   * The focus distance. Range: [0.0, 1.0].
   */
  get focusDistance() {
    return this.uniforms.focusDistance.value;
  }
  set focusDistance(value) {
    this.uniforms.focusDistance.value = value;
  }
  /**
   * The focus distance in world units.
   */
  get worldFocusDistance() {
    return -orthographicDepthToViewZ(this.focusDistance, this.near, this.far);
  }
  set worldFocusDistance(value) {
    this.focusDistance = viewZToOrthographicDepth(-value, this.near, this.far);
  }
  /**
   * The focus range. Range: [0.0, 1.0].
   */
  get focusRange() {
    return this.uniforms.focusRange.value;
  }
  set focusRange(value) {
    this.uniforms.focusRange.value = value;
  }
  /**
   * The focus range in world units.
   */
  get worldFocusRange() {
    return -orthographicDepthToViewZ(this.focusRange, this.near, this.far);
  }
  set worldFocusRange(value) {
    this.focusRange = viewZToOrthographicDepth(-value, this.near, this.far);
  }
};

// src/materials/DepthCopyMaterial.ts
import { Uniform as Uniform10, Vector2 as Vector24 } from "three";

// src/materials/shaders/depth-copy.frag
var depth_copy_default = "#include <pp_precision_fragment>\n#include <pp_default_output_pars_fragment>\nin vec2 vUv;\n#ifdef NORMAL_DEPTH\n#ifdef GL_FRAGMENT_PRECISION_HIGH\nuniform highp sampler2D normalDepthBuffer;\n#else\nuniform mediump sampler2D normalDepthBuffer;\n#endif\n#define getDepth(uv) texture(normalDepthBuffer, uv).a\n#else\n#include <pp_depth_buffer_pars_fragment>\n#define getDepth(uv) texture(depthBuffer, uv).r\n#endif\nvoid main(){outputColor=vec4(getDepth(vUv));}";

// src/materials/shaders/depth-copy.vert
var depth_copy_default2 = "out vec2 vUv;\n#if DEPTH_COPY_MODE == 1\nuniform vec2 texelPosition;\n#endif\nvoid main(){\n#if DEPTH_COPY_MODE == 1\nvUv=texelPosition;\n#else\nvUv=position.xy*0.5+0.5;\n#endif\ngl_Position=vec4(position.xy,1.0,1.0);}";

// src/materials/DepthCopyMaterial.ts
var DepthCopyMaterial = class extends FullscreenMaterial {
  /**
   * Constructs a new depth copy material.
   */
  constructor() {
    super({
      name: "DepthCopyMaterial",
      fragmentShader: depth_copy_default,
      vertexShader: depth_copy_default2,
      defines: {
        DEPTH_COPY_MODE: 0 /* FULL */
      },
      uniforms: {
        depthBuffer: new Uniform10(null),
        texelPosition: new Uniform10(new Vector24())
      }
    });
  }
  /**
   * The input depth buffer.
   */
  get depthBuffer() {
    return this.uniforms.depthBuffer.value;
  }
  set depthBuffer(value) {
    this.uniforms.depthBuffer.value = value;
  }
  /**
   * The screen space position used for single-texel copy operations.
   */
  get texelPosition() {
    return this.uniforms.texelPosition.value;
  }
  /**
   * The current depth copy mode.
   */
  get mode() {
    return this.defines.DEPTH_COPY_MODE;
  }
  set mode(value) {
    this.defines.DEPTH_COPY_MODE = value;
    this.needsUpdate = true;
  }
};

// src/materials/DepthDownsamplingMaterial.ts
import { Uniform as Uniform11 } from "three";

// src/materials/shaders/depth-downsampling.frag
var depth_downsampling_default = "#include <pp_precision_fragment>\n#include <pp_default_output_pars_fragment>\n#include <pp_depth_buffer_pars_fragment>\n#include <pp_depth_utils_pars_fragment>\n#include <packing>\n#ifdef DOWNSAMPLE_NORMALS\nuniform mediump sampler2D normalBuffer;\n#endif\nin vec2 vUv0,vUv1,vUv2,vUv3;int findBestDepth(const in float samples[4]){float c=(samples[0]+samples[1]+samples[2]+samples[3])*0.25;float distances[4];distances[0]=abs(c-samples[0]);distances[1]=abs(c-samples[1]);distances[2]=abs(c-samples[2]);distances[3]=abs(c-samples[3]);float maxDistance=max(max(distances[0],distances[1]),max(distances[2],distances[3]));int remaining[3];int rejected[3];int i,j,k;for(i=0,j=0,k=0;i<4;++i){if(distances[i]<maxDistance){remaining[j++]=i;}else{rejected[k++]=i;}}for(;j<3;++j){remaining[j]=rejected[--k];}vec3 s=vec3(samples[remaining[0]],samples[remaining[1]],samples[remaining[2]]);c=(s.x+s.y+s.z)/3.0;distances[0]=abs(c-s.x);distances[1]=abs(c-s.y);distances[2]=abs(c-s.z);float minDistance=min(distances[0],min(distances[1],distances[2]));for(i=0;i<3;++i){if(distances[i]==minDistance){break;}}return remaining[i];}void main(){float d[4];d[0]=readDepth(vUv0);d[1]=readDepth(vUv1);d[2]=readDepth(vUv2);d[3]=readDepth(vUv3);int index=findBestDepth(d);\n#ifdef DOWNSAMPLE_NORMALS\nvec3 n[4];n[0]=texture(normalBuffer,vUv0).rgb;n[1]=texture(normalBuffer,vUv1).rgb;n[2]=texture(normalBuffer,vUv2).rgb;n[3]=texture(normalBuffer,vUv3).rgb;\n#else\nvec3 n[4];n[0]=vec3(0.0);n[1]=vec3(0.0);n[2]=vec3(0.0);n[3]=vec3(0.0);\n#endif\noutputColor=vec4(n[index],d[index]);}";

// src/materials/shaders/depth-downsampling.vert
var depth_downsampling_default2 = "#include <pp_resolution_pars_fragment>\nout vec2 vUv0,vUv1,vUv2,vUv3;void main(){vec2 uv=position.xy*0.5+0.5;vUv0=uv;vUv1=vec2(uv.x,uv.y+resolution.w);vUv2=vec2(uv.x+resolution.z,uv.y);vUv3=uv+resolution.zw;gl_Position=vec4(position.xy,1.0,1.0);}";

// src/materials/DepthDownsamplingMaterial.ts
var DepthDownsamplingMaterial = class extends FullscreenMaterial {
  /**
   * Constructs a new depth downsampling material.
   */
  constructor() {
    super({
      name: "DepthDownsamplingMaterial",
      fragmentShader: depth_downsampling_default,
      vertexShader: depth_downsampling_default2,
      uniforms: {
        depthBuffer: new Uniform11(null),
        normalBuffer: new Uniform11(null)
      }
    });
  }
  /**
   * The depth buffer.
   */
  set depthBuffer(value) {
    this.uniforms.depthBuffer.value = value;
  }
  /**
   * The normal buffer.
   */
  set normalBuffer(value) {
    this.uniforms.normalBuffer.value = value;
    if (value !== null) {
      this.defines.DOWNSAMPLE_NORMALS = true;
    } else {
      delete this.defines.DOWNSAMPLE_NORMALS;
    }
    this.needsUpdate = true;
  }
};

// src/materials/shaders/convolution.downsampling.frag
var convolution_downsampling_default = "#include <pp_precision_fragment>\n#include <pp_default_output_pars_fragment>\n#include <pp_input_buffer_pars_fragment>\n#define WEIGHT_INNER 0.125\n#define WEIGHT_OUTER 0.0555555\nin vec2 vUv;in vec2 vUv00,vUv01,vUv02,vUv03;in vec2 vUv04,vUv05,vUv06,vUv07;in vec2 vUv08,vUv09,vUv10,vUv11;float clampToBorder(const in vec2 uv){return float(uv.s>=0.0&&uv.s<=1.0&&uv.t>=0.0&&uv.t<=1.0);}void main(){vec4 c=vec4(0.0);vec4 w=WEIGHT_INNER*vec4(clampToBorder(vUv00),clampToBorder(vUv01),clampToBorder(vUv02),clampToBorder(vUv03));c+=w.x*texture(inputBuffer,vUv00);c+=w.y*texture(inputBuffer,vUv01);c+=w.z*texture(inputBuffer,vUv02);c+=w.w*texture(inputBuffer,vUv03);w=WEIGHT_OUTER*vec4(clampToBorder(vUv04),clampToBorder(vUv05),clampToBorder(vUv06),clampToBorder(vUv07));c+=w.x*texture(inputBuffer,vUv04);c+=w.y*texture(inputBuffer,vUv05);c+=w.z*texture(inputBuffer,vUv06);c+=w.w*texture(inputBuffer,vUv07);w=WEIGHT_OUTER*vec4(clampToBorder(vUv08),clampToBorder(vUv09),clampToBorder(vUv10),clampToBorder(vUv11));c+=w.x*texture(inputBuffer,vUv08);c+=w.y*texture(inputBuffer,vUv09);c+=w.z*texture(inputBuffer,vUv10);c+=w.w*texture(inputBuffer,vUv11);c+=WEIGHT_OUTER*texture(inputBuffer,vUv);outputColor=c;}";

// src/materials/shaders/convolution.downsampling.vert
var convolution_downsampling_default2 = "#include <pp_resolution_pars_fragment>\nout vec2 vUv;out vec2 vUv00,vUv01,vUv02,vUv03;out vec2 vUv04,vUv05,vUv06,vUv07;out vec2 vUv08,vUv09,vUv10,vUv11;void main(){vUv=position.xy*0.5+0.5;vUv00=vUv+resolution.zw*vec2(-1.0,1.0);vUv01=vUv+resolution.zw*vec2(1.0,1.0);vUv02=vUv+resolution.zw*vec2(-1.0,-1.0);vUv03=vUv+resolution.zw*vec2(1.0,-1.0);vUv04=vUv+resolution.zw*vec2(-2.0,2.0);vUv05=vUv+resolution.zw*vec2(0.0,2.0);vUv06=vUv+resolution.zw*vec2(2.0,2.0);vUv07=vUv+resolution.zw*vec2(-2.0,0.0);vUv08=vUv+resolution.zw*vec2(2.0,0.0);vUv09=vUv+resolution.zw*vec2(-2.0,-2.0);vUv10=vUv+resolution.zw*vec2(0.0,-2.0);vUv11=vUv+resolution.zw*vec2(2.0,-2.0);gl_Position=vec4(position.xy,1.0,1.0);}";

// src/materials/DownsamplingMaterial.ts
var DownsamplingMaterial = class extends FullscreenMaterial {
  /**
   * Constructs a new downsampling material.
   */
  constructor() {
    super({
      name: "DownsamplingMaterial",
      fragmentShader: convolution_downsampling_default,
      vertexShader: convolution_downsampling_default2
    });
  }
};

// src/materials/EdgeDetectionMaterial.ts
import { Uniform as Uniform12, UnsignedByteType as UnsignedByteType4 } from "three";

// src/materials/shaders/edge-detection.frag
var edge_detection_default = "#include <pp_precision_fragment>\n#include <pp_default_output_pars_fragment>\nin vec2 vUv;in vec2 vUv0;in vec2 vUv1;\n#if EDGE_DETECTION_MODE != 0\nin vec2 vUv2,vUv3,vUv4,vUv5;\n#endif\n#if EDGE_DETECTION_MODE == 1\n#include <common>\n#endif\n#if EDGE_DETECTION_MODE == 0 || PREDICATION_MODE == 1\n#include <pp_depth_buffer_pars_fragment>\n#include <pp_depth_utils_pars_fragment>\n#include <packing>\nfloat getOrthographicDepth(sampler2D depthBuffer,const in vec2 uv,const in float near,const in float far){float depth=readDepth(depthBuffer,uv);\n#ifdef PERSPECTIVE_CAMERA\nfloat viewZ=perspectiveDepthToViewZ(depth,near,far);return viewZToOrthographicDepth(viewZ,near,far);\n#else\nreturn depth;\n#endif\n}uniform vec2 cameraParams;vec3 gatherNeighbors(){float p=getOrthographicDepth(depthBuffer,vUv,cameraParams.x,cameraParams.y);float pLeft=getOrthographicDepth(depthBuffer,vUv0,cameraParams.x,cameraParams.y);float pTop=getOrthographicDepth(depthBuffer,vUv1,cameraParams.x,cameraParams.y);return vec3(p,pLeft,pTop);}\n#elif PREDICATION_MODE == 2\n#ifdef PREDICATIONBUFFER_PRECISION_HIGH\nuniform mediump sampler2D predicationBuffer;\n#else\nuniform lowp sampler2D predicationBuffer;\n#endif\nvec3 gatherNeighbors(){float p=texture(predicationBuffer,vUv).r;float pLeft=texture(predicationBuffer,vUv0).r;float pTop=texture(predicationBuffer,vUv1).r;return vec3(p,pLeft,pTop);}\n#endif\n#if PREDICATION_MODE != 0\nvec2 calculatePredicatedThreshold(){vec3 neighbours=gatherNeighbors();vec2 delta=abs(neighbours.xx-neighbours.yz);vec2 edges=step(PREDICATION_THRESHOLD,delta);return PREDICATION_SCALE*EDGE_THRESHOLD*(1.0-PREDICATION_STRENGTH*edges);}\n#endif\n#if EDGE_DETECTION_MODE != 0\n#include <pp_input_buffer_pars_fragment>\n#endif\nvoid main(){\n#if EDGE_DETECTION_MODE == 0\nconst vec2 threshold=vec2(DEPTH_THRESHOLD);\n#elif PREDICATION_MODE != 0\nvec2 threshold=calculatePredicatedThreshold();\n#else\nconst vec2 threshold=vec2(EDGE_THRESHOLD);\n#endif\n#if EDGE_DETECTION_MODE == 0\nvec3 neighbors=gatherNeighbors();vec2 delta=abs(neighbors.xx-vec2(neighbors.y,neighbors.z));vec2 edges=step(threshold,delta);if(dot(edges,vec2(1.0))==0.0){discard;}outputColor=vec4(edges,0.0,1.0);\n#elif EDGE_DETECTION_MODE == 1\nfloat l=luminance(texture(inputBuffer,vUv).rgb);float lLeft=luminance(texture(inputBuffer,vUv0).rgb);float lTop=luminance(texture(inputBuffer,vUv1).rgb);vec4 delta;delta.xy=abs(l-vec2(lLeft,lTop));vec2 edges=step(threshold,delta.xy);if(dot(edges,vec2(1.0))==0.0){discard;}float lRight=luminance(texture(inputBuffer,vUv2).rgb);float lBottom=luminance(texture(inputBuffer,vUv3).rgb);delta.zw=abs(l-vec2(lRight,lBottom));vec2 maxDelta=max(delta.xy,delta.zw);float lLeftLeft=luminance(texture(inputBuffer,vUv4).rgb);float lTopTop=luminance(texture(inputBuffer,vUv5).rgb);delta.zw=abs(vec2(lLeft,lTop)-vec2(lLeftLeft,lTopTop));maxDelta=max(maxDelta.xy,delta.zw);float finalDelta=max(maxDelta.x,maxDelta.y);edges.xy*=step(finalDelta,LOCAL_CONTRAST_ADAPTATION_FACTOR*delta.xy);outputColor=vec4(edges,0.0,1.0);\n#elif EDGE_DETECTION_MODE == 2\nvec4 delta;vec3 c=texture(inputBuffer,vUv).rgb;vec3 cLeft=texture(inputBuffer,vUv0).rgb;vec3 t=abs(c-cLeft);delta.x=max(max(t.r,t.g),t.b);vec3 cTop=texture(inputBuffer,vUv1).rgb;t=abs(c-cTop);delta.y=max(max(t.r,t.g),t.b);vec2 edges=step(threshold,delta.xy);if(dot(edges,vec2(1.0))==0.0){discard;}vec3 cRight=texture(inputBuffer,vUv2).rgb;t=abs(c-cRight);delta.z=max(max(t.r,t.g),t.b);vec3 cBottom=texture(inputBuffer,vUv3).rgb;t=abs(c-cBottom);delta.w=max(max(t.r,t.g),t.b);vec2 maxDelta=max(delta.xy,delta.zw);vec3 cLeftLeft=texture(inputBuffer,vUv4).rgb;t=abs(c-cLeftLeft);delta.z=max(max(t.r,t.g),t.b);vec3 cTopTop=texture(inputBuffer,vUv5).rgb;t=abs(c-cTopTop);delta.w=max(max(t.r,t.g),t.b);maxDelta=max(maxDelta.xy,delta.zw);float finalDelta=max(maxDelta.x,maxDelta.y);edges*=step(finalDelta,LOCAL_CONTRAST_ADAPTATION_FACTOR*delta.xy);outputColor=vec4(edges,0.0,1.0);\n#endif\n}";

// src/materials/shaders/edge-detection.vert
var edge_detection_default2 = "#include <pp_resolution_pars_fragment>\nout vec2 vUv;out vec2 vUv0;out vec2 vUv1;\n#if EDGE_DETECTION_MODE != 0\nout vec2 vUv2,vUv3,vUv4,vUv5;\n#endif\nvoid main(){vUv=position.xy*0.5+0.5;vUv0=vUv+resolution.zw*vec2(-1.0,0.0);vUv1=vUv+resolution.zw*vec2(0.0,-1.0);\n#if EDGE_DETECTION_MODE != 0\nvUv2=vUv+resolution.zw*vec2(1.0,0.0);vUv3=vUv+resolution.zw*vec2(0.0,1.0);vUv4=vUv+resolution.zw*vec2(-2.0,0.0);vUv5=vUv+resolution.zw*vec2(0.0,-2.0);\n#endif\ngl_Position=vec4(position.xy,1.0,1.0);}";

// src/materials/EdgeDetectionMaterial.ts
var EdgeDetectionMaterial = class extends FullscreenMaterial {
  /**
   * Constructs a new edge detection material.
   */
  constructor() {
    super({
      name: "EdgeDetectionMaterial",
      fragmentShader: edge_detection_default,
      vertexShader: edge_detection_default2,
      defines: {
        LOCAL_CONTRAST_ADAPTATION_FACTOR: 2,
        EDGE_DETECTION_MODE: 2 /* COLOR */,
        EDGE_THRESHOLD: 0.1,
        DEPTH_THRESHOLD: 0.01,
        PREDICATION_MODE: 0 /* DISABLED */,
        PREDICATION_THRESHOLD: 0.01,
        PREDICATION_SCALE: 2,
        PREDICATION_STRENGTH: 1
      },
      uniforms: {
        depthBuffer: new Uniform12(null),
        predicationBuffer: new Uniform12(null)
      }
    });
  }
  /**
   * The depth buffer.
   */
  set depthBuffer(value) {
    this.uniforms.depthBuffer.value = value;
  }
  /**
   * The edge detection mode.
   */
  get edgeDetectionMode() {
    return this.defines.EDGE_DETECTION_MODE;
  }
  set edgeDetectionMode(value) {
    this.defines.EDGE_DETECTION_MODE = value;
    this.needsUpdate = true;
  }
  /**
   * The local contrast adaptation factor. Has no effect if the edge detection mode is set to DEPTH. Default is `2.0`.
   *
   * If a neighbor edge has _factor_ times bigger contrast than the current edge, the edge will be discarded.
   *
   * This allows to eliminate spurious crossing edges and is based on the fact that if there is too much contrast in a
   * direction, the perceptual contrast in the other neighbors will be hidden.
   */
  get localContrastAdaptationFactor() {
    return this.defines.LOCAL_CONTRAST_ADAPTATION_FACTOR;
  }
  set localContrastAdaptationFactor(value) {
    this.defines.LOCAL_CONTRAST_ADAPTATION_FACTOR = value;
    this.needsUpdate = true;
  }
  /**
   * The edge detection threshold. Range: [0.0, 0.5].
   *
   * A lower value results in more edges being detected at the expense of performance.
   *
   * For luma- and chroma-based edge detection, 0.1 is a reasonable value and allows to catch most visible edges. 0.05
   * is a rather overkill value that allows to catch 'em all. Darker scenes may require an even lower threshold.
   *
   * If depth-based edge detection is used, the threshold will depend on the scene depth.
   */
  get edgeDetectionThreshold() {
    return this.defines.EDGE_THRESHOLD;
  }
  set edgeDetectionThreshold(value) {
    this.defines.EDGE_THRESHOLD = value;
    this.defines.DEPTH_THRESHOLD = value * 0.1;
    this.needsUpdate = true;
  }
  /**
   * The predication mode.
   *
   * Predicated thresholding allows to better preserve texture details and to improve edge detection using an additional
   * buffer such as a light accumulation or depth buffer.
   */
  get predicationMode() {
    return this.defines.PREDICATION_MODE;
  }
  set predicationMode(value) {
    this.defines.PREDICATION_MODE = value;
    this.needsUpdate = true;
  }
  /**
   * Indicates whether the predication buffer uses high precision.
   */
  get predicationBufferPrecisionHigh() {
    return this.defines.PREDICATIONBUFFER_PRECISION_HIGH !== void 0;
  }
  set predicationBufferPrecisionHigh(value) {
    if (this.predicationBufferPrecisionHigh !== value) {
      if (value) {
        this.defines.PREDICATIONBUFFER_PRECISION_HIGH = true;
      } else {
        delete this.defines.PREDICATIONBUFFER_PRECISION_HIGH;
      }
      this.needsUpdate = true;
    }
  }
  /**
   * The predication buffer.
   *
   * If this buffer uses high precision, the macro `PREDICATIONBUFFER_PRECISION_HIGH` will be defined.
   */
  set predicationBuffer(value) {
    this.predicationBufferPrecisionHigh = value !== null && value.type !== UnsignedByteType4;
    this.uniforms.predicationBuffer.value = value;
  }
  /**
   * The predication threshold.
   *
   * @type {Number}
   */
  get predicationThreshold() {
    return this.defines.PREDICATION_THRESHOLD;
  }
  set predicationThreshold(value) {
    this.defines.PREDICATION_THRESHOLD = value;
    this.needsUpdate = true;
  }
  /**
   * The predication scale. Range: [1.0, 5.0].
   *
   * Determines how much the edge detection threshold should be scaled when using predication.
   */
  get predicationScale() {
    return this.defines.PREDICATION_SCALE;
  }
  set predicationScale(value) {
    this.defines.PREDICATION_SCALE = value;
    this.needsUpdate = true;
  }
  /**
   * The predication strength. Range: [0.0, 1.0].
   *
   * Determines how much the edge detection threshold should be decreased locally when using predication.
   */
  get predicationStrength() {
    return this.defines.PREDICATION_STRENGTH;
  }
  set predicationStrength(value) {
    this.defines.PREDICATION_STRENGTH = value;
    this.needsUpdate = true;
  }
};

// src/materials/EffectMaterial.ts
import { Uniform as Uniform13 } from "three";

// src/materials/shaders/effect.frag
var effect_default = "#include <pp_precision_fragment>\n#include <common>\n#include <colorspace_pars_fragment>\n#include <dithering_pars_fragment>\n#include <packing>\n#include <pp_camera_pars_fragment>\n#include <pp_colorspace_pars_fragment>\n#include <pp_colorspace_conversion_pars_fragment>\n#include <pp_default_output_pars_fragment>\n#include <pp_depth_precision_pars_fragment>\n#include <pp_depth_utils_pars_fragment>\n#include <pp_frame_buffer_precision_pars_fragment>\n#include <pp_input_buffer_pars_fragment>\n#include <pp_resolution_pars_fragment>\n#define packFloatToRGBA(v) packDepthToRGBA(v)\n#define unpackRGBAToFloat(v) unpackRGBAToDepth(v)\n$FRAGMENT_HEAD_GDATA$FRAGMENT_HEAD_GBUFFER uniform GBuffer gBuffer;uniform float time;in vec2 vUv;$FRAGMENT_HEAD_EFFECTS void main(){$FRAGMENT_MAIN_UV$FRAGMENT_MAIN_GDATA vec4 color0=gData.color;vec4 color1=vec4(0.0);$FRAGMENT_MAIN_IMAGE color0.a=clamp(color0.a,0.0,1.0);outputColor=color0;\n#ifdef COLOR_SPACE_CONVERSION\n#include <colorspace_fragment>\n#endif\n#include <dithering_fragment>\n}";

// src/materials/shaders/effect.vert
var effect_default2 = "#include <pp_camera_pars_fragment>\n#include <pp_resolution_pars_fragment>\nuniform float time;in vec3 position;out vec2 vUv;$VERTEX_HEAD void main(){vUv=position.xy*0.5+0.5;$VERTEX_MAIN_SUPPORT gl_Position=vec4(position.xy,1.0,1.0);}";

// src/materials/EffectMaterial.ts
var EffectMaterial = class extends FullscreenMaterial {
  /**
   * Constructs a new effect material.
   */
  constructor() {
    super({
      name: "EffectMaterial",
      defines: {
        COLOR_SPACE_CONVERSION: true
      },
      uniforms: {
        gBuffer: new Uniform13(null),
        time: new Uniform13(0)
      }
    });
  }
  /**
   * The current gBuffer.
   */
  get gBuffer() {
    return this.uniforms.gBuffer.value;
  }
  set gBuffer(value) {
    this.uniforms.gBuffer.value = value;
  }
  /**
   * Indicates whether output color space conversion is enabled.
   */
  get colorSpaceConversion() {
    return this.defines.COLOR_SPACE_CONVERSION !== void 0;
  }
  set colorSpaceConversion(value) {
    if (this.colorSpaceConversion !== value) {
      if (value) {
        this.defines.COLOR_SPACE_CONVERSION = true;
      } else {
        delete this.defines.COLOR_SPACE_CONVERSION;
      }
      this.needsUpdate = true;
    }
  }
  /**
   * The current animation time in seconds.
   */
  get time() {
    return this.uniforms.time.value;
  }
  set time(value) {
    this.uniforms.time.value = value;
  }
  /**
   * Sets the shader parts.
   *
   * @param shaderParts - A collection of shader code snippets. See {@link EffectShaderSection}.
   * @return This material.
   */
  setShaderParts(shaderParts) {
    this.fragmentShader = effect_default.replace("$FRAGMENT_MAIN_IMAGE" /* FRAGMENT_MAIN_IMAGE */, shaderParts.get("$FRAGMENT_MAIN_IMAGE" /* FRAGMENT_MAIN_IMAGE */)).replace("$FRAGMENT_MAIN_GDATA" /* FRAGMENT_MAIN_GDATA */, shaderParts.get("$FRAGMENT_MAIN_GDATA" /* FRAGMENT_MAIN_GDATA */)).replace("$FRAGMENT_MAIN_UV" /* FRAGMENT_MAIN_UV */, shaderParts.get("$FRAGMENT_MAIN_UV" /* FRAGMENT_MAIN_UV */)).replace("$FRAGMENT_HEAD_EFFECTS" /* FRAGMENT_HEAD_EFFECTS */, shaderParts.get("$FRAGMENT_HEAD_EFFECTS" /* FRAGMENT_HEAD_EFFECTS */)).replace("$FRAGMENT_HEAD_GBUFFER" /* FRAGMENT_HEAD_GBUFFER */, shaderParts.get("$FRAGMENT_HEAD_GBUFFER" /* FRAGMENT_HEAD_GBUFFER */)).replace("$FRAGMENT_HEAD_GDATA" /* FRAGMENT_HEAD_GDATA */, shaderParts.get("$FRAGMENT_HEAD_GDATA" /* FRAGMENT_HEAD_GDATA */));
    this.vertexShader = effect_default2.replace("$VERTEX_MAIN_SUPPORT" /* VERTEX_MAIN_SUPPORT */, shaderParts.get("$VERTEX_MAIN_SUPPORT" /* VERTEX_MAIN_SUPPORT */)).replace("$VERTEX_HEAD" /* VERTEX_HEAD */, shaderParts.get("$VERTEX_HEAD" /* VERTEX_HEAD */));
    this.needsUpdate = true;
    return this;
  }
  /**
   * Sets the shader macros.
   *
   * @param defines - A collection of preprocessor macro definitions.
   * @return This material.
   */
  setDefines(defines) {
    for (const entry of defines.entries()) {
      this.defines[entry[0]] = entry[1];
    }
    this.needsUpdate = true;
    return this;
  }
  /**
   * Sets the shader uniforms.
   *
   * @param uniforms - A collection of uniforms.
   * @return This material.
   */
  setUniforms(uniforms) {
    for (const entry of uniforms.entries()) {
      this.uniforms[entry[0]] = entry[1];
    }
    this.needsUpdate = true;
    return this;
  }
};

// src/materials/GaussianBlurMaterial.ts
import { Uniform as Uniform14, Vector2 as Vector25 } from "three";

// src/utils/GaussKernel.ts
function getCoefficients(n) {
  let result;
  if (n < 0) {
    throw new Error(`Invalid index: ${n}`);
  } else if (n === 0) {
    result = new Float64Array(0);
  } else if (n === 1) {
    result = new Float64Array([1]);
  } else {
    let row0 = new Float64Array(n);
    let row1 = new Float64Array(n);
    result = row1;
    for (let y = 1; y <= n; ++y) {
      for (let x = 0; x < y; ++x) {
        row1[x] = x === 0 || x === y - 1 ? 1 : row0[x - 1] + row0[x];
      }
      result = row1;
      row1 = row0;
      row0 = result;
    }
  }
  return result;
}
var GaussKernel = class {
  /**
   * The weights for discrete sampling.
   */
  weights;
  /**
   * The offsets for discrete sampling.
   */
  offsets;
  /**
   * The weights for linear sampling.
   */
  linearWeights;
  /**
   * The offsets for linear sampling.
   */
  linearOffsets;
  /**
   * Constructs a new Gauss kernel.
   *
   * @param kernelSize - The kernel size. Should be an odd number in the range [3, 1020].
   * @param edgeBias - Determines how many edge coefficients should be cut off for increased accuracy.
   */
  constructor(kernelSize, edgeBias = 2) {
    this.generate(kernelSize, edgeBias);
  }
  /**
   * The number of steps for discrete sampling.
   */
  get steps() {
    return this.offsets === null ? 0 : this.offsets.length;
  }
  /**
   * The number of steps for linear sampling.
   */
  get linearSteps() {
    return this.linearOffsets === null ? 0 : this.linearOffsets.length;
  }
  /**
   * Generates the kernel.
   *
   * @param kernelSize - The kernel size.
   * @param edgeBias - The amount of edge coefficients to ignore.
   */
  generate(kernelSize, edgeBias) {
    if (kernelSize < 3 || kernelSize > 1020) {
      throw new Error("The kernel size must be in the range [3, 1020]");
    }
    const n = kernelSize + edgeBias * 2;
    const coefficients = edgeBias > 0 ? getCoefficients(n).slice(edgeBias, -edgeBias) : getCoefficients(n);
    const mid = Math.floor((coefficients.length - 1) / 2);
    const sum = coefficients.reduce((a, b) => a + b, 0);
    const weights = coefficients.slice(mid);
    const offsets = [...Array(mid + 1).keys()];
    const linearWeights = new Float64Array(Math.floor(offsets.length / 2));
    const linearOffsets = new Float64Array(linearWeights.length);
    linearWeights[0] = weights[0] / sum;
    for (let i = 1, j = 1, l = offsets.length - 1; i < l; i += 2, ++j) {
      const offset0 = offsets[i], offset1 = offsets[i + 1];
      const weight0 = weights[i], weight1 = weights[i + 1];
      const w = weight0 + weight1;
      const o = (offset0 * weight0 + offset1 * weight1) / w;
      linearWeights[j] = w / sum;
      linearOffsets[j] = o;
    }
    for (let i = 0, l = weights.length, s = 1 / sum; i < l; ++i) {
      weights[i] *= s;
    }
    const linearWeightSum = (linearWeights.reduce((a, b) => a + b, 0) - linearWeights[0] * 0.5) * 2;
    if (linearWeightSum !== 0) {
      for (let i = 0, l = linearWeights.length, s = 1 / linearWeightSum; i < l; ++i) {
        linearWeights[i] *= s;
      }
    }
    this.weights = weights;
    this.offsets = new Float64Array(offsets);
    this.linearOffsets = linearOffsets;
    this.linearWeights = linearWeights;
  }
};

// src/materials/shaders/convolution.gaussian.frag
var convolution_gaussian_default = "#include <pp_precision_fragment>\n#include <pp_default_output_pars_fragment>\n#include <pp_input_buffer_pars_fragment>\nuniform vec2 kernel[STEPS];in vec2 vOffset;in vec2 vUv;void main(){vec4 result=texture(inputBuffer,vUv)*kernel[0].y;for(int i=1;i<STEPS;++i){vec2 offset=kernel[i].x*vOffset;vec4 c0=texture(inputBuffer,vUv+offset);vec4 c1=texture(inputBuffer,vUv-offset);result+=(c0+c1)*kernel[i].y;}outputColor=result;}";

// src/materials/shaders/convolution.gaussian.vert
var convolution_gaussian_default2 = "#include <pp_resolution_pars_fragment>\nuniform vec2 direction;uniform float scale;out vec2 vOffset;out vec2 vUv;void main(){vOffset=direction*resolution.zw*scale;vUv=position.xy*0.5+0.5;gl_Position=vec4(position.xy,1.0,1.0);}";

// src/materials/GaussianBlurMaterial.ts
var GaussianBlurMaterial = class extends FullscreenMaterial {
  /**
   * @see kernelSize
   */
  _kernelSize;
  /**
   * Constructs a new blur material.
   *
   * @param options - The options.
   */
  constructor({ kernelSize = 35 } = {}) {
    super({
      name: "GaussianBlurMaterial",
      fragmentShader: convolution_gaussian_default,
      vertexShader: convolution_gaussian_default2,
      defines: {
        STEPS: 0
      },
      uniforms: {
        direction: new Uniform14(new Vector25()),
        kernel: new Uniform14(null),
        scale: new Uniform14(1)
      }
    });
    this._kernelSize = 0;
    this.kernelSize = kernelSize;
  }
  /**
   * The kernel size.
   */
  get kernelSize() {
    return this._kernelSize;
  }
  set kernelSize(value) {
    this._kernelSize = value;
    this.generateKernel(value);
  }
  /**
   * The blur direction.
   */
  get direction() {
    return this.uniforms.direction.value;
  }
  /**
   * The blur kernel scale. Values greater than 1.0 may introduce artifacts.
   */
  get scale() {
    return this.uniforms.scale.value;
  }
  set scale(value) {
    this.uniforms.scale.value = value;
  }
  /**
   * Generates the Gauss kernel.
   *
   * @param kernelSize - The kernel size.
   */
  generateKernel(kernelSize) {
    const kernel = new GaussKernel(kernelSize);
    const steps = kernel.linearSteps;
    const kernelData = new Float64Array(steps * 2);
    for (let i = 0, j = 0; i < steps; ++i) {
      kernelData[j++] = kernel.linearOffsets[i];
      kernelData[j++] = kernel.linearWeights[i];
    }
    this.uniforms.kernel.value = kernelData;
    this.defines.STEPS = steps;
    this.needsUpdate = true;
  }
};

// src/materials/KawaseBlurMaterial.ts
import { Uniform as Uniform15 } from "three";

// src/materials/shaders/convolution.kawase.frag
var convolution_kawase_default = "#include <pp_precision_fragment>\n#include <pp_default_output_pars_fragment>\n#include <pp_input_buffer_pars_fragment>\nin vec2 vUv0,vUv1,vUv2,vUv3;void main(){vec4 sum=texture(inputBuffer,vUv0);sum+=texture(inputBuffer,vUv1);sum+=texture(inputBuffer,vUv2);sum+=texture(inputBuffer,vUv3);outputColor=sum*0.25;}";

// src/materials/shaders/convolution.kawase.vert
var convolution_kawase_default2 = "#include <pp_resolution_pars_fragment>\nuniform float kernel;uniform float scale;out vec2 vUv0,vUv1,vUv2,vUv3;void main(){vec2 uv=position.xy*0.5+0.5;vec2 dUv=(texelSize.zw*vec2(kernel)+texelSize.zw*vec2(0.5))*scale;vUv0=vec2(uv.x-dUv.x,uv.y+dUv.y);vUv1=vec2(uv.x+dUv.x,uv.y+dUv.y);vUv2=vec2(uv.x+dUv.x,uv.y-dUv.y);vUv3=vec2(uv.x-dUv.x,uv.y-dUv.y);gl_Position=vec4(position.xy,1.0,1.0);}";

// src/materials/KawaseBlurMaterial.ts
var kernelPresets = [
  new Float32Array([0, 0]),
  new Float32Array([0, 1, 1]),
  new Float32Array([0, 1, 1, 2]),
  new Float32Array([0, 1, 2, 2, 3]),
  new Float32Array([0, 1, 2, 3, 4, 4, 5]),
  new Float32Array([0, 1, 2, 3, 4, 5, 7, 8, 9, 10])
];
var KawaseBlurMaterial = class extends FullscreenMaterial {
  /**
   * The kernel size.
   */
  kernelSize;
  /**
   * Constructs a new blur material.
   */
  constructor() {
    super({
      name: "KawaseBlurMaterial",
      fragmentShader: convolution_kawase_default,
      vertexShader: convolution_kawase_default2,
      uniforms: {
        scale: new Uniform15(1),
        kernel: new Uniform15(0)
      }
    });
    this.kernelSize = 2 /* MEDIUM */;
  }
  /**
   * The kernel sequence for the current kernel size. Can be used to configure the {@link kernel}.
   */
  get kernelSequence() {
    return kernelPresets[this.kernelSize];
  }
  /**
   * The blur scale.
   */
  get scale() {
    return this.uniforms.scale.value;
  }
  set scale(value) {
    this.uniforms.scale.value = value;
  }
  /**
   * The current kernel. Can be configured using the {@link kernelSequence}.
   */
  get kernel() {
    return this.uniforms.kernel.value;
  }
  set kernel(value) {
    this.uniforms.kernel.value = value;
  }
};

// src/materials/LuminanceMaterial.ts
import { Uniform as Uniform16 } from "three";

// src/materials/shaders/luminance.frag
var luminance_default = "#include <pp_precision_fragment>\n#include <common>\n#include <pp_default_output_pars_fragment>\n#include <pp_input_buffer_pars_fragment>\n#ifdef THRESHOLD\nuniform float threshold;uniform float smoothing;\n#endif\nin vec2 vUv;void main(){vec4 texel=texture(inputBuffer,vUv);float l=luminance(texel.rgb);\n#ifdef THRESHOLD\nl=smoothstep(threshold,threshold+smoothing,l);\n#endif\n#ifdef COLOR\noutputColor=vec4(texel.rgb*l,l);\n#else\noutputColor=vec4(l);\n#endif\n}";

// src/materials/LuminanceMaterial.ts
var LuminanceMaterial = class extends FullscreenMaterial {
  /**
   * Constructs a new luminance material.
   */
  constructor() {
    super({
      name: "LuminanceMaterial",
      fragmentShader: luminance_default,
      vertexShader: common_default,
      uniforms: {
        threshold: new Uniform16(0),
        smoothing: new Uniform16(0)
      }
    });
  }
  /**
   * The luminance threshold.
   */
  get threshold() {
    return this.uniforms.threshold.value;
  }
  set threshold(value) {
    if (this.smoothing > 0 || value > 0) {
      this.defines.THRESHOLD = true;
    } else {
      delete this.defines.THRESHOLD;
    }
    this.uniforms.threshold.value = value;
  }
  /**
   * The luminance smoothing.
   */
  get smoothing() {
    return this.uniforms.smoothing.value;
  }
  set smoothing(value) {
    if (this.threshold > 0 || value > 0) {
      this.defines.THRESHOLD = true;
    } else {
      delete this.defines.THRESHOLD;
    }
    this.uniforms.smoothing.value = value;
  }
  /**
   * Indicates whether color output is enabled.
   */
  get colorOutput() {
    return this.defines.COLOR !== void 0;
  }
  set colorOutput(value) {
    if (value) {
      this.defines.COLOR = true;
    } else {
      delete this.defines.COLOR;
    }
    this.needsUpdate = true;
  }
};

// src/materials/MaskMaterial.ts
import { Uniform as Uniform17, UnsignedByteType as UnsignedByteType5 } from "three";

// src/materials/shaders/mask.frag
var mask_default = "#include <pp_precision_fragment>\n#include <pp_default_output_pars_fragment>\n#include <pp_input_buffer_pars_fragment>\n#ifdef MASK_PRECISION_HIGH\nuniform mediump sampler2D maskTexture;\n#else\nuniform lowp sampler2D maskTexture;\n#endif\n#if MASK_FUNCTION != 0\nuniform float strength;\n#endif\nin vec2 vUv;void main(){\n#if COLOR_CHANNEL == 0\nfloat mask=texture(maskTexture,vUv).r;\n#elif COLOR_CHANNEL == 1\nfloat mask=texture(maskTexture,vUv).g;\n#elif COLOR_CHANNEL == 2\nfloat mask=texture(maskTexture,vUv).b;\n#else\nfloat mask=texture(maskTexture,vUv).a;\n#endif\n#if MASK_FUNCTION == 0\n#ifdef INVERTED\nmask=step(mask,0.0);\n#else\nmask=1.0-step(mask,0.0);\n#endif\n#else\nmask=clamp(mask*strength,0.0,1.0);\n#ifdef INVERTED\nmask=1.0-mask;\n#endif\n#endif\n#if MASK_FUNCTION == 3\nvec4 texel=texture(inputBuffer,vUv);outputColor=vec4(mask*texel.rgb,texel.a);\n#elif MASK_FUNCTION == 2\noutputColor=vec4(mask*texture(inputBuffer,vUv).rgb,mask);\n#else\noutputColor=mask*texture(inputBuffer,vUv);\n#endif\n}";

// src/materials/MaskMaterial.ts
var MaskMaterial = class extends FullscreenMaterial {
  /**
   * Constructs a new mask material.
   *
   * @param maskTexture - A mask texture.
   */
  constructor(maskTexture = null) {
    super({
      name: "MaskMaterial",
      fragmentShader: mask_default,
      vertexShader: common_default,
      defines: {
        COLOR_CHANNEL: 0 /* RED */,
        MASK_FUNCTION: 0 /* DISCARD */
      },
      uniforms: {
        maskTexture: new Uniform17(maskTexture),
        strength: new Uniform17(1)
      }
    });
  }
  /**
   * The mask texture.
   */
  set maskTexture(value) {
    this.uniforms.maskTexture.value = value;
    delete this.defines.MASK_PRECISION_HIGH;
    if (value?.type !== UnsignedByteType5) {
      this.defines.MASK_PRECISION_HIGH = true;
    }
    this.needsUpdate = true;
  }
  /**
   * The color channel to use for masking. Default is `ColorChannel.RED`.
   */
  get colorChannel() {
    return this.defines.COLOR_CHANNEL;
  }
  set colorChannel(value) {
    this.defines.COLOR_CHANNEL = value;
    this.needsUpdate = true;
  }
  /**
   * The masking technique. Default is `MaskFunction.DISCARD`.
   */
  get maskFunction() {
    return this.defines.MASK_FUNCTION;
  }
  set maskFunction(value) {
    this.defines.MASK_FUNCTION = value;
    this.needsUpdate = true;
  }
  /**
   * Indicates whether the masking is inverted.
   */
  get inverted() {
    return this.defines.INVERTED !== void 0;
  }
  set inverted(value) {
    if (this.inverted && !value) {
      delete this.defines.INVERTED;
    } else if (value) {
      this.defines.INVERTED = true;
    }
    this.needsUpdate = true;
  }
  /**
   * The current mask strength.
   *
   * Individual mask values will be clamped to [0.0, 1.0]. Has no effect when the mask function is set to `DISCARD`.
   *
   * @type {Number}
   */
  get strength() {
    return this.uniforms.strength.value;
  }
  set strength(value) {
    this.uniforms.strength.value = value;
  }
};

// src/materials/SMAAWeightsMaterial.ts
import { Uniform as Uniform18 } from "three";

// src/materials/shaders/smaa-weights.frag
var smaa_weights_default = "#include <pp_precision_fragment>\n#include <pp_default_output_pars_fragment>\n#include <pp_input_buffer_pars_fragment>\n#define sampleLevelZeroOffset(t, coord, offset) texture(t, coord + offset * resolution.zw)\nuniform lowp sampler2D areaTexture;uniform lowp sampler2D searchTexture;uniform vec4 resolution;in vec2 vUv;in vec4 vOffset[3];in vec2 vPixCoord;void movec(const in bvec2 c,inout vec2 variable,const in vec2 value){if(c.x){variable.x=value.x;}if(c.y){variable.y=value.y;}}void movec(const in bvec4 c,inout vec4 variable,const in vec4 value){movec(c.xy,variable.xy,value.xy);movec(c.zw,variable.zw,value.zw);}vec2 decodeDiagBilinearAccess(in vec2 e){e.r=e.r*abs(5.0*e.r-5.0*0.75);return round(e);}vec4 decodeDiagBilinearAccess(in vec4 e){e.rb=e.rb*abs(5.0*e.rb-5.0*0.75);return round(e);}vec2 searchDiag1(const in vec2 texCoord,const in vec2 dir,out vec2 e){vec4 coord=vec4(texCoord,-1.0,1.0);vec3 t=vec3(resolution.zw,1.0);for(int i=0;i<MAX_SEARCH_STEPS;++i){if(!(coord.z<float(MAX_SEARCH_STEPS_DIAG-1)&&coord.w>0.9)){break;}coord.xyz=t*vec3(dir,1.0)+coord.xyz;e=texture(inputBuffer,coord.xy).rg;coord.w=dot(e,vec2(0.5));}return coord.zw;}vec2 searchDiag2(const in vec2 texCoord,const in vec2 dir,out vec2 e){vec4 coord=vec4(texCoord,-1.0,1.0);coord.x+=0.25*resolution.z;vec3 t=vec3(resolution.zw,1.0);for(int i=0;i<MAX_SEARCH_STEPS;++i){if(!(coord.z<float(MAX_SEARCH_STEPS_DIAG-1)&&coord.w>0.9)){break;}coord.xyz=t*vec3(dir,1.0)+coord.xyz;e=texture(inputBuffer,coord.xy).rg;e=decodeDiagBilinearAccess(e);coord.w=dot(e,vec2(0.5));}return coord.zw;}vec2 areaDiag(const in vec2 dist,const in vec2 e,const in float offset){vec2 texCoord=vec2(AREATEX_MAX_DISTANCE_DIAG,AREATEX_MAX_DISTANCE_DIAG)*e+dist;texCoord=AREATEX_PIXEL_SIZE*texCoord+0.5*AREATEX_PIXEL_SIZE;texCoord.x+=0.5;texCoord.y+=AREATEX_SUBTEX_SIZE*offset;return texture(areaTexture,texCoord).rg;}vec2 calculateDiagWeights(const in vec2 texCoord,const in vec2 e,const in vec4 subsampleIndices){vec2 weights=vec2(0.0);vec4 d;vec2 end;if(e.r>0.0){d.xz=searchDiag1(texCoord,vec2(-1.0,1.0),end);d.x+=float(end.y>0.9);}else{d.xz=vec2(0.0);}d.yw=searchDiag1(texCoord,vec2(1.0,-1.0),end);if(d.x+d.y>2.0){vec4 coords=vec4(-d.x+0.25,d.x,d.y,-d.y-0.25)*resolution.zwzw+texCoord.xyxy;vec4 c;c.xy=sampleLevelZeroOffset(inputBuffer,coords.xy,vec2(-1,0)).rg;c.zw=sampleLevelZeroOffset(inputBuffer,coords.zw,vec2(1,0)).rg;c.yxwz=decodeDiagBilinearAccess(c.xyzw);vec2 cc=vec2(2.0)*c.xz+c.yw;movec(bvec2(step(0.9,d.zw)),cc,vec2(0.0));weights+=areaDiag(d.xy,cc,subsampleIndices.z);}d.xz=searchDiag2(texCoord,vec2(-1.0,-1.0),end);if(sampleLevelZeroOffset(inputBuffer,texCoord,vec2(1,0)).r>0.0){d.yw=searchDiag2(texCoord,vec2(1.0),end);d.y+=float(end.y>0.9);}else{d.yw=vec2(0.0);}if(d.x+d.y>2.0){vec4 coords=vec4(-d.x,-d.x,d.y,d.y)*resolution.zwzw+texCoord.xyxy;vec4 c;c.x=sampleLevelZeroOffset(inputBuffer,coords.xy,vec2(-1,0)).g;c.y=sampleLevelZeroOffset(inputBuffer,coords.xy,vec2(0,-1)).r;c.zw=sampleLevelZeroOffset(inputBuffer,coords.zw,vec2(1,0)).gr;vec2 cc=vec2(2.0)*c.xz+c.yw;movec(bvec2(step(0.9,d.zw)),cc,vec2(0.0));weights+=areaDiag(d.xy,cc,subsampleIndices.w).gr;}return weights;}float searchLength(const in vec2 e,const in float offset){vec2 scale=SEARCHTEX_SIZE*vec2(0.5,-1.0);vec2 bias=SEARCHTEX_SIZE*vec2(offset,1.0);scale+=vec2(-1.0,1.0);bias+=vec2(0.5,-0.5);scale*=1.0/SEARCHTEX_PACKED_SIZE;bias*=1.0/SEARCHTEX_PACKED_SIZE;return texture(searchTexture,scale*e+bias).r;}float searchXLeft(in vec2 texCoord,const in float end){vec2 e=vec2(0.0,1.0);for(int i=0;i<MAX_SEARCH_STEPS;++i){if(!(texCoord.x>end&&e.g>0.8281&&e.r==0.0)){break;}e=texture(inputBuffer,texCoord).rg;texCoord=vec2(-2.0,0.0)*resolution.zw+texCoord;}float offset=-(255.0/127.0)*searchLength(e,0.0)+3.25;return resolution.z*offset+texCoord.x;}float searchXRight(vec2 texCoord,const in float end){vec2 e=vec2(0.0,1.0);for(int i=0;i<MAX_SEARCH_STEPS;++i){if(!(texCoord.x<end&&e.g>0.8281&&e.r==0.0)){break;}e=texture(inputBuffer,texCoord).rg;texCoord=vec2(2.0,0.0)*resolution.zw+texCoord;}float offset=-(255.0/127.0)*searchLength(e,0.5)+3.25;return-resolution.z*offset+texCoord.x;}float searchYUp(vec2 texCoord,const in float end){vec2 e=vec2(1.0,0.0);for(int i=0;i<MAX_SEARCH_STEPS;++i){if(!(texCoord.y>end&&e.r>0.8281&&e.g==0.0)){break;}e=texture(inputBuffer,texCoord).rg;texCoord=-vec2(0.0,2.0)*resolution.zw+texCoord;}float offset=-(255.0/127.0)*searchLength(e.gr,0.0)+3.25;return resolution.w*offset+texCoord.y;}float searchYDown(vec2 texCoord,const in float end){vec2 e=vec2(1.0,0.0);for(int i=0;i<MAX_SEARCH_STEPS;i++){if(!(texCoord.y<end&&e.r>0.8281&&e.g==0.0)){break;}e=texture(inputBuffer,texCoord).rg;texCoord=vec2(0.0,2.0)*resolution.zw+texCoord;}float offset=-(255.0/127.0)*searchLength(e.gr,0.5)+3.25;return-resolution.w*offset+texCoord.y;}vec2 area(const in vec2 dist,const in float e1,const in float e2,const in float offset){vec2 texCoord=vec2(AREATEX_MAX_DISTANCE)*round(4.0*vec2(e1,e2))+dist;texCoord=AREATEX_PIXEL_SIZE*texCoord+0.5*AREATEX_PIXEL_SIZE;texCoord.y=AREATEX_SUBTEX_SIZE*offset+texCoord.y;return texture(areaTexture,texCoord).rg;}void detectHorizontalCornerPattern(inout vec2 weights,const in vec4 texCoord,const in vec2 d){\n#if !defined(DISABLE_CORNER_DETECTION)\nvec2 leftRight=step(d.xy,d.yx);vec2 rounding=(1.0-CORNER_ROUNDING_NORM)*leftRight;rounding/=leftRight.x+leftRight.y;vec2 factor=vec2(1.0);factor.x-=rounding.x*sampleLevelZeroOffset(inputBuffer,texCoord.xy,vec2(0,1)).r;factor.x-=rounding.y*sampleLevelZeroOffset(inputBuffer,texCoord.zw,vec2(1,1)).r;factor.y-=rounding.x*sampleLevelZeroOffset(inputBuffer,texCoord.xy,vec2(0,-2)).r;factor.y-=rounding.y*sampleLevelZeroOffset(inputBuffer,texCoord.zw,vec2(1,-2)).r;weights*=clamp(factor,0.0,1.0);\n#endif\n}void detectVerticalCornerPattern(inout vec2 weights,const in vec4 texCoord,const in vec2 d){\n#if !defined(DISABLE_CORNER_DETECTION)\nvec2 leftRight=step(d.xy,d.yx);vec2 rounding=(1.0-CORNER_ROUNDING_NORM)*leftRight;rounding/=leftRight.x+leftRight.y;vec2 factor=vec2(1.0);factor.x-=rounding.x*sampleLevelZeroOffset(inputBuffer,texCoord.xy,vec2(1,0)).g;factor.x-=rounding.y*sampleLevelZeroOffset(inputBuffer,texCoord.zw,vec2(1,1)).g;factor.y-=rounding.x*sampleLevelZeroOffset(inputBuffer,texCoord.xy,vec2(-2,0)).g;factor.y-=rounding.y*sampleLevelZeroOffset(inputBuffer,texCoord.zw,vec2(-2,1)).g;weights*=clamp(factor,0.0,1.0);\n#endif\n}void main(){vec4 weights=vec4(0.0);vec4 subsampleIndices=vec4(0.0);vec2 e=texture(inputBuffer,vUv).rg;if(e.g>0.0){\n#if !defined(DISABLE_DIAG_DETECTION)\nweights.rg=calculateDiagWeights(vUv,e,subsampleIndices);if(weights.r==-weights.g){\n#endif\nvec2 d;vec3 coords;coords.x=searchXLeft(vOffset[0].xy,vOffset[2].x);coords.y=vOffset[1].y;d.x=coords.x;float e1=texture(inputBuffer,coords.xy).r;coords.z=searchXRight(vOffset[0].zw,vOffset[2].y);d.y=coords.z;d=round(resolution.xx*d+-vPixCoord.xx);vec2 sqrtD=sqrt(abs(d));float e2=sampleLevelZeroOffset(inputBuffer,coords.zy,vec2(1,0)).r;weights.rg=area(sqrtD,e1,e2,subsampleIndices.y);coords.y=vUv.y;detectHorizontalCornerPattern(weights.rg,coords.xyzy,d);\n#if !defined(DISABLE_DIAG_DETECTION)\n}else{e.r=0.0;}\n#endif\n}if(e.r>0.0){vec2 d;vec3 coords;coords.y=searchYUp(vOffset[1].xy,vOffset[2].z);coords.x=vOffset[0].x;d.x=coords.y;float e1=texture(inputBuffer,coords.xy).g;coords.z=searchYDown(vOffset[1].zw,vOffset[2].w);d.y=coords.z;d=round(resolution.yy*d-vPixCoord.yy);vec2 sqrtD=sqrt(abs(d));float e2=sampleLevelZeroOffset(inputBuffer,coords.xz,vec2(0,1)).g;weights.ba=area(sqrtD,e1,e2,subsampleIndices.x);coords.x=vUv.x;detectVerticalCornerPattern(weights.ba,coords.xyxz,d);}outputColor=weights;}";

// src/materials/shaders/smaa-weights.vert
var smaa_weights_default2 = "uniform vec4 resolution;out vec2 vUv;out vec4 vOffset[3];out vec2 vPixCoord;void main(){vUv=position.xy*0.5+0.5;vPixCoord=vUv*resolution.xy;vOffset[0]=vUv.xyxy+resolution.zwzw*vec4(-0.25,-0.125,1.25,-0.125);vOffset[1]=vUv.xyxy+resolution.zwzw*vec4(-0.125,-0.25,-0.125,1.25);vOffset[2]=vec4(vOffset[0].xz,vOffset[1].yw)+vec4(-2.0,2.0,-2.0,2.0)*resolution.zzww*MAX_SEARCH_STEPS_FLOAT;gl_Position=vec4(position.xy,1.0,1.0);}";

// src/materials/SMAAWeightsMaterial.ts
var SMAAWeightsMaterial = class extends FullscreenMaterial {
  /**
   * Constructs a new SMAA weights material.
   */
  constructor() {
    super({
      name: "SMAAWeightsMaterial",
      fragmentShader: smaa_weights_default,
      vertexShader: smaa_weights_default2,
      defines: {
        // Configurable settings:
        MAX_SEARCH_STEPS: 16,
        MAX_SEARCH_STEPS_DIAG: 8,
        CORNER_ROUNDING: 25,
        CORNER_ROUNDING_NORM: 0.25,
        // Non-configurable settings:
        AREATEX_MAX_DISTANCE: 16,
        AREATEX_MAX_DISTANCE_DIAG: 20,
        AREATEX_PIXEL_SIZE: "(1.0 / vec2(160.0, 560.0))",
        AREATEX_SUBTEX_SIZE: "(1.0 / 7.0)",
        SEARCHTEX_SIZE: "vec2(66.0, 33.0)",
        SEARCHTEX_PACKED_SIZE: "vec2(64.0, 16.0)"
      },
      uniforms: {
        searchTexture: new Uniform18(null),
        areaTexture: new Uniform18(null)
      }
    });
  }
  /**
   * The search lookup texture.
   */
  get searchTexture() {
    return this.uniforms.searchTexture.value;
  }
  set searchTexture(value) {
    this.uniforms.searchTexture.value = value;
  }
  /**
   * The area lookup texture.
   */
  get areaTexture() {
    return this.uniforms.areaTexture.value;
  }
  set areaTexture(value) {
    this.uniforms.areaTexture.value = value;
  }
  /**
   * The maximum amount of steps performed in the horizontal/vertical pattern searches, at each side of the pixel.
   * Range: [0, 112].
   *
   * In number of pixels, it's actually the double. So the maximum line length perfectly handled by, for example 16, is
   * 64 (perfectly means that longer lines won't look as good, but are still antialiased).
   */
  get orthogonalSearchSteps() {
    return this.defines.MAX_SEARCH_STEPS;
  }
  set orthogonalSearchSteps(value) {
    const s = Math.min(Math.max(value, 0), 112);
    this.defines.MAX_SEARCH_STEPS = s;
    this.needsUpdate = true;
  }
  /**
   * The maximum steps performed in the diagonal pattern searches, at each side of the pixel. This search
   * jumps one pixel at a time. Range: [0, 20].
   *
   * On high-end machines this search is cheap (between 0.8x and 0.9x slower for 16 steps), but it can have a
   * significant impact on older machines.
   */
  get diagonalSearchSteps() {
    return this.defines.MAX_SEARCH_STEPS_DIAG;
  }
  set diagonalSearchSteps(value) {
    const s = Math.min(Math.max(value, 0), 20);
    this.defines.MAX_SEARCH_STEPS_DIAG = s;
    this.needsUpdate = true;
  }
  /**
   * Indicates whether diagonal pattern detection is enabled.
   */
  get diagonalDetection() {
    return this.defines.DISABLE_DIAG_DETECTION === void 0;
  }
  set diagonalDetection(value) {
    if (value) {
      delete this.defines.DISABLE_DIAG_DETECTION;
    } else {
      this.defines.DISABLE_DIAG_DETECTION = true;
    }
    this.needsUpdate = true;
  }
  /**
   * Specifies how much sharp corners will be rounded. Range: [0, 100].
   */
  get cornerRounding() {
    return this.defines.CORNER_ROUNDING;
  }
  set cornerRounding(value) {
    const r = Math.min(Math.max(value, 0), 100);
    this.defines.CORNER_ROUNDING = r;
    this.defines.CORNER_ROUNDING_NORM = r / 100;
    this.needsUpdate = true;
  }
  /**
   * Indicates whether corner detection is enabled.
   */
  get cornerDetection() {
    return this.defines.DISABLE_CORNER_DETECTION === void 0;
  }
  set cornerDetection(value) {
    if (value) {
      delete this.defines.DISABLE_CORNER_DETECTION;
    } else {
      this.defines.DISABLE_CORNER_DETECTION = true;
    }
    this.needsUpdate = true;
  }
};

// src/materials/TiltShiftBlurMaterial.ts
import { Uniform as Uniform19, Vector2 as Vector26, Vector4 as Vector42 } from "three";

// src/materials/shaders/convolution.tilt-shift.frag
var convolution_tilt_shift_default = "#include <pp_precision_fragment>\n#include <pp_default_output_pars_fragment>\n#include <pp_input_buffer_pars_fragment>\nuniform vec4 maskParams;in vec2 vUv;in vec2 vUv2;in vec2 vOffset;float linearGradientMask(const in float x){return smoothstep(maskParams.x,maskParams.y,x)-smoothstep(maskParams.w,maskParams.z,x);}void main(){vec2 dUv=vOffset*(1.0-linearGradientMask(vUv2.y));vec4 sum=texture(inputBuffer,vec2(vUv.x-dUv.x,vUv.y+dUv.y));sum+=texture(inputBuffer,vec2(vUv.x+dUv.x,vUv.y+dUv.y));sum+=texture(inputBuffer,vec2(vUv.x+dUv.x,vUv.y-dUv.y));sum+=texture(inputBuffer,vec2(vUv.x-dUv.x,vUv.y-dUv.y));outputColor=sum*0.25;}";

// src/materials/shaders/convolution.tilt-shift.vert
var convolution_tilt_shift_default2 = "#include <pp_resolution_pars_fragment>\nuniform float kernel;uniform float scale;uniform float aspect;uniform vec2 rotation;out vec2 vUv;out vec2 vUv2;out vec2 vOffset;void main(){vec2 uv=position.xy*0.5+0.5;vUv=uv;vUv2=(uv-0.5)*2.0*vec2(aspect,1.0);vUv2=vec2(dot(rotation,vUv2),dot(rotation,vec2(vUv2.y,-vUv2.x)));vOffset=(texelSize.zw*vec2(kernel)+texelSize.zw*vec2(0.5))*scale;gl_Position=vec4(position.xy,1.0,1.0);}";

// src/materials/TiltShiftBlurMaterial.ts
var TiltShiftBlurMaterial = class extends KawaseBlurMaterial {
  /**
   * @see {@link offset}
   */
  _offset;
  /**
   * @see {@link focusArea}
   */
  _focusArea;
  /**
   * @see {@link feather}
   */
  _feather;
  /**
   * Constructs a new tilt shift material.
   *
   * @param options - The options.
   */
  constructor({
    kernelSize = 2 /* MEDIUM */,
    offset = 0,
    rotation = 0,
    focusArea = 0.4,
    feather = 0.3
  } = {}) {
    super();
    this.fragmentShader = convolution_tilt_shift_default;
    this.vertexShader = convolution_tilt_shift_default2;
    this.uniforms.aspect = new Uniform19(1);
    this.uniforms.rotation = new Uniform19(new Vector26());
    this.uniforms.maskParams = new Uniform19(new Vector42());
    this._offset = offset;
    this._focusArea = focusArea;
    this._feather = feather;
    this.kernelSize = kernelSize;
    this.rotation = rotation;
    this.updateParams();
  }
  /**
   * The relative offset of the focus area.
   */
  updateParams() {
    const params = this.uniforms.maskParams.value;
    const a = Math.max(this.focusArea, 0);
    const b = Math.max(a - this.feather, 0);
    params.set(
      this.offset - a,
      this.offset - b,
      this.offset + a,
      this.offset + b
    );
  }
  /**
   * The rotation of the focus area in radians.
   */
  get rotation() {
    const rotation = this.uniforms.rotation.value;
    return Math.acos(rotation.x);
  }
  set rotation(value) {
    const rotation = this.uniforms.rotation.value;
    rotation.set(Math.cos(value), Math.sin(value));
  }
  /**
   * The relative offset of the focus area.
   */
  get offset() {
    return this._offset;
  }
  set offset(value) {
    this._offset = value;
    this.updateParams();
  }
  /**
   * The relative size of the focus area.
   */
  get focusArea() {
    return this._focusArea;
  }
  set focusArea(value) {
    this._focusArea = value;
    this.updateParams();
  }
  /**
   * The softness of the focus area edges.
   */
  get feather() {
    return this._feather;
  }
  set feather(value) {
    this._feather = value;
    this.updateParams();
  }
  setSize(width, height) {
    super.setSize(width, height);
    this.uniforms.aspect.value = width / height;
  }
};

// src/materials/UpsamplingMaterial.ts
import { Uniform as Uniform20, Vector2 as Vector27 } from "three";

// src/materials/shaders/convolution.upsampling.frag
var convolution_upsampling_default = "#include <pp_precision_fragment>\n#include <pp_default_output_pars_fragment>\n#include <pp_input_buffer_pars_fragment>\n#ifdef FRAMEBUFFER_PRECISION_HIGH\nuniform mediump sampler2D supportBuffer;\n#else\nuniform lowp sampler2D supportBuffer;\n#endif\nuniform float radius;in vec2 vUv;in vec2 vUv0,vUv1,vUv2,vUv3;in vec2 vUv4,vUv5,vUv6,vUv7;void main(){vec4 c=vec4(0.0);c+=texture(inputBuffer,vUv0)*0.0625;c+=texture(inputBuffer,vUv1)*0.125;c+=texture(inputBuffer,vUv2)*0.0625;c+=texture(inputBuffer,vUv3)*0.125;c+=texture(inputBuffer,vUv)*0.25;c+=texture(inputBuffer,vUv4)*0.125;c+=texture(inputBuffer,vUv5)*0.0625;c+=texture(inputBuffer,vUv6)*0.125;c+=texture(inputBuffer,vUv7)*0.0625;vec4 baseColor=texture(supportBuffer,vUv);outputColor=mix(baseColor,c,radius);}";

// src/materials/shaders/convolution.upsampling.vert
var convolution_upsampling_default2 = "#include <pp_resolution_pars_fragment>\nout vec2 vUv;out vec2 vUv0,vUv1,vUv2,vUv3;out vec2 vUv4,vUv5,vUv6,vUv7;void main(){vUv=position.xy*0.5+0.5;vUv0=vUv+resolution.zw*vec2(-1.0,1.0);vUv1=vUv+resolution.zw*vec2(0.0,1.0);vUv2=vUv+resolution.zw*vec2(1.0,1.0);vUv3=vUv+resolution.zw*vec2(-1.0,0.0);vUv4=vUv+resolution.zw*vec2(1.0,0.0);vUv5=vUv+resolution.zw*vec2(-1.0,-1.0);vUv6=vUv+resolution.zw*vec2(0.0,-1.0);vUv7=vUv+resolution.zw*vec2(1.0,-1.0);gl_Position=vec4(position.xy,1.0,1.0);}";

// src/materials/UpsamplingMaterial.ts
var UpsamplingMaterial = class extends FullscreenMaterial {
  /**
   * Constructs a new upsampling material.
   */
  constructor() {
    super({
      name: "UpsamplingMaterial",
      fragmentShader: convolution_upsampling_default,
      vertexShader: convolution_upsampling_default2,
      uniforms: {
        supportBuffer: new Uniform20(null),
        texelSize: new Uniform20(new Vector27()),
        radius: new Uniform20(0.85)
      }
    });
  }
  /**
   * A support buffer.
   *
   * Assumed to use the same texture type as the main input buffer.
   */
  set supportBuffer(value) {
    this.uniforms.supportBuffer.value = value;
  }
  /**
   * The blur radius.
   */
  get radius() {
    return this.uniforms.radius.value;
  }
  set radius(value) {
    this.uniforms.radius.value = value;
  }
};

// src/passes/BufferDebugPass.ts
import { Mesh as Mesh3, MeshBasicMaterial, OrthographicCamera as OrthographicCamera4, PlaneGeometry, Scene as Scene3 } from "three";
var BufferDebugPass = class extends CopyPass {
  /**
   * The size of each texture view relative to the screen size. Default is `0.1`.
   */
  viewSize;
  /**
   * Limits the amount of texture views per row. Default is `4`.
   */
  columns;
  /**
   * @see {@link bufferFocus}
   */
  _bufferFocus;
  /**
   * A list of meshes that are used to render the input textures.
   */
  views;
  /**
   * A scene that contains the debug meshes.
   */
  debugScene;
  /**
   * A debug camera.
   */
  debugCamera;
  /**
   * Constructs a new buffer debug pass.
   *
   * @param gBufferComponents - GBuffer components that should be rendered and visualized.
   */
  constructor(gBufferComponents) {
    super();
    this.name = "GBufferDebugPass";
    this.viewSize = 0.1;
    this.columns = 4;
    this.views = [];
    this._bufferFocus = null;
    this.debugScene = new Scene3();
    this.debugCamera = new OrthographicCamera4(-1, 1, 1, -1, 0, 1);
    if (gBufferComponents !== void 0) {
      for (const component of gBufferComponents) {
        this.input.gBuffer.add(component);
      }
    }
  }
  /**
   * A buffer that should be rendered in fullscreen mode.
   */
  get bufferFocus() {
    return this._bufferFocus;
  }
  set bufferFocus(value) {
    this._bufferFocus = value;
    if (value !== null && this.input.buffers.has(value)) {
      this.fullscreenMaterial.inputBuffer = this.input.buffers.get(value);
    } else {
      this.fullscreenMaterial.inputBuffer = this.input.defaultBuffer;
    }
  }
  /**
   * Updates the texture views.
   */
  updateViews() {
    const { width, height } = this.resolution;
    const size = Math.min(Math.max(this.viewSize, 0), 1);
    const columns = Math.max(this.columns, 0);
    const views = this.views;
    const rows = Math.ceil(views.length / columns);
    if (views.length * size > 1 || views.length / rows * size > 1) {
      Log.warn("Unable to fit texture views");
      return;
    }
    const sizeHalf = size * 0.5;
    const viewSizeX = size * width;
    const viewSizeY = size * height;
    const startX = width - sizeHalf * width;
    let offsetX = startX;
    let offsetY = sizeHalf * height;
    for (let i = 0, l = views.length, y = 0; y < rows; ++y) {
      for (let x = 0; x < columns && i < l; ++x, ++i) {
        const view = views[i];
        this.debugScene.add(view);
        view.scale.set(viewSizeX, viewSizeY, 1);
        view.position.set(offsetX, offsetY, 0);
        offsetX -= viewSizeX;
      }
      offsetX = startX;
      offsetY += viewSizeY;
    }
  }
  onResolutionChange(resolution) {
    super.onResolutionChange(resolution);
    const { width, height } = resolution;
    const debugCamera = this.debugCamera;
    debugCamera.left = 0;
    debugCamera.right = width;
    debugCamera.top = height;
    debugCamera.bottom = 0;
    debugCamera.updateProjectionMatrix();
    this.updateViews();
  }
  onInputChange() {
    super.onInputChange();
    for (const view of this.views) {
      view.geometry.dispose();
      this.debugScene.remove(view);
    }
    const capturedTextures = /* @__PURE__ */ new WeakSet();
    this.views = [];
    for (const entry of this.input.textures) {
      if (entry[0] === Input.BUFFER_DEFAULT || entry[1] === null || capturedTextures.has(entry[1])) {
        continue;
      }
      const view = new Mesh3(
        new PlaneGeometry(),
        new MeshBasicMaterial({
          map: entry[1]
        })
      );
      view.name = entry[0];
      this.views.push(view);
      capturedTextures.add(entry[1]);
    }
    this.updateViews();
  }
  render() {
    super.render();
    this.renderer?.render(this.debugScene, this.debugCamera);
  }
};

// src/passes/DepthDownsamplingPass.ts
import { FloatType, NearestFilter as NearestFilter2, WebGLRenderTarget as WebGLRenderTarget4 } from "three";
var DepthDownsamplingPass = class extends Pass {
  /**
   * Constructs a new depth downsampling pass.
   */
  constructor() {
    super("DepthDownsamplingPass");
    this.fullscreenMaterial = new DepthDownsamplingMaterial();
    this.input.gBuffer.add("GBUFFER_DEPTH" /* DEPTH */);
    this.input.gBuffer.add("GBUFFER_NORMAL" /* NORMAL */);
    const renderTarget = new WebGLRenderTarget4(1, 1, {
      minFilter: NearestFilter2,
      magFilter: NearestFilter2,
      depthBuffer: false,
      type: FloatType
    });
    this.output.defaultBuffer = renderTarget;
  }
  onInputChange() {
    this.fullscreenMaterial.depthBuffer = this.input.buffers.get("GBUFFER_DEPTH" /* DEPTH */);
    this.fullscreenMaterial.normalBuffer = this.input.buffers.get("GBUFFER_NORMAL" /* NORMAL */);
  }
  onResolutionChange(resolution) {
    this.fullscreenMaterial.setSize(resolution.baseWidth, resolution.baseHeight);
  }
  checkRequirements(renderer) {
    const gl = renderer.getContext();
    const renderable = gl.getExtension("EXT_color_buffer_float") || gl.getExtension("EXT_color_buffer_half_float");
    if (!renderable) {
      throw new Error("Rendering to a float texture is not supported");
    }
  }
  render() {
    this.renderer?.setRenderTarget(this.output.defaultBuffer);
    this.renderFullscreen();
  }
};

// src/passes/DepthPickingPass.ts
import { UnsignedByteType as UnsignedByteType6 } from "three";

// src/utils/functions/packing.ts
var unpackFactors = new Float32Array([
  255 / 256 / 256 ** 3,
  255 / 256 / 256 ** 2,
  255 / 256 / 256,
  255 / 256
]);
function unpackRGBAToFloat(packedDepth) {
  return (packedDepth[0] * unpackFactors[0] + packedDepth[1] * unpackFactors[1] + packedDepth[2] * unpackFactors[2] + packedDepth[3] * unpackFactors[3]) / 255;
}

// src/passes/DepthCopyPass.ts
import { FloatType as FloatType2, NearestFilter as NearestFilter3, WebGLRenderTarget as WebGLRenderTarget5 } from "three";
var DepthCopyPass = class extends Pass {
  /**
   * Constructs a new depth copy pass.
   */
  constructor() {
    super("DepthCopyPass");
    this.fullscreenMaterial = new DepthCopyMaterial();
    this.input.gBuffer.add("GBUFFER_DEPTH" /* DEPTH */);
    const renderTarget = new WebGLRenderTarget5(1, 1, {
      minFilter: NearestFilter3,
      magFilter: NearestFilter3,
      depthBuffer: false,
      type: FloatType2
    });
    this.output.defaultBuffer = renderTarget;
  }
  onInputChange() {
    this.fullscreenMaterial.depthBuffer = this.input.buffers.get("GBUFFER_DEPTH" /* DEPTH */);
  }
  render() {
    this.renderer?.setRenderTarget(this.output.defaultBuffer);
    this.renderFullscreen();
  }
};

// src/passes/DepthPickingPass.ts
var floatPixelBuffer = new Float32Array(4);
var uint8PixelBuffer = new Uint8Array(4);
var DepthPickingPass = class extends DepthCopyPass {
  /**
   * A callback that handles picking results.
   */
  callback;
  /**
   * Constructs a new depth picking pass.
   *
   * @param mode - The depth copy mode.
   */
  constructor(mode = 1 /* SINGLE */) {
    super();
    this.name = "DepthPickingPass";
    this.fullscreenMaterial.mode = mode;
    this.callback = null;
    if (mode === 1 /* SINGLE */) {
      this.resolution.setPreferredSize(1, 1);
    }
  }
  /**
   * Reads depth at a specific texture position.
   *
   * @param x - The X-coordinate.
   * @param x - The Y-coordinate.
   * @return The depth value.
   */
  readDepthAt(x, y) {
    const renderTarget = this.output.defaultBuffer;
    const packed = renderTarget.texture.type === UnsignedByteType6;
    const pixelBuffer = packed ? uint8PixelBuffer : floatPixelBuffer;
    this.renderer?.readRenderTargetPixels(renderTarget, x, y, 1, 1, pixelBuffer);
    return packed ? unpackRGBAToFloat(uint8PixelBuffer) : floatPixelBuffer[0];
  }
  /**
   * Reads depth at a specific screen position.
   *
   * If the mode is set to {@link DepthCopyMode.SINGLE}, only one depth value can be picked per frame. Calling this
   * method multiple times per frame will then overwrite the picking coordinates. Unresolved promises will be abandoned.
   *
   * @param ndc - Normalized device coordinates. Only X and Y are relevant.
   * @return A promise that returns the depth.
   * @example
   * const ndc = new Vector3();
   * const clientRect = myViewport.getBoundingClientRect();
   * const clientX = pointerEvent.clientX - clientRect.left;
   * const clientY = pointerEvent.clientY - clientRect.top;
   * ndc.x = (clientX / myViewport.clientWidth) * 2.0 - 1.0;
   * ndc.y = -(clientY / myViewport.clientHeight) * 2.0 + 1.0;
   * const depth = await depthPickingPass.readDepth(ndc);
   * ndc.z = depth * 2.0 - 1.0;
   * const worldPosition = ndc.unproject(camera);
   */
  readDepth(ndc) {
    this.fullscreenMaterial.texelPosition.set(ndc.x * 0.5 + 0.5, ndc.y * 0.5 + 0.5);
    return new Promise((resolve) => {
      if (this.fullscreenMaterial.mode === 1 /* SINGLE */) {
        this.callback = resolve;
      } else {
        const renderTarget = this.output.defaultBuffer;
        const texelPosition = this.fullscreenMaterial.texelPosition;
        const x = Math.round(texelPosition.x * renderTarget.width);
        const y = Math.round(texelPosition.y * renderTarget.height);
        resolve(this.readDepthAt(x, y));
      }
    });
  }
  render() {
    if (this.fullscreenMaterial.mode === 0 /* FULL */) {
      super.render();
    } else if (this.callback !== null) {
      super.render();
      this.callback(this.readDepthAt(0, 0));
      this.callback = null;
    }
  }
};

// src/passes/EffectPass.ts
import {
  SRGBColorSpace as SRGBColorSpace5
} from "three";

// src/utils/EffectShaderData.ts
import { LinearSRGBColorSpace as LinearSRGBColorSpace2, NoColorSpace as NoColorSpace2, SRGBColorSpace as SRGBColorSpace4 } from "three";

// src/utils/functions/string.ts
function prefixSubstrings(prefix, substrings, namedValues) {
  for (const substring of substrings) {
    const prefixed = "$1" + prefix + substring.charAt(0).toUpperCase() + substring.slice(1);
    const regExp = new RegExp("([^\\.])(\\b" + substring + "\\b)", "g");
    for (const entry of namedValues.entries()) {
      if (typeof entry[1] === "string") {
        namedValues.set(entry[0], entry[1].replace(regExp, prefixed));
      }
    }
  }
}

// src/utils/EffectShaderData.ts
var EffectShaderData = class {
  defines;
  uniforms;
  /**
   * The shader parts.
   */
  shaderParts;
  /**
   * The blend modes of the individual effects.
   */
  blendModes;
  /**
   * A set of varyings.
   */
  varyings;
  /**
   * A collection of required GBuffer data.
   */
  gData;
  /**
   * A list of effects that use convolution operations.
   */
  convolutionEffects;
  /**
   * Indicates whether the shader transforms UV coordinates in the fragment shader.
   */
  uvTransformation;
  /**
   * Keeps track of the current color space.
   */
  colorSpace;
  /**
   * Constructs new shader data.
   */
  constructor() {
    this.shaderParts = /* @__PURE__ */ new Map([
      ["$FRAGMENT_HEAD_GBUFFER" /* FRAGMENT_HEAD_GBUFFER */, ""],
      ["$FRAGMENT_HEAD_EFFECTS" /* FRAGMENT_HEAD_EFFECTS */, ""],
      ["$FRAGMENT_MAIN_UV" /* FRAGMENT_MAIN_UV */, ""],
      ["$FRAGMENT_MAIN_GDATA" /* FRAGMENT_MAIN_GDATA */, ""],
      ["$FRAGMENT_MAIN_IMAGE" /* FRAGMENT_MAIN_IMAGE */, ""],
      ["$VERTEX_HEAD" /* VERTEX_HEAD */, ""],
      ["$VERTEX_MAIN_SUPPORT" /* VERTEX_MAIN_SUPPORT */, ""]
    ]);
    this.defines = /* @__PURE__ */ new Map();
    this.uniforms = /* @__PURE__ */ new Map();
    this.blendModes = /* @__PURE__ */ new Map();
    this.varyings = /* @__PURE__ */ new Set();
    this.gData = /* @__PURE__ */ new Set(["color" /* COLOR */]);
    this.convolutionEffects = /* @__PURE__ */ new Set();
    this.uvTransformation = false;
    this.colorSpace = LinearSRGBColorSpace2;
  }
  /**
   * Validates the given effect.
   *
   * @param effect - The effect.
   * @throws {@link Error} if the effect is invalid or cannot be merged.
   */
  validateEffect(effect) {
    const fragmentShader = effect.fragmentShader;
    if (fragmentShader === null) {
      throw new Error(`Missing fragment shader (${effect.name})`);
    }
    if (effect.isConvolutionPass(false)) {
      this.convolutionEffects.add(effect);
    }
    if (this.convolutionEffects.size > 1) {
      const effectNames = Array.from(this.convolutionEffects).map((x) => x.name).join(", ");
      throw new Error(`Convolution effects cannot be merged (${effectNames})`);
    } else if (effect.hasMainUvFunction && this.convolutionEffects.size > 0) {
      throw new Error(`Effects that transform UVs are incompatible with convolution effects (${effect.name})`);
    } else if (!effect.hasMainImageFunction && !effect.hasMainUvFunction) {
      throw new Error(`Could not find a valid mainImage or mainUv function (${effect.name})`);
    }
  }
  /**
  * Integrates the given effect by collecting relevant shader data.
  *
  * @param prefix - A prefix.
  * @param effect - The effect.
  * @throws {@link Error} if the effect is invalid or cannot be merged.
  */
  integrateEffect(prefix, effect) {
    this.validateEffect(effect);
    let fragmentShader = effect.fragmentShader;
    let vertexShader = effect.vertexShader;
    const shaderParts = this.shaderParts;
    let fragmentHead = shaderParts.get("$FRAGMENT_HEAD_EFFECTS" /* FRAGMENT_HEAD_EFFECTS */);
    let fragmentMainUv = shaderParts.get("$FRAGMENT_MAIN_UV" /* FRAGMENT_MAIN_UV */);
    let fragmentMainImage = shaderParts.get("$FRAGMENT_MAIN_IMAGE" /* FRAGMENT_MAIN_IMAGE */);
    let vertexHead = shaderParts.get("$VERTEX_HEAD" /* VERTEX_HEAD */);
    let vertexMainSupport = shaderParts.get("$VERTEX_MAIN_SUPPORT" /* VERTEX_MAIN_SUPPORT */);
    const varyings = /* @__PURE__ */ new Set();
    const names = /* @__PURE__ */ new Set();
    if (effect.hasMainUvFunction) {
      fragmentMainUv += `	${prefix}MainUv(UV);
`;
      this.uvTransformation = true;
    }
    const functionRegExp = /\w+\s+(\w+)\([\w\s,]*\)\s*{/g;
    if (vertexShader !== null && effect.hasMainSupportFunction) {
      const needsUv = /mainSupport\s*\([\w\s]*?uv\s*?\)/.test(vertexShader);
      vertexMainSupport += `	${prefix}MainSupport(`;
      vertexMainSupport += needsUv ? "vUv);\n" : ");\n";
      for (const m of vertexShader.matchAll(/(?:out\s+\w+\s+([\S\s]*?);)/g)) {
        for (const n of m[1].split(/\s*,\s*/)) {
          this.varyings.add(n);
          varyings.add(n);
          names.add(n);
        }
      }
      for (const m of vertexShader.matchAll(functionRegExp)) {
        names.add(m[1]);
      }
    }
    for (const m of fragmentShader.matchAll(functionRegExp)) {
      names.add(m[1]);
    }
    for (const d of effect.input.defines.keys()) {
      names.add(d.replace(/\([\w\s,]*\)/g, ""));
    }
    for (const u of effect.input.uniforms.keys()) {
      names.add(u);
    }
    names.delete("while");
    names.delete("for");
    names.delete("if");
    effect.input.uniforms.forEach((v2, k) => this.uniforms.set(prefix + k.charAt(0).toUpperCase() + k.slice(1), v2));
    effect.input.defines.forEach((v2, k) => this.defines.set(prefix + k.charAt(0).toUpperCase() + k.slice(1), v2));
    const shaders = /* @__PURE__ */ new Map([["fragment", fragmentShader], ["vertex", vertexShader]]);
    prefixSubstrings(prefix, names, this.defines);
    prefixSubstrings(prefix, names, shaders);
    fragmentShader = shaders.get("fragment");
    vertexShader = shaders.get("vertex");
    const blendMode = effect.blendMode;
    this.blendModes.set(blendMode.blendFunction.id, blendMode);
    if (effect.hasMainImageFunction) {
      const gDataParamName = fragmentShader.match(/GData\s+(\w+)/)[0];
      for (const value of Object.values(GData)) {
        const regExpGData = new RegExp(`${gDataParamName}.${value}`);
        if (regExpGData.test(fragmentShader)) {
          this.gData.add(value);
        }
      }
      if (effect.inputColorSpace !== NoColorSpace2 && effect.inputColorSpace !== this.colorSpace) {
        fragmentMainImage += effect.inputColorSpace === SRGBColorSpace4 ? "color0 = LinearTosRGB(color0);\n	" : "color0 = sRGBToLinear(color0);\n	";
      }
      if (effect.outputColorSpace !== null) {
        this.colorSpace = effect.outputColorSpace;
      } else if (effect.inputColorSpace !== null) {
        this.colorSpace = effect.inputColorSpace;
      }
      fragmentMainImage += `color1 = ${prefix}MainImage(color0, UV, gData);
	`;
      const blendOpacity = prefix + "BlendOpacity";
      this.uniforms.set(blendOpacity, blendMode.opacityUniform);
      fragmentMainImage += `color0 = blend${blendMode.blendFunction.id}(color0, color1, ${blendOpacity});

	`;
      fragmentHead += `uniform float ${blendOpacity};

`;
    }
    fragmentHead += fragmentShader + "\n";
    if (vertexShader !== null) {
      vertexHead += vertexShader + "\n";
    }
    shaderParts.set("$FRAGMENT_HEAD_EFFECTS" /* FRAGMENT_HEAD_EFFECTS */, fragmentHead);
    shaderParts.set("$FRAGMENT_MAIN_UV" /* FRAGMENT_MAIN_UV */, fragmentMainUv);
    shaderParts.set("$FRAGMENT_MAIN_IMAGE" /* FRAGMENT_MAIN_IMAGE */, fragmentMainImage);
    shaderParts.set("$VERTEX_HEAD" /* VERTEX_HEAD */, vertexHead);
    shaderParts.set("$VERTEX_MAIN_SUPPORT" /* VERTEX_MAIN_SUPPORT */, vertexMainSupport);
  }
  /**
  * Creates a struct that defines the required GBuffer components.
  *
  * @return The shader code.
  */
  createGBufferStruct() {
    const gData = this.gData;
    let s = "struct GBuffer {\n";
    if (gData.has("color" /* COLOR */)) {
      s += "	FRAME_BUFFER_PRECISION sampler2D color;\n";
    }
    if (gData.has("depth" /* DEPTH */)) {
      s += "	DEPTH_BUFFER_PRECISION sampler2D depth;\n";
    }
    if (gData.has("normal" /* NORMAL */)) {
      s += "	mediump sampler2D normal;\n";
    }
    if (gData.has("roughness" /* ROUGHNESS */) || gData.has("metalness" /* METALNESS */)) {
      s += "	lowp sampler2D roughnessMetalness;\n";
    }
    s += "};\n";
    return s;
  }
  /**
  * Creates a struct that defines the required GBuffer data.
  *
  * @return The shader code.
  */
  createGDataStruct() {
    const gData = this.gData;
    let s = "struct GData {\n";
    if (gData.has("color" /* COLOR */)) {
      s += "	vec4 color;\n";
    }
    if (gData.has("depth" /* DEPTH */)) {
      s += "	float depth;\n";
    }
    if (gData.has("normal" /* NORMAL */)) {
      s += "	vec3 normal;\n";
    }
    if (gData.has("roughness" /* ROUGHNESS */)) {
      s += "	float roughness;\n";
    }
    if (gData.has("metalness" /* METALNESS */)) {
      s += "	float metalness;\n";
    }
    if (gData.has("luminance" /* LUMINANCE */)) {
      s += "	float luminance;\n";
    }
    s += "};\n";
    return s;
  }
  /**
  * Creates the GData setup code.
  *
  * @return The shader code.
  */
  createGDataSetup() {
    const gData = this.gData;
    let s = "GData gData;\n";
    if (gData.has("color" /* COLOR */)) {
      s += "	gData.color = texture(gBuffer.color, UV);\n";
    }
    if (gData.has("depth" /* DEPTH */)) {
      s += "	gData.depth = texture(gBuffer.depth, UV).r;\n";
    }
    if (gData.has("normal" /* NORMAL */)) {
      s += "	gData.normal = texture(gBuffer.normal, UV).xyz;\n";
    }
    if (gData.has("roughness" /* ROUGHNESS */) || gData.has("metalness" /* METALNESS */)) {
      s += "	vec2 roughnessMetalness = texture(gBuffer.roughnessMetalness, UV).rg;\n";
    }
    if (gData.has("roughness" /* ROUGHNESS */)) {
      s += "	gData.roughness = roughnessMetalness.r;\n";
    }
    if (gData.has("metalness" /* METALNESS */)) {
      s += "	gData.metalness = roughnessMetalness.g;\n";
    }
    if (gData.has("luminance" /* LUMINANCE */)) {
      s += "	gData.luminance = luminance(gData.color.rgb);\n";
    }
    return s;
  }
  /**
  * Creates the relevant blend function declarations.
  *
  * @return The shader code.
  */
  createBlendFunctions() {
    const blendRegExp = /\bblend\b/g;
    let s = "";
    for (const blendMode of this.blendModes.values()) {
      const blendFunctionShader = blendMode.blendFunction.shader;
      const blendFunctionName = `blend${blendMode.blendFunction.id}`;
      s += blendFunctionShader.replace(blendRegExp, blendFunctionName) + "\n";
    }
    return s;
  }
};

// src/passes/EffectPass.ts
var EffectPass = class _EffectPass extends Pass {
  /**
   * A collection that maps GBuffer components to GBuffer struct field names.
   */
  static gBufferStructFields = /* @__PURE__ */ new Map([
    ["GBUFFER_COLOR" /* COLOR */, "color"],
    ["GBUFFER_DEPTH" /* DEPTH */, "depth"],
    ["GBUFFER_NORMAL" /* NORMAL */, "normal"],
    ["GBUFFER_ROUGHNESS" /* ROUGHNESS */, "roughnessMetalness"],
    ["GBUFFER_METALNESS" /* METALNESS */, "roughnessMetalness"]
  ]);
  /**
   * An event listener that forwards events to {@link handleEvent}.
   */
  listener;
  /**
   * An animation time scale.
   */
  timeScale;
  /**
   * Constructs a new effect pass.
   *
   * @param effects - The effects that will be rendered by this pass.
   */
  constructor(...effects) {
    super("EffectPass");
    this.output.defaultBuffer = this.createFramebuffer();
    this.fullscreenMaterial = new EffectMaterial();
    this.listener = (e) => this.handleEvent(e);
    this.effects = effects;
    this.timeScale = 1;
  }
  get camera() {
    return super.camera;
  }
  set camera(value) {
    super.camera = value;
    if (value !== null) {
      this.fullscreenMaterial.copyCameraSettings(value);
    }
  }
  get subpasses() {
    return super.subpasses;
  }
  set subpasses(value) {
    for (const effect of super.subpasses) {
      effect.removeEventListener(Pass.EVENT_CHANGE, this.listener);
    }
    super.subpasses = value;
    Object.freeze(super.subpasses);
    for (const effect of super.subpasses) {
      effect.addEventListener(Pass.EVENT_CHANGE, this.listener);
    }
    this.rebuild();
  }
  /**
   * The effects.
   */
  get effects() {
    return this.subpasses;
  }
  set effects(value) {
    this.subpasses = value;
  }
  /**
   * Indicates whether dithering is enabled.
   */
  get dithering() {
    return this.fullscreenMaterial.dithering;
  }
  set dithering(value) {
    const material = this.fullscreenMaterial;
    if (material.dithering !== value) {
      if (value && this.fullscreenMaterial.outputPrecision !== "lowp") {
        Log.info("Dithering only works on low precision colors");
      } else {
        material.dithering = value;
        material.needsUpdate = true;
      }
    }
  }
  /**
   * Updates the composite shader material.
   *
   * @throws {@link Error} if the current effects cannot be merged.
   */
  updateMaterial() {
    const data = new EffectShaderData();
    let id = 0;
    for (const effect of this.effects) {
      if (effect.blendMode.blendFunction.shader !== null) {
        data.integrateEffect(`e${id++}`, effect);
      }
    }
    data.shaderParts.set("$FRAGMENT_HEAD_GBUFFER" /* FRAGMENT_HEAD_GBUFFER */, data.createGBufferStruct());
    data.shaderParts.set("$FRAGMENT_HEAD_GDATA" /* FRAGMENT_HEAD_GDATA */, data.createGDataStruct());
    data.shaderParts.set("$FRAGMENT_MAIN_GDATA" /* FRAGMENT_MAIN_GDATA */, data.createGDataSetup());
    const fragmentHead = data.shaderParts.get("$FRAGMENT_HEAD_EFFECTS" /* FRAGMENT_HEAD_EFFECTS */);
    data.shaderParts.set("$FRAGMENT_HEAD_EFFECTS" /* FRAGMENT_HEAD_EFFECTS */, fragmentHead + data.createBlendFunctions());
    if (data.colorSpace === SRGBColorSpace5) {
      const fragmentMainImage = data.shaderParts.get("$FRAGMENT_MAIN_IMAGE" /* FRAGMENT_MAIN_IMAGE */);
      data.shaderParts.set("$FRAGMENT_MAIN_IMAGE" /* FRAGMENT_MAIN_IMAGE */, fragmentMainImage + "color0 = sRGBToLinear(color0);\n	");
    }
    if (data.uvTransformation) {
      const fragmentMainUv = data.shaderParts.get("$FRAGMENT_MAIN_UV" /* FRAGMENT_MAIN_UV */);
      data.shaderParts.set("$FRAGMENT_MAIN_UV" /* FRAGMENT_MAIN_UV */, "vec2 transformedUv = vUv;\n" + fragmentMainUv);
      data.defines.set("UV", "transformedUv");
    } else {
      data.defines.set("UV", "vUv");
    }
    data.shaderParts.forEach((v2, k, map) => map.set(k, v2.trim().replace(/^#/, "\n#")));
    this.fullscreenMaterial.setShaderParts(data.shaderParts).setDefines(data.defines).setUniforms(data.uniforms);
  }
  /**
   * Rebuilds the composite shader material.
   */
  rebuild() {
    try {
      this.updateMaterial();
    } catch (e) {
      Log.error(e);
      Log.info("Disabling pass:", this);
      this.enabled = false;
    }
  }
  onResolutionChange(resolution) {
    this.fullscreenMaterial.setSize(resolution.width, resolution.height);
    for (const effect of this.effects) {
      effect.resolution.copy(resolution);
    }
  }
  onInputChange() {
    const entries = [];
    const input = this.input;
    for (const component of input.gBuffer) {
      entries.push([
        _EffectPass.gBufferStructFields.get(component),
        component === "GBUFFER_COLOR" /* COLOR */ ? input.defaultBuffer : input.buffers.get(component) || null
      ]);
    }
    this.fullscreenMaterial.gBuffer = Object.fromEntries(entries);
  }
  checkRequirements(renderer) {
    for (const effect of this.effects) {
      effect.checkRequirements(renderer);
    }
  }
  dispose() {
    for (const effect of this.effects) {
      effect.removeEventListener("change", this.listener);
    }
    super.dispose();
  }
  render() {
    if (this.renderer === null || this.timer === null) {
      return;
    }
    for (const effect of this.effects) {
      effect.render();
    }
    const material = this.fullscreenMaterial;
    material.time += this.timer.getDelta() * this.timeScale;
    this.renderer.setRenderTarget(this.output.defaultBuffer);
    this.renderFullscreen();
  }
  handleEvent(event) {
    switch (event.type) {
      case "change":
        this.rebuild();
        break;
    }
  }
};

// src/passes/LambdaPass.ts
var LambdaPass = class extends Pass {
  /**
   * The function to execute.
   */
  f;
  /**
   * Constructs a new lambda pass.
   *
   * @param f - A function.
   */
  constructor(f) {
    super("LambdaPass");
    this.f = f;
  }
  render() {
    this.f();
  }
};

// src/passes/LuminancePass.ts
var LuminancePass = class extends Pass {
  /**
   * Constructs a new luminance pass.
   */
  constructor() {
    super("LuminancePass");
    this.output.defaultBuffer = this.createFramebuffer();
    this.fullscreenMaterial = new LuminanceMaterial();
  }
  render() {
    this.renderer?.setRenderTarget(this.output.defaultBuffer);
    this.renderFullscreen();
  }
};

// src/passes/ShaderPass.ts
var ShaderPass = class extends Pass {
  /**
   * The name of the input buffer uniform.
   *
   * Most fullscreen materials modify texels from an input texture. This pass automatically assigns the default input
   * buffer to the uniform identified by this name.
   */
  uniformName;
  /**
   * Constructs a new shader pass.
   *
   * @param material - A shader material.
   * @param uniformName - The name of the input buffer uniform. Default is `inputBuffer`.
   */
  constructor(material, uniformName = "inputBuffer") {
    super("ShaderPass");
    this.output.defaultBuffer = this.createFramebuffer();
    this.fullscreenMaterial = material;
    this.uniformName = uniformName;
  }
  onInputChange() {
    const uniforms = this.fullscreenMaterial.uniforms;
    const inputBuffer = this.input.defaultBuffer;
    if (uniforms !== void 0 && uniforms[this.uniformName] !== void 0) {
      uniforms[this.uniformName].value = inputBuffer;
    }
  }
  render() {
    this.renderer?.setRenderTarget(this.output.defaultBuffer);
    this.renderFullscreen();
  }
};

// src/textures/lut/LookupTexture.ts
import {
  Color as Color4,
  Data3DTexture,
  DataTexture,
  FloatType as FloatType3,
  LinearFilter as LinearFilter2,
  LinearSRGBColorSpace as LinearSRGBColorSpace3,
  RGBAFormat as RGBAFormat2,
  SRGBColorSpace as SRGBColorSpace6,
  UnsignedByteType as UnsignedByteType7,
  Vector3 as Vector34
} from "three";

// src/textures/RawImageData.ts
function createCanvas(width, height, data) {
  const canvas = document.createElement("canvas");
  const context = canvas.getContext("2d");
  canvas.width = width;
  canvas.height = height;
  if (context === null) {
    return canvas;
  } else if (data instanceof Image) {
    context.drawImage(data, 0, 0);
  } else {
    const imageData = context.createImageData(width, height);
    imageData.data.set(data);
    context.putImageData(imageData, 0, 0);
  }
  return canvas;
}
var RawImageData = class _RawImageData {
  colorSpace;
  /**
   * The width of the image.
   */
  width;
  /**
   * The height of the image.
   */
  height;
  /**
   * The RGBA image data.
   */
  data;
  /**
   * Constructs a new image data container.
   *
   * @param width - The width of the image.
   * @param height - The height of the image.
   * @param data - The image data.
   */
  constructor(width = 0, height = 0, data) {
    this.colorSpace = "srgb";
    this.width = width;
    this.height = height;
    this.data = data;
  }
  /**
   * Creates a canvas from this image data.
   *
   * @return The canvas.
   */
  toCanvas() {
    if (typeof document === "undefined") {
      throw new Error("Failed to create canvas");
    }
    return createCanvas(this.width, this.height, this.data);
  }
  /**
   * Creates a new image data container.
   *
   * @param image - An image or plain image data.
   * @return The image data.
   */
  static from(image) {
    const { width, height } = image;
    let data;
    if (image instanceof Image) {
      const canvas = createCanvas(width, height, image);
      const context = canvas.getContext("2d");
      if (canvas === null || context === null) {
        throw new Error("Failed to create canvas");
      }
      data = context.getImageData(0, 0, width, height).data;
    } else {
      data = image.data;
    }
    return new _RawImageData(width, height, data);
  }
};

// temp/lut/worker.txt
var worker_default = '"use strict";(()=>{var B=Math.pow;var C=[new Float32Array(3),new Float32Array(3)],t=[new Float32Array(3),new Float32Array(3),new Float32Array(3),new Float32Array(3)],V=[[new Float32Array([0,0,0]),new Float32Array([1,0,0]),new Float32Array([1,1,0]),new Float32Array([1,1,1])],[new Float32Array([0,0,0]),new Float32Array([1,0,0]),new Float32Array([1,0,1]),new Float32Array([1,1,1])],[new Float32Array([0,0,0]),new Float32Array([0,0,1]),new Float32Array([1,0,1]),new Float32Array([1,1,1])],[new Float32Array([0,0,0]),new Float32Array([0,1,0]),new Float32Array([1,1,0]),new Float32Array([1,1,1])],[new Float32Array([0,0,0]),new Float32Array([0,1,0]),new Float32Array([0,1,1]),new Float32Array([1,1,1])],[new Float32Array([0,0,0]),new Float32Array([0,0,1]),new Float32Array([0,1,1]),new Float32Array([1,1,1])]];function P(o,r,a,m){let F=a[0]-r[0],A=a[1]-r[1],e=a[2]-r[2],i=o[0]-r[0],w=o[1]-r[1],y=o[2]-r[2],s=A*y-e*w,c=e*i-F*y,p=F*w-A*i,h=Math.sqrt(s*s+c*c+p*p),X=h*.5,l=s/h,u=c/h,f=p/h,b=-(o[0]*l+o[1]*u+o[2]*f),M=m[0]*l+m[1]*u+m[2]*f;return Math.abs(M+b)*X/3}function Y(o,r,a,m,F,A){let e=(a+m*r+F*r*r)*4;A[0]=o[e+0],A[1]=o[e+1],A[2]=o[e+2]}function W(o,r,a,m,F,A){let e=a*(r-1),i=m*(r-1),w=F*(r-1),y=Math.floor(e),s=Math.floor(i),c=Math.floor(w),p=Math.ceil(e),h=Math.ceil(i),X=Math.ceil(w),l=e-y,u=i-s,f=w-c;if(y===e&&s===i&&c===w)Y(o,r,e,i,w,A);else{let b;l>=u&&u>=f?b=V[0]:l>=f&&f>=u?b=V[1]:f>=l&&l>=u?b=V[2]:u>=l&&l>=f?b=V[3]:u>=f&&f>=l?b=V[4]:b=V[5];let[M,g,d,v]=b,x=C[0];x[0]=l,x[1]=u,x[2]=f;let n=C[1],Z=p-y,U=h-s,L=X-c;n[0]=Z*M[0]+y,n[1]=U*M[1]+s,n[2]=L*M[2]+c,Y(o,r,n[0],n[1],n[2],t[0]),n[0]=Z*g[0]+y,n[1]=U*g[1]+s,n[2]=L*g[2]+c,Y(o,r,n[0],n[1],n[2],t[1]),n[0]=Z*d[0]+y,n[1]=U*d[1]+s,n[2]=L*d[2]+c,Y(o,r,n[0],n[1],n[2],t[2]),n[0]=Z*v[0]+y,n[1]=U*v[1]+s,n[2]=L*v[2]+c,Y(o,r,n[0],n[1],n[2],t[3]);let T=P(g,d,v,x)*6,q=P(M,d,v,x)*6,S=P(M,g,v,x)*6,E=P(M,g,d,x)*6;t[0][0]*=T,t[0][1]*=T,t[0][2]*=T,t[1][0]*=q,t[1][1]*=q,t[1][2]*=q,t[2][0]*=S,t[2][1]*=S,t[2][2]*=S,t[3][0]*=E,t[3][1]*=E,t[3][2]*=E,A[0]=t[0][0]+t[1][0]+t[2][0]+t[3][0],A[1]=t[0][1]+t[1][1]+t[2][1]+t[3][1],A[2]=t[0][2]+t[1][2]+t[2][2]+t[3][2]}}var k=class{static expand(r,a){let m=Math.cbrt(r.length/4),F=new r.constructor(B(a,3)*4),A=r instanceof Uint8Array?255:1,e=new Float32Array(3),i=B(a,2),w=1/(a-1);for(let y=0;y<a;++y)for(let s=0;s<a;++s)for(let c=0;c<a;++c){let p=c*w,h=s*w,X=y*w,l=Math.round(c+s*a+y*i)*4;W(r,m,p,h,X,e),F[l+0]=e[0],F[l+1]=e[1],F[l+2]=e[2],F[l+3]=A}return F}};self.addEventListener("message",o=>{let r=o.data,a=k.expand(r.data,r.size);self.postMessage(a,[a.buffer]),close()});})();\n';

// src/textures/lut/LookupTexture.ts
var c = new Color4();
var LookupTexture = class _LookupTexture extends Data3DTexture {
  domainMin;
  domainMax;
  /**
   * Constructs a cubic 3D lookup texture.
   *
   * @param data - The pixel data. The default format is RGBA.
   * @param size - The sidelength.
   */
  constructor(data, size) {
    super(data, size, size, size);
    this.type = FloatType3;
    this.minFilter = LinearFilter2;
    this.unpackAlignment = 1;
    this.needsUpdate = true;
    this.domainMin = new Vector34(0, 0, 0);
    this.domainMax = new Vector34(1, 1, 1);
  }
  /**
   * Scales this LUT up to a given target size using tetrahedral interpolation.
   *
   * @param size - The target sidelength.
   * @param [transferData=true] - Extra fast mode. Set to false to keep the original data intact.
   * @return A promise that resolves with a new LUT upon completion.
   */
  async scaleUp(size, transferData = true) {
    const image = this.image;
    let promise;
    if (size <= image.width) {
      promise = Promise.reject(new Error("The target size must be greater than the current size"));
    } else {
      promise = new Promise((resolve, reject) => {
        const workerURL = URL.createObjectURL(new Blob([worker_default], {
          type: "text/javascript"
        }));
        const worker = new Worker(workerURL);
        worker.addEventListener("error", (event) => reject(event.error));
        worker.addEventListener("message", (event) => {
          const lut = new _LookupTexture(event.data, size);
          lut.colorSpace = this.colorSpace;
          lut.type = this.type;
          lut.name = this.name;
          URL.revokeObjectURL(workerURL);
          resolve(lut);
        });
        const transferList = transferData ? [image.data.buffer] : [];
        worker.postMessage({
          data: image.data,
          size
        }, transferList);
      });
    }
    return promise;
  }
  /**
   * Applies the given LUT to this one.
   *
   * @param lut - A LUT. Must have the same dimensions, type and format as this LUT.
   * @return This texture.
   */
  applyLUT(lut) {
    const img0 = this.image;
    const img1 = lut.image;
    const size0 = Math.min(img0.width, img0.height, img0.depth);
    const size1 = Math.min(img1.width, img1.height, img1.depth);
    if (size0 !== size1) {
      throw new Error("Size mismatch");
    } else if (lut.type !== FloatType3 || this.type !== FloatType3) {
      throw new Error("Both LUTs must be FloatType textures");
    } else if (lut.format !== RGBAFormat2 || this.format !== RGBAFormat2) {
      throw new Error("Both LUTs must be RGBA textures");
    } else {
      const data0 = img0.data;
      const data1 = img1.data;
      const size = size0;
      const sizeSq = size ** 2;
      const s = size - 1;
      for (let i = 0, l = size ** 3; i < l; ++i) {
        const i4 = i * 4;
        const r = data0[i4 + 0] * s;
        const g = data0[i4 + 1] * s;
        const b = data0[i4 + 2] * s;
        const iRGB = Math.round(r + g * size + b * sizeSq) * 4;
        data0[i4 + 0] = data1[iRGB + 0];
        data0[i4 + 1] = data1[iRGB + 1];
        data0[i4 + 2] = data1[iRGB + 2];
      }
      this.needsUpdate = true;
    }
    return this;
  }
  /**
   * Converts the LUT data into unsigned byte data.
   *
   * This is a lossy operation which should only be performed after all other transformations have been applied.
   *
   * @return This texture.
   */
  convertToUint8() {
    if (this.type === FloatType3) {
      const img = this.image;
      const floatData = img.data;
      const uint8Data = new Uint8Array(floatData.length);
      for (let i = 0, l = floatData.length; i < l; ++i) {
        uint8Data[i] = floatData[i] * 255 + 0.5;
      }
      this.source.data = uint8Data;
      this.type = UnsignedByteType7;
      this.needsUpdate = true;
    }
    return this;
  }
  /**
   * Converts the LUT data into float data.
   *
   * @return This texture.
   */
  convertToFloat() {
    if (this.type === UnsignedByteType7) {
      const img = this.image;
      const uint8Data = img.data;
      const floatData = new Float32Array(uint8Data.length);
      for (let i = 0, l = uint8Data.length; i < l; ++i) {
        floatData[i] = uint8Data[i] / 255;
      }
      this.source.data = floatData;
      this.type = FloatType3;
      this.needsUpdate = true;
    }
    return this;
  }
  /**
   * Converts the output of this LUT into sRGB color space.
   *
   * @return This texture.
   */
  convertLinearToSRGB() {
    const img = this.image;
    const data = img.data;
    if (this.type === FloatType3) {
      for (let i = 0, l = data.length; i < l; i += 4) {
        c.fromArray(data, i).convertLinearToSRGB().toArray(data, i);
      }
      this.colorSpace = SRGBColorSpace6;
      this.needsUpdate = true;
    } else {
      throw new Error("Color space conversion requires FloatType data");
    }
    return this;
  }
  /**
   * Converts the output of this LUT into linear color space.
   *
   * @return This texture.
   */
  convertSRGBToLinear() {
    const img = this.image;
    const data = img.data;
    if (this.type === FloatType3) {
      for (let i = 0, l = data.length; i < l; i += 4) {
        c.fromArray(data, i).convertSRGBToLinear().toArray(data, i);
      }
      this.colorSpace = LinearSRGBColorSpace3;
      this.needsUpdate = true;
    } else {
      throw new Error("Color space conversion requires FloatType data");
    }
    return this;
  }
  /**
   * Converts this LUT into a 2D data texture.
   *
   * Custom {@link LUTDomainBounds} are stored as `userData.domainBounds`.
   *
   * @return The texture.
   */
  toDataTexture() {
    const img = this.image;
    const width = img.width;
    const height = img.height * img.depth;
    const texture = new DataTexture(img.data, width, height);
    texture.name = this.name;
    texture.type = this.type;
    texture.format = this.format;
    texture.colorSpace = this.colorSpace;
    texture.minFilter = LinearFilter2;
    texture.magFilter = LinearFilter2;
    texture.wrapS = this.wrapS;
    texture.wrapT = this.wrapT;
    texture.generateMipmaps = false;
    texture.needsUpdate = true;
    const userData = texture.userData;
    userData.domainBounds = {
      domainMin: this.domainMin,
      domainMax: this.domainMax
    };
    return texture;
  }
  /**
   * Creates a new 3D LUT by copying a given LUT.
   *
   * Common image-based textures will be converted into 3D data textures.
   *
   * @param texture - The LUT. Assumed to be cubic.
   * @return A new 3D LUT.
   */
  static from(texture) {
    const image = texture.image;
    const { width, height } = image;
    const size = Math.min(width, height);
    let data;
    if (image instanceof Image) {
      const rawImageData = RawImageData.from(image);
      const src = rawImageData.data;
      if (width > height) {
        data = new Uint8Array(src.length);
        for (let z = 0; z < size; ++z) {
          for (let y = 0; y < size; ++y) {
            for (let x = 0; x < size; ++x) {
              const i4 = (x + z * size + y * size * size) * 4;
              const j4 = (x + y * size + z * size * size) * 4;
              data[j4 + 0] = src[i4 + 0];
              data[j4 + 1] = src[i4 + 1];
              data[j4 + 2] = src[i4 + 2];
              data[j4 + 3] = src[i4 + 3];
            }
          }
        }
      } else {
        data = new Uint8Array(src.buffer);
      }
    } else {
      data = image.data.slice();
    }
    const lut = new _LookupTexture(data, size);
    lut.colorSpace = texture.colorSpace;
    lut.type = texture.type;
    lut.name = texture.name;
    const userData = texture.userData;
    if (userData.domainBounds !== void 0) {
      const domainData = userData.domainBounds;
      lut.domainMin.copy(domainData.domainMin);
      lut.domainMax.copy(domainData.domainMax);
    }
    return lut;
  }
  /**
   * Creates a neutral 3D LUT.
   *
   * @param size - The sidelength.
   * @return A neutral 3D LUT.
   */
  static createNeutral(size) {
    const data = new Float32Array(size ** 3 * 4);
    const sizeSq = size ** 2;
    const s = 1 / (size - 1);
    for (let r = 0; r < size; ++r) {
      for (let g = 0; g < size; ++g) {
        for (let b = 0; b < size; ++b) {
          const i4 = (r + g * size + b * sizeSq) * 4;
          data[i4 + 0] = r * s;
          data[i4 + 1] = g * s;
          data[i4 + 2] = b * s;
          data[i4 + 3] = 1;
        }
      }
    }
    const lut = new _LookupTexture(data, size);
    lut.name = "neutral";
    return lut;
  }
};

// src/textures/lut/TetrahedralUpscaler.ts
var P = [
  new Float32Array(3),
  new Float32Array(3)
];
var C = [
  new Float32Array(3),
  new Float32Array(3),
  new Float32Array(3),
  new Float32Array(3)
];
var T = [
  [
    new Float32Array([0, 0, 0]),
    new Float32Array([1, 0, 0]),
    new Float32Array([1, 1, 0]),
    new Float32Array([1, 1, 1])
  ],
  [
    new Float32Array([0, 0, 0]),
    new Float32Array([1, 0, 0]),
    new Float32Array([1, 0, 1]),
    new Float32Array([1, 1, 1])
  ],
  [
    new Float32Array([0, 0, 0]),
    new Float32Array([0, 0, 1]),
    new Float32Array([1, 0, 1]),
    new Float32Array([1, 1, 1])
  ],
  [
    new Float32Array([0, 0, 0]),
    new Float32Array([0, 1, 0]),
    new Float32Array([1, 1, 0]),
    new Float32Array([1, 1, 1])
  ],
  [
    new Float32Array([0, 0, 0]),
    new Float32Array([0, 1, 0]),
    new Float32Array([0, 1, 1]),
    new Float32Array([1, 1, 1])
  ],
  [
    new Float32Array([0, 0, 0]),
    new Float32Array([0, 0, 1]),
    new Float32Array([0, 1, 1]),
    new Float32Array([1, 1, 1])
  ]
];
function calculateTetrahedronVolume(a, b, c2, d) {
  const bcX = c2[0] - b[0];
  const bcY = c2[1] - b[1];
  const bcZ = c2[2] - b[2];
  const baX = a[0] - b[0];
  const baY = a[1] - b[1];
  const baZ = a[2] - b[2];
  const crossX = bcY * baZ - bcZ * baY;
  const crossY = bcZ * baX - bcX * baZ;
  const crossZ = bcX * baY - bcY * baX;
  const length = Math.sqrt(crossX * crossX + crossY * crossY + crossZ * crossZ);
  const triangleArea = length * 0.5;
  const normalX = crossX / length;
  const normalY = crossY / length;
  const normalZ = crossZ / length;
  const constant = -(a[0] * normalX + a[1] * normalY + a[2] * normalZ);
  const dot = d[0] * normalX + d[1] * normalY + d[2] * normalZ;
  const height = Math.abs(dot + constant);
  return height * triangleArea / 3;
}
function sample(data, size, x, y, z, color2) {
  const i4 = (x + y * size + z * size * size) * 4;
  color2[0] = data[i4 + 0];
  color2[1] = data[i4 + 1];
  color2[2] = data[i4 + 2];
}
function tetrahedralSample(data, size, u, v2, w, color2) {
  const px = u * (size - 1);
  const py = v2 * (size - 1);
  const pz = w * (size - 1);
  const minX = Math.floor(px);
  const minY = Math.floor(py);
  const minZ = Math.floor(pz);
  const maxX = Math.ceil(px);
  const maxY = Math.ceil(py);
  const maxZ = Math.ceil(pz);
  const su = px - minX;
  const sv = py - minY;
  const sw = pz - minZ;
  if (minX === px && minY === py && minZ === pz) {
    sample(data, size, px, py, pz, color2);
  } else {
    let vertices;
    if (su >= sv && sv >= sw) {
      vertices = T[0];
    } else if (su >= sw && sw >= sv) {
      vertices = T[1];
    } else if (sw >= su && su >= sv) {
      vertices = T[2];
    } else if (sv >= su && su >= sw) {
      vertices = T[3];
    } else if (sv >= sw && sw >= su) {
      vertices = T[4];
    } else {
      vertices = T[5];
    }
    const [P0, P1, P2, P3] = vertices;
    const coords = P[0];
    coords[0] = su;
    coords[1] = sv;
    coords[2] = sw;
    const tmp = P[1];
    const diffX = maxX - minX;
    const diffY = maxY - minY;
    const diffZ = maxZ - minZ;
    tmp[0] = diffX * P0[0] + minX;
    tmp[1] = diffY * P0[1] + minY;
    tmp[2] = diffZ * P0[2] + minZ;
    sample(data, size, tmp[0], tmp[1], tmp[2], C[0]);
    tmp[0] = diffX * P1[0] + minX;
    tmp[1] = diffY * P1[1] + minY;
    tmp[2] = diffZ * P1[2] + minZ;
    sample(data, size, tmp[0], tmp[1], tmp[2], C[1]);
    tmp[0] = diffX * P2[0] + minX;
    tmp[1] = diffY * P2[1] + minY;
    tmp[2] = diffZ * P2[2] + minZ;
    sample(data, size, tmp[0], tmp[1], tmp[2], C[2]);
    tmp[0] = diffX * P3[0] + minX;
    tmp[1] = diffY * P3[1] + minY;
    tmp[2] = diffZ * P3[2] + minZ;
    sample(data, size, tmp[0], tmp[1], tmp[2], C[3]);
    const V0 = calculateTetrahedronVolume(P1, P2, P3, coords) * 6;
    const V1 = calculateTetrahedronVolume(P0, P2, P3, coords) * 6;
    const V2 = calculateTetrahedronVolume(P0, P1, P3, coords) * 6;
    const V3 = calculateTetrahedronVolume(P0, P1, P2, coords) * 6;
    C[0][0] *= V0;
    C[0][1] *= V0;
    C[0][2] *= V0;
    C[1][0] *= V1;
    C[1][1] *= V1;
    C[1][2] *= V1;
    C[2][0] *= V2;
    C[2][1] *= V2;
    C[2][2] *= V2;
    C[3][0] *= V3;
    C[3][1] *= V3;
    C[3][2] *= V3;
    color2[0] = C[0][0] + C[1][0] + C[2][0] + C[3][0];
    color2[1] = C[0][1] + C[1][1] + C[2][1] + C[3][1];
    color2[2] = C[0][2] + C[1][2] + C[2][2] + C[3][2];
  }
}
var TetrahedralUpscaler = class {
  /**
   * Expands the given data to the target size.
   *
   * @param {TypedArray} data - The input RGBA data. Assumed to be cubic.
   * @param {Number} size - The target size.
   * @return {TypedArray} The new data.
   */
  static expand(data, size) {
    const originalSize = Math.cbrt(data.length / 4);
    const array = new data.constructor(size ** 3 * 4);
    const maxValue = data instanceof Uint8Array ? 255 : 1;
    const rgb = new Float32Array(3);
    const sizeSq = size ** 2;
    const s = 1 / (size - 1);
    for (let z = 0; z < size; ++z) {
      for (let y = 0; y < size; ++y) {
        for (let x = 0; x < size; ++x) {
          const u = x * s;
          const v2 = y * s;
          const w = z * s;
          const i4 = Math.round(x + y * size + z * sizeSq) * 4;
          tetrahedralSample(data, originalSize, u, v2, w, rgb);
          array[i4 + 0] = rgb[0];
          array[i4 + 1] = rgb[1];
          array[i4 + 2] = rgb[2];
          array[i4 + 3] = maxValue;
        }
      }
    }
    return array;
  }
};

// src/utils/functions/math.ts
function lerp(a, b, p) {
  return a + (b - a) * p;
}
function saturate(a) {
  return Math.min(Math.max(a, 0), 1);
}

// src/textures/smaa/SMAAAreaImageData.ts
var area = [[0, 0], [0, 0]];
var ORTHOGONAL_SIZE = 16;
var DIAGONAL_SIZE = 20;
var DIAGONAL_SAMPLES = 30;
var SMOOTH_MAX_DISTANCE = 32;
var orthogonalSubsamplingOffsets = [0, -0.25, 0.25, -0.125, 0.125, -0.375, 0.375];
var diagonalSubsamplingOffsets = [
  [0, 0],
  [0.25, -0.25],
  [-0.25, 0.25],
  [0.125, -0.125],
  [-0.125, 0.125]
];
var orthogonalEdges = [
  [0, 0],
  [3, 0],
  [0, 3],
  [3, 3],
  [1, 0],
  [4, 0],
  [1, 3],
  [4, 3],
  [0, 1],
  [3, 1],
  [0, 4],
  [3, 4],
  [1, 1],
  [4, 1],
  [1, 4],
  [4, 4]
];
var diagonalEdges = [
  [0, 0],
  [1, 0],
  [0, 2],
  [1, 2],
  [2, 0],
  [3, 0],
  [2, 2],
  [3, 2],
  [0, 1],
  [1, 1],
  [0, 3],
  [1, 3],
  [2, 1],
  [3, 1],
  [2, 3],
  [3, 3]
];
function smoothArea(d) {
  const a1 = area[0];
  const a2 = area[1];
  const b1X = Math.sqrt(a1[0] * 2) * 0.5;
  const b1Y = Math.sqrt(a1[1] * 2) * 0.5;
  const b2X = Math.sqrt(a2[0] * 2) * 0.5;
  const b2Y = Math.sqrt(a2[1] * 2) * 0.5;
  const p = saturate(d / SMOOTH_MAX_DISTANCE);
  a1[0] = lerp(b1X, a1[0], p);
  a1[1] = lerp(b1Y, a1[1], p);
  a2[0] = lerp(b2X, a2[0], p);
  a2[1] = lerp(b2Y, a2[1], p);
}
function getOrthArea(p1X, p1Y, p2X, p2Y, x, result) {
  const dX = p2X - p1X;
  const dY = p2Y - p1Y;
  const x1 = x;
  const x2 = x + 1;
  const y1 = p1Y + dY * (x1 - p1X) / dX;
  const y2 = p1Y + dY * (x2 - p1X) / dX;
  if (x1 >= p1X && x1 < p2X || x2 > p1X && x2 <= p2X) {
    if (Math.sign(y1) === Math.sign(y2) || Math.abs(y1) < 1e-4 || Math.abs(y2) < 1e-4) {
      const a = (y1 + y2) / 2;
      if (a < 0) {
        result[0] = Math.abs(a);
        result[1] = 0;
      } else {
        result[0] = 0;
        result[1] = Math.abs(a);
      }
    } else {
      const t = -p1Y * dX / dY + p1X;
      const tInt = Math.trunc(t);
      const a1 = t > p1X ? y1 * (t - tInt) / 2 : 0;
      const a2 = t < p2X ? y2 * (1 - (t - tInt)) / 2 : 0;
      const a = Math.abs(a1) > Math.abs(a2) ? a1 : -a2;
      if (a < 0) {
        result[0] = Math.abs(a1);
        result[1] = Math.abs(a2);
      } else {
        result[0] = Math.abs(a2);
        result[1] = Math.abs(a1);
      }
    }
  } else {
    result[0] = 0;
    result[1] = 0;
  }
}
function getOrthAreaForPattern(pattern, left, right, offset, result) {
  const a1 = area[0];
  const a2 = area[1];
  const o1 = 0.5 + offset;
  const o2 = 0.5 + offset - 1;
  const d = left + right + 1;
  switch (pattern) {
    case 0: {
      result[0] = 0;
      result[1] = 0;
      break;
    }
    case 1: {
      if (left <= right) {
        getOrthArea(0, o2, d / 2, 0, left, result);
      } else {
        result[0] = 0;
        result[1] = 0;
      }
      break;
    }
    case 2: {
      if (left >= right) {
        getOrthArea(d / 2, 0, d, o2, left, result);
      } else {
        result[0] = 0;
        result[1] = 0;
      }
      break;
    }
    case 3: {
      getOrthArea(0, o2, d / 2, 0, left, a1);
      getOrthArea(d / 2, 0, d, o2, left, a2);
      smoothArea(d);
      result[0] = a1[0] + a2[0];
      result[1] = a1[1] + a2[1];
      break;
    }
    case 4: {
      if (left <= right) {
        getOrthArea(0, o1, d / 2, 0, left, result);
      } else {
        result[0] = 0;
        result[1] = 0;
      }
      break;
    }
    case 5: {
      result[0] = 0;
      result[1] = 0;
      break;
    }
    case 6: {
      if (Math.abs(offset) > 0) {
        getOrthArea(0, o1, d, o2, left, a1);
        getOrthArea(0, o1, d / 2, 0, left, a2);
        getOrthArea(d / 2, 0, d, o2, left, result);
        a2[0] = a2[0] + result[0];
        a2[1] = a2[1] + result[1];
        result[0] = (a1[0] + a2[0]) / 2;
        result[1] = (a1[1] + a2[1]) / 2;
      } else {
        getOrthArea(0, o1, d, o2, left, result);
      }
      break;
    }
    case 7: {
      getOrthArea(0, o1, d, o2, left, result);
      break;
    }
    case 8: {
      if (left >= right) {
        getOrthArea(d / 2, 0, d, o1, left, result);
      } else {
        result[0] = 0;
        result[1] = 0;
      }
      break;
    }
    case 9: {
      if (Math.abs(offset) > 0) {
        getOrthArea(0, o2, d, o1, left, a1);
        getOrthArea(0, o2, d / 2, 0, left, a2);
        getOrthArea(d / 2, 0, d, o1, left, result);
        a2[0] = a2[0] + result[0];
        a2[1] = a2[1] + result[1];
        result[0] = (a1[0] + a2[0]) / 2;
        result[1] = (a1[1] + a2[1]) / 2;
      } else {
        getOrthArea(0, o2, d, o1, left, result);
      }
      break;
    }
    case 10: {
      result[0] = 0;
      result[1] = 0;
      break;
    }
    case 11: {
      getOrthArea(0, o2, d, o1, left, result);
      break;
    }
    case 12: {
      getOrthArea(0, o1, d / 2, 0, left, a1);
      getOrthArea(d / 2, 0, d, o1, left, a2);
      smoothArea(d);
      result[0] = a1[0] + a2[0];
      result[1] = a1[1] + a2[1];
      break;
    }
    case 13: {
      getOrthArea(0, o2, d, o1, left, result);
      break;
    }
    case 14: {
      getOrthArea(0, o1, d, o2, left, result);
      break;
    }
    case 15: {
      result[0] = 0;
      result[1] = 0;
      break;
    }
  }
}
function isInsideArea(a1X, a1Y, a2X, a2Y, x, y) {
  let result = a1X === a2X && a1Y === a2Y;
  if (!result) {
    const xm = (a1X + a2X) / 2;
    const ym = (a1Y + a2Y) / 2;
    const a = a2Y - a1Y;
    const b = a1X - a2X;
    const c2 = a * (x - xm) + b * (y - ym);
    result = c2 > 0;
  }
  return result;
}
function getDiagAreaForPixel(a1X, a1Y, a2X, a2Y, pX, pY) {
  let n = 0;
  for (let y = 0; y < DIAGONAL_SAMPLES; ++y) {
    for (let x = 0; x < DIAGONAL_SAMPLES; ++x) {
      const offsetX = x / (DIAGONAL_SAMPLES - 1);
      const offsetY = y / (DIAGONAL_SAMPLES - 1);
      if (isInsideArea(a1X, a1Y, a2X, a2Y, pX + offsetX, pY + offsetY)) {
        ++n;
      }
    }
  }
  return n / (DIAGONAL_SAMPLES * DIAGONAL_SAMPLES);
}
function getDiagArea(pattern, a1X, a1Y, a2X, a2Y, left, offset, result) {
  const e = diagonalEdges[pattern];
  const e1 = e[0];
  const e2 = e[1];
  if (e1 > 0) {
    a1X += offset[0];
    a1Y += offset[1];
  }
  if (e2 > 0) {
    a2X += offset[0];
    a2Y += offset[1];
  }
  result[0] = 1 - getDiagAreaForPixel(a1X, a1Y, a2X, a2Y, 1 + left, 0 + left);
  result[1] = getDiagAreaForPixel(a1X, a1Y, a2X, a2Y, 1 + left, 1 + left);
}
function getDiagAreaForPattern(pattern, left, right, offset, result) {
  const a1 = area[0];
  const a2 = area[1];
  const d = left + right + 1;
  switch (pattern) {
    case 0: {
      getDiagArea(pattern, 1, 1, 1 + d, 1 + d, left, offset, a1);
      getDiagArea(pattern, 1, 0, 1 + d, 0 + d, left, offset, a2);
      result[0] = (a1[0] + a2[0]) / 2;
      result[1] = (a1[1] + a2[1]) / 2;
      break;
    }
    case 1: {
      getDiagArea(pattern, 1, 0, 0 + d, 0 + d, left, offset, a1);
      getDiagArea(pattern, 1, 0, 1 + d, 0 + d, left, offset, a2);
      result[0] = (a1[0] + a2[0]) / 2;
      result[1] = (a1[1] + a2[1]) / 2;
      break;
    }
    case 2: {
      getDiagArea(pattern, 0, 0, 1 + d, 0 + d, left, offset, a1);
      getDiagArea(pattern, 1, 0, 1 + d, 0 + d, left, offset, a2);
      result[0] = (a1[0] + a2[0]) / 2;
      result[1] = (a1[1] + a2[1]) / 2;
      break;
    }
    case 3: {
      getDiagArea(pattern, 1, 0, 1 + d, 0 + d, left, offset, result);
      break;
    }
    case 4: {
      getDiagArea(pattern, 1, 1, 0 + d, 0 + d, left, offset, a1);
      getDiagArea(pattern, 1, 1, 1 + d, 0 + d, left, offset, a2);
      result[0] = (a1[0] + a2[0]) / 2;
      result[1] = (a1[1] + a2[1]) / 2;
      break;
    }
    case 5: {
      getDiagArea(pattern, 1, 1, 0 + d, 0 + d, left, offset, a1);
      getDiagArea(pattern, 1, 0, 1 + d, 0 + d, left, offset, a2);
      result[0] = (a1[0] + a2[0]) / 2;
      result[1] = (a1[1] + a2[1]) / 2;
      break;
    }
    case 6: {
      getDiagArea(pattern, 1, 1, 1 + d, 0 + d, left, offset, result);
      break;
    }
    case 7: {
      getDiagArea(pattern, 1, 1, 1 + d, 0 + d, left, offset, a1);
      getDiagArea(pattern, 1, 0, 1 + d, 0 + d, left, offset, a2);
      result[0] = (a1[0] + a2[0]) / 2;
      result[1] = (a1[1] + a2[1]) / 2;
      break;
    }
    case 8: {
      getDiagArea(pattern, 0, 0, 1 + d, 1 + d, left, offset, a1);
      getDiagArea(pattern, 1, 0, 1 + d, 1 + d, left, offset, a2);
      result[0] = (a1[0] + a2[0]) / 2;
      result[1] = (a1[1] + a2[1]) / 2;
      break;
    }
    case 9: {
      getDiagArea(pattern, 1, 0, 1 + d, 1 + d, left, offset, result);
      getDiagArea(pattern, 1, 0, 1 + d, 1 + d, left, offset, result);
      break;
    }
    case 10: {
      getDiagArea(pattern, 0, 0, 1 + d, 1 + d, left, offset, a1);
      getDiagArea(pattern, 1, 0, 1 + d, 0 + d, left, offset, a2);
      result[0] = (a1[0] + a2[0]) / 2;
      result[1] = (a1[1] + a2[1]) / 2;
      break;
    }
    case 11: {
      getDiagArea(pattern, 1, 0, 1 + d, 1 + d, left, offset, a1);
      getDiagArea(pattern, 1, 0, 1 + d, 0 + d, left, offset, a2);
      result[0] = (a1[0] + a2[0]) / 2;
      result[1] = (a1[1] + a2[1]) / 2;
      break;
    }
    case 12: {
      getDiagArea(pattern, 1, 1, 1 + d, 1 + d, left, offset, result);
      break;
    }
    case 13: {
      getDiagArea(pattern, 1, 1, 1 + d, 1 + d, left, offset, a1);
      getDiagArea(pattern, 1, 0, 1 + d, 1 + d, left, offset, a2);
      result[0] = (a1[0] + a2[0]) / 2;
      result[1] = (a1[1] + a2[1]) / 2;
      break;
    }
    case 14: {
      getDiagArea(pattern, 1, 1, 1 + d, 1 + d, left, offset, a1);
      getDiagArea(pattern, 1, 1, 1 + d, 0 + d, left, offset, a2);
      result[0] = (a1[0] + a2[0]) / 2;
      result[1] = (a1[1] + a2[1]) / 2;
      break;
    }
    case 15: {
      getDiagArea(pattern, 1, 1, 1 + d, 1 + d, left, offset, a1);
      getDiagArea(pattern, 1, 0, 1 + d, 0 + d, left, offset, a2);
      result[0] = (a1[0] + a2[0]) / 2;
      result[1] = (a1[1] + a2[1]) / 2;
      break;
    }
  }
}
function generatePatterns(patterns, offset, orthogonal) {
  const result = [0, 0];
  for (let i = 0, l = patterns.length; i < l; ++i) {
    const pattern = patterns[i];
    const data = pattern.data;
    const size = pattern.width;
    for (let y = 0; y < size; ++y) {
      for (let x = 0; x < size; ++x) {
        if (orthogonal) {
          getOrthAreaForPattern(i, x, y, offset[0], result);
        } else {
          getDiagAreaForPattern(i, x, y, offset, result);
        }
        const c2 = (y * size + x) * 2;
        data[c2] = result[0] * 255;
        data[c2 + 1] = result[1] * 255;
      }
    }
  }
}
function assemble(baseX, baseY, patterns, edges2, size, orthogonal, target) {
  const dstData = target.data;
  const dstWidth = target.width;
  for (let i = 0, l = patterns.length; i < l; ++i) {
    const edge = edges2[i];
    const pattern = patterns[i];
    const srcData = pattern.data;
    const srcWidth = pattern.width;
    for (let y = 0; y < size; ++y) {
      for (let x = 0; x < size; ++x) {
        const pX = edge[0] * size + baseX + x;
        const pY = edge[1] * size + baseY + y;
        const c2 = (pY * dstWidth + pX) * 4;
        const d = orthogonal ? (y * y * srcWidth + x * x) * 2 : (y * srcWidth + x) * 2;
        dstData[c2] = srcData[d];
        dstData[c2 + 1] = srcData[d + 1];
        dstData[c2 + 2] = 0;
        dstData[c2 + 3] = 255;
      }
    }
  }
}
var SMAAAreaImageData = class {
  /**
   * Creates a new area image.
   *
   * @return The generated image data.
   */
  static generate() {
    const width = 2 * 5 * ORTHOGONAL_SIZE;
    const height = orthogonalSubsamplingOffsets.length * 5 * ORTHOGONAL_SIZE;
    const data = new Uint8ClampedArray(width * height * 4);
    const result = new RawImageData(width, height, data);
    const orthPatternSize = Math.pow(ORTHOGONAL_SIZE - 1, 2) + 1;
    const orthogonalPatterns = [];
    const diagonalPatterns = [];
    for (let i = 3, l = data.length; i < l; i += 4) {
      data[i] = 255;
    }
    for (let i = 0; i < 16; ++i) {
      orthogonalPatterns.push(new RawImageData(
        orthPatternSize,
        orthPatternSize,
        new Uint8ClampedArray(orthPatternSize * orthPatternSize * 2)
      ));
      diagonalPatterns.push(new RawImageData(
        DIAGONAL_SIZE,
        DIAGONAL_SIZE,
        new Uint8ClampedArray(DIAGONAL_SIZE * DIAGONAL_SIZE * 2)
      ));
    }
    for (let i = 0, l = orthogonalSubsamplingOffsets.length; i < l; ++i) {
      generatePatterns(orthogonalPatterns, [orthogonalSubsamplingOffsets[i]], true);
      assemble(
        0,
        5 * ORTHOGONAL_SIZE * i,
        orthogonalPatterns,
        orthogonalEdges,
        ORTHOGONAL_SIZE,
        true,
        result
      );
    }
    for (let i = 0, l = diagonalSubsamplingOffsets.length; i < l; ++i) {
      generatePatterns(diagonalPatterns, diagonalSubsamplingOffsets[i], false);
      assemble(
        5 * ORTHOGONAL_SIZE,
        4 * DIAGONAL_SIZE * i,
        diagonalPatterns,
        diagonalEdges,
        DIAGONAL_SIZE,
        false,
        result
      );
    }
    return result;
  }
};

// src/textures/smaa/SMAAImageGenerator.ts
import { LoadingManager } from "three";

// temp/smaa/worker.txt
var worker_default2 = '"use strict";(()=>{var j=Object.defineProperty;var B=(r,a,t)=>a in r?j(r,a,{enumerable:!0,configurable:!0,writable:!0,value:t}):r[a]=t;var E=(r,a,t)=>(B(r,typeof a!="symbol"?a+"":a,t),t);function I(r,a,t){return r+(a-r)*t}function W(r){return Math.min(Math.max(r,0),1)}function U(r,a,t){let i=document.createElement("canvas"),n=i.getContext("2d");if(i.width=r,i.height=a,n===null)return i;if(t instanceof Image)n.drawImage(t,0,0);else{let o=n.createImageData(r,a);o.data.set(t),n.putImageData(o,0,0)}return i}var A=class r{constructor(a=0,t=0,i){E(this,"colorSpace");E(this,"width");E(this,"height");E(this,"data");this.colorSpace="srgb",this.width=a,this.height=t,this.data=i}toCanvas(){if(typeof document=="undefined")throw new Error("Failed to create canvas");return U(this.width,this.height,this.data)}static from(a){let{width:t,height:i}=a,n;if(a instanceof Image){let o=U(t,i,a),c=o.getContext("2d");if(o===null||c===null)throw new Error("Failed to create canvas");n=c.getImageData(0,0,t,i).data}else n=a.data;return new r(t,i,n)}};var p=[[0,0],[0,0]],y=16,v=20,C=30,J=32,H=[0,-.25,.25,-.125,.125,-.375,.375],T=[[0,0],[.25,-.25],[-.25,.25],[.125,-.125],[-.125,.125]],K=[[0,0],[3,0],[0,3],[3,3],[1,0],[4,0],[1,3],[4,3],[0,1],[3,1],[0,4],[3,4],[1,1],[4,1],[1,4],[4,4]],G=[[0,0],[1,0],[0,2],[1,2],[2,0],[3,0],[2,2],[3,2],[0,1],[1,1],[0,3],[1,3],[2,1],[3,1],[2,3],[3,3]];function F(r){let a=p[0],t=p[1],i=Math.sqrt(a[0]*2)*.5,n=Math.sqrt(a[1]*2)*.5,o=Math.sqrt(t[0]*2)*.5,c=Math.sqrt(t[1]*2)*.5,e=W(r/J);a[0]=I(i,a[0],e),a[1]=I(n,a[1],e),t[0]=I(o,t[0],e),t[1]=I(c,t[1],e)}function d(r,a,t,i,n,o){let c=t-r,e=i-a,m=n,b=n+1,h=a+e*(m-r)/c,w=a+e*(b-r)/c;if(m>=r&&m<t||b>r&&b<=t)if(Math.sign(h)===Math.sign(w)||Math.abs(h)<1e-4||Math.abs(w)<1e-4){let u=(h+w)/2;u<0?(o[0]=Math.abs(u),o[1]=0):(o[0]=0,o[1]=Math.abs(u))}else{let u=-a*c/e+r,D=Math.trunc(u),M=u>r?h*(u-D)/2:0,k=u<t?w*(1-(u-D))/2:0;(Math.abs(M)>Math.abs(k)?M:-k)<0?(o[0]=Math.abs(M),o[1]=Math.abs(k)):(o[0]=Math.abs(k),o[1]=Math.abs(M))}else o[0]=0,o[1]=0}function Q(r,a,t,i,n){let o=p[0],c=p[1],e=.5+i,m=.5+i-1,b=a+t+1;switch(r){case 0:{n[0]=0,n[1]=0;break}case 1:{a<=t?d(0,m,b/2,0,a,n):(n[0]=0,n[1]=0);break}case 2:{a>=t?d(b/2,0,b,m,a,n):(n[0]=0,n[1]=0);break}case 3:{d(0,m,b/2,0,a,o),d(b/2,0,b,m,a,c),F(b),n[0]=o[0]+c[0],n[1]=o[1]+c[1];break}case 4:{a<=t?d(0,e,b/2,0,a,n):(n[0]=0,n[1]=0);break}case 5:{n[0]=0,n[1]=0;break}case 6:{Math.abs(i)>0?(d(0,e,b,m,a,o),d(0,e,b/2,0,a,c),d(b/2,0,b,m,a,n),c[0]=c[0]+n[0],c[1]=c[1]+n[1],n[0]=(o[0]+c[0])/2,n[1]=(o[1]+c[1])/2):d(0,e,b,m,a,n);break}case 7:{d(0,e,b,m,a,n);break}case 8:{a>=t?d(b/2,0,b,e,a,n):(n[0]=0,n[1]=0);break}case 9:{Math.abs(i)>0?(d(0,m,b,e,a,o),d(0,m,b/2,0,a,c),d(b/2,0,b,e,a,n),c[0]=c[0]+n[0],c[1]=c[1]+n[1],n[0]=(o[0]+c[0])/2,n[1]=(o[1]+c[1])/2):d(0,m,b,e,a,n);break}case 10:{n[0]=0,n[1]=0;break}case 11:{d(0,m,b,e,a,n);break}case 12:{d(0,e,b/2,0,a,o),d(b/2,0,b,e,a,c),F(b),n[0]=o[0]+c[0],n[1]=o[1]+c[1];break}case 13:{d(0,m,b,e,a,n);break}case 14:{d(0,e,b,m,a,n);break}case 15:{n[0]=0,n[1]=0;break}}}function V(r,a,t,i,n,o){let c=r===t&&a===i;if(!c){let e=(r+t)/2,m=(a+i)/2,b=i-a,h=r-t;c=b*(n-e)+h*(o-m)>0}return c}function q(r,a,t,i,n,o){let c=0;for(let e=0;e<C;++e)for(let m=0;m<C;++m){let b=m/(C-1),h=e/(C-1);V(r,a,t,i,n+b,o+h)&&++c}return c/(C*C)}function s(r,a,t,i,n,o,c,e){let m=G[r],b=m[0],h=m[1];b>0&&(a+=c[0],t+=c[1]),h>0&&(i+=c[0],n+=c[1]),e[0]=1-q(a,t,i,n,1+o,0+o),e[1]=q(a,t,i,n,1+o,1+o)}function $(r,a,t,i,n){let o=p[0],c=p[1],e=a+t+1;switch(r){case 0:{s(r,1,1,1+e,1+e,a,i,o),s(r,1,0,1+e,0+e,a,i,c),n[0]=(o[0]+c[0])/2,n[1]=(o[1]+c[1])/2;break}case 1:{s(r,1,0,0+e,0+e,a,i,o),s(r,1,0,1+e,0+e,a,i,c),n[0]=(o[0]+c[0])/2,n[1]=(o[1]+c[1])/2;break}case 2:{s(r,0,0,1+e,0+e,a,i,o),s(r,1,0,1+e,0+e,a,i,c),n[0]=(o[0]+c[0])/2,n[1]=(o[1]+c[1])/2;break}case 3:{s(r,1,0,1+e,0+e,a,i,n);break}case 4:{s(r,1,1,0+e,0+e,a,i,o),s(r,1,1,1+e,0+e,a,i,c),n[0]=(o[0]+c[0])/2,n[1]=(o[1]+c[1])/2;break}case 5:{s(r,1,1,0+e,0+e,a,i,o),s(r,1,0,1+e,0+e,a,i,c),n[0]=(o[0]+c[0])/2,n[1]=(o[1]+c[1])/2;break}case 6:{s(r,1,1,1+e,0+e,a,i,n);break}case 7:{s(r,1,1,1+e,0+e,a,i,o),s(r,1,0,1+e,0+e,a,i,c),n[0]=(o[0]+c[0])/2,n[1]=(o[1]+c[1])/2;break}case 8:{s(r,0,0,1+e,1+e,a,i,o),s(r,1,0,1+e,1+e,a,i,c),n[0]=(o[0]+c[0])/2,n[1]=(o[1]+c[1])/2;break}case 9:{s(r,1,0,1+e,1+e,a,i,n),s(r,1,0,1+e,1+e,a,i,n);break}case 10:{s(r,0,0,1+e,1+e,a,i,o),s(r,1,0,1+e,0+e,a,i,c),n[0]=(o[0]+c[0])/2,n[1]=(o[1]+c[1])/2;break}case 11:{s(r,1,0,1+e,1+e,a,i,o),s(r,1,0,1+e,0+e,a,i,c),n[0]=(o[0]+c[0])/2,n[1]=(o[1]+c[1])/2;break}case 12:{s(r,1,1,1+e,1+e,a,i,n);break}case 13:{s(r,1,1,1+e,1+e,a,i,o),s(r,1,0,1+e,1+e,a,i,c),n[0]=(o[0]+c[0])/2,n[1]=(o[1]+c[1])/2;break}case 14:{s(r,1,1,1+e,1+e,a,i,o),s(r,1,1,1+e,0+e,a,i,c),n[0]=(o[0]+c[0])/2,n[1]=(o[1]+c[1])/2;break}case 15:{s(r,1,1,1+e,1+e,a,i,o),s(r,1,0,1+e,0+e,a,i,c),n[0]=(o[0]+c[0])/2,n[1]=(o[1]+c[1])/2;break}}}function N(r,a,t){let i=[0,0];for(let n=0,o=r.length;n<o;++n){let c=r[n],e=c.data,m=c.width;for(let b=0;b<m;++b)for(let h=0;h<m;++h){t?Q(n,h,b,a[0],i):$(n,h,b,a,i);let w=(b*m+h)*2;e[w]=i[0]*255,e[w+1]=i[1]*255}}}function _(r,a,t,i,n,o,c){let e=c.data,m=c.width;for(let b=0,h=t.length;b<h;++b){let w=i[b],u=t[b],D=u.data,M=u.width;for(let k=0;k<n;++k)for(let x=0;x<n;++x){let Z=w[0]*n+r+x,S=((w[1]*n+a+k)*m+Z)*4,P=o?(k*k*M+x*x)*2:(k*M+x)*2;e[S]=D[P],e[S+1]=D[P+1],e[S+2]=0,e[S+3]=255}}}var L=class{static generate(){let a=10*y,t=H.length*5*y,i=new Uint8ClampedArray(a*t*4),n=new A(a,t,i),o=Math.pow(y-1,2)+1,c=[],e=[];for(let m=3,b=i.length;m<b;m+=4)i[m]=255;for(let m=0;m<16;++m)c.push(new A(o,o,new Uint8ClampedArray(o*o*2))),e.push(new A(v,v,new Uint8ClampedArray(v*v*2)));for(let m=0,b=H.length;m<b;++m)N(c,[H[m]],!0),_(0,5*y*m,c,K,y,!0,n);for(let m=0,b=T.length;m<b;++m)N(e,T[m],!1),_(5*y,4*v*m,e,G,v,!1,n);return n}};var O=new Map([[g(0,0,0,0),[0,0,0,0]],[g(0,0,0,1),[0,0,0,1]],[g(0,0,1,0),[0,0,1,0]],[g(0,0,1,1),[0,0,1,1]],[g(0,1,0,0),[0,1,0,0]],[g(0,1,0,1),[0,1,0,1]],[g(0,1,1,0),[0,1,1,0]],[g(0,1,1,1),[0,1,1,1]],[g(1,0,0,0),[1,0,0,0]],[g(1,0,0,1),[1,0,0,1]],[g(1,0,1,0),[1,0,1,0]],[g(1,0,1,1),[1,0,1,1]],[g(1,1,0,0),[1,1,0,0]],[g(1,1,0,1),[1,1,0,1]],[g(1,1,1,0),[1,1,1,0]],[g(1,1,1,1),[1,1,1,1]]]);function g(r,a,t,i){let n=I(r,a,.75),o=I(t,i,1-.25);return I(n,o,1-.125)}function z(r,a){let t=0;return a[3]===1&&(t+=1),t===1&&a[2]===1&&r[1]!==1&&r[3]!==1&&(t+=1),t}function Y(r,a){let t=0;return a[3]===1&&r[1]!==1&&r[3]!==1&&(t+=1),t===1&&a[2]===1&&r[0]!==1&&r[2]!==1&&(t+=1),t}var R=class{static generate(){let c=new Uint8ClampedArray(2178),e=new Uint8ClampedArray(64*16*4);for(let m=0;m<33;++m)for(let b=0;b<66;++b){let h=.03125*b,w=.03125*m;if(O.has(h)&&O.has(w)){let u=O.get(h),D=O.get(w),M=m*66+b;c[M]=127*z(u,D),c[M+33]=127*Y(u,D)}}for(let m=0,b=17;b<33;++b)for(let h=0;h<64;++h,m+=4)e[m]=c[b*66+h],e[m+3]=255;return new A(64,16,e)}};self.addEventListener("message",()=>{let r=L.generate(),a=R.generate();self.postMessage({areaImageData:r,searchImageData:a},[r.data.buffer,a.data.buffer]),close()});})();\n';

// src/textures/smaa/SMAAImageGenerator.ts
function generate(useCache = true) {
  const workerURL = URL.createObjectURL(new Blob([worker_default2], {
    type: "text/javascript"
  }));
  const worker = new Worker(workerURL);
  URL.revokeObjectURL(workerURL);
  return new Promise((resolve, reject) => {
    worker.addEventListener("error", (event) => reject(event.error));
    worker.addEventListener("message", (event) => {
      const searchImageData = RawImageData.from(event.data.searchImageData);
      const areaImageData = RawImageData.from(event.data.areaImageData);
      const urls = [
        searchImageData.toCanvas().toDataURL("image/png", 1),
        areaImageData.toCanvas().toDataURL("image/png", 1)
      ];
      if (useCache) {
        localStorage.setItem("smaa-search", urls[0]);
        localStorage.setItem("smaa-area", urls[1]);
      }
      resolve(urls);
    });
    worker.postMessage(null);
  });
}
var SMAAImageGenerator = class {
  /**
   * Indicates whether data image caching is enabled. Default is true.
   */
  cacheEnabled;
  /**
   * Constructs a new SMAA image generator.
   */
  constructor() {
    this.cacheEnabled = true;
  }
  /**
   * Generates the SMAA data images.
   *
   * @example
   * SMAAImageGenerator.generate().then(([search, area]) => {
   *   const smaaEffect = new SMAAEffect(search, area);
   * });
   * @return A promise that returns the search image and area image as a pair.
   */
  async generate() {
    const useCache = this.cacheEnabled && window.localStorage !== void 0;
    const cachedURLs = useCache ? [
      localStorage.getItem("smaa-search"),
      localStorage.getItem("smaa-area")
    ] : [null, null];
    const promise = cachedURLs[0] !== null && cachedURLs[1] !== null ? Promise.resolve(cachedURLs) : generate(useCache);
    const urls = await promise;
    return await new Promise((resolve, reject) => {
      const searchImage = new Image();
      const areaImage = new Image();
      const manager = new LoadingManager();
      manager.onLoad = () => resolve([searchImage, areaImage]);
      manager.onError = reject;
      searchImage.addEventListener("error", () => manager.itemError("smaa-search"));
      areaImage.addEventListener("error", () => manager.itemError("smaa-area"));
      searchImage.addEventListener("load", () => manager.itemEnd("smaa-search"));
      areaImage.addEventListener("load", () => manager.itemEnd("smaa-area"));
      manager.itemStart("smaa-search");
      manager.itemStart("smaa-area");
      searchImage.src = urls[0];
      areaImage.src = urls[1];
    });
  }
};

// src/textures/smaa/SMAASearchImageData.ts
var edges = /* @__PURE__ */ new Map([
  [bilinear(0, 0, 0, 0), [0, 0, 0, 0]],
  [bilinear(0, 0, 0, 1), [0, 0, 0, 1]],
  [bilinear(0, 0, 1, 0), [0, 0, 1, 0]],
  [bilinear(0, 0, 1, 1), [0, 0, 1, 1]],
  [bilinear(0, 1, 0, 0), [0, 1, 0, 0]],
  [bilinear(0, 1, 0, 1), [0, 1, 0, 1]],
  [bilinear(0, 1, 1, 0), [0, 1, 1, 0]],
  [bilinear(0, 1, 1, 1), [0, 1, 1, 1]],
  [bilinear(1, 0, 0, 0), [1, 0, 0, 0]],
  [bilinear(1, 0, 0, 1), [1, 0, 0, 1]],
  [bilinear(1, 0, 1, 0), [1, 0, 1, 0]],
  [bilinear(1, 0, 1, 1), [1, 0, 1, 1]],
  [bilinear(1, 1, 0, 0), [1, 1, 0, 0]],
  [bilinear(1, 1, 0, 1), [1, 1, 0, 1]],
  [bilinear(1, 1, 1, 0), [1, 1, 1, 0]],
  [bilinear(1, 1, 1, 1), [1, 1, 1, 1]]
]);
function bilinear(e0, e1, e2, e3) {
  const a = lerp(e0, e1, 1 - 0.25);
  const b = lerp(e2, e3, 1 - 0.25);
  return lerp(a, b, 1 - 0.125);
}
function deltaLeft(left, top) {
  let d = 0;
  if (top[3] === 1) {
    d += 1;
  }
  if (d === 1 && top[2] === 1 && left[1] !== 1 && left[3] !== 1) {
    d += 1;
  }
  return d;
}
function deltaRight(left, top) {
  let d = 0;
  if (top[3] === 1 && left[1] !== 1 && left[3] !== 1) {
    d += 1;
  }
  if (d === 1 && top[2] === 1 && left[0] !== 1 && left[2] !== 1) {
    d += 1;
  }
  return d;
}
var SMAASearchImageData = class {
  /**
   * Creates a new search image.
   *
   * @return The generated image data.
   */
  static generate() {
    const width = 66;
    const height = 33;
    const halfWidth = width / 2;
    const croppedWidth = 64;
    const croppedHeight = 16;
    const data = new Uint8ClampedArray(width * height);
    const croppedData = new Uint8ClampedArray(croppedWidth * croppedHeight * 4);
    for (let y = 0; y < height; ++y) {
      for (let x = 0; x < width; ++x) {
        const s = 0.03125 * x;
        const t = 0.03125 * y;
        if (edges.has(s) && edges.has(t)) {
          const e1 = edges.get(s);
          const e2 = edges.get(t);
          const i = y * width + x;
          data[i] = 127 * deltaLeft(e1, e2);
          data[i + halfWidth] = 127 * deltaRight(e1, e2);
        }
      }
    }
    for (let i = 0, y = height - croppedHeight; y < height; ++y) {
      for (let x = 0; x < croppedWidth; ++x, i += 4) {
        croppedData[i] = data[y * width + x];
        croppedData[i + 3] = 255;
      }
    }
    return new RawImageData(croppedWidth, croppedHeight, croppedData);
  }
};

// src/textures/NoiseTexture.ts
import {
  DataTexture as DataTexture2,
  LuminanceFormat,
  RedFormat,
  RGFormat as RGFormat2,
  RGBAFormat as RGBAFormat3,
  UnsignedByteType as UnsignedByteType8
} from "three";
function getNoise(size, format, type) {
  const channels = /* @__PURE__ */ new Map([
    [LuminanceFormat, 1],
    [RedFormat, 1],
    [RGFormat2, 2],
    [RGBAFormat3, 4]
  ]);
  const c2 = channels.get(format);
  let data;
  if (c2 === void 0) {
    throw new Error(`Texture format not supported: ${format}`);
  }
  if (type === UnsignedByteType8) {
    data = new Uint8Array(size * c2);
    for (let i = 0, l = data.length; i < l; ++i) {
      data[i] = Math.random() * 255 + 0.5;
    }
  } else {
    data = new Float32Array(size * c2);
    for (let i = 0, l = data.length; i < l; ++i) {
      data[i] = Math.random();
    }
  }
  return data;
}
var NoiseTexture = class extends DataTexture2 {
  /**
   * Constructs a new noise texture.
   *
   * Supported texture formats: `RGBAFormat` (default), `LuminanceFormat`.
   * Supported texture formats (WebGL 2): `RedFormat`, `RGFormat`.
   *
   * @param width - The width.
   * @param height - The height.
   * @param format - The texture format.
   * @param type - The texture type.
   */
  constructor(width, height, format = RGBAFormat3, type = UnsignedByteType8) {
    super(getNoise(width * height, format, type), width, height, format, type);
    this.needsUpdate = true;
  }
};

// src/utils/functions/texture.ts
function getHash(texture) {
  const texture3D = texture;
  const attributes = [
    texture.wrapS,
    texture.wrapT,
    texture3D.wrapR || 0,
    texture.magFilter,
    texture.minFilter,
    texture.anisotropy,
    texture.internalFormat,
    texture.format,
    texture.type,
    texture.generateMipmaps,
    texture.premultiplyAlpha,
    texture.flipY,
    texture.unpackAlignment,
    texture.colorSpace
  ];
  return attributes.join(";");
}
export {
  AdaptiveLuminanceMaterial,
  AddBlendFunction,
  AlphaBlendFunction,
  AverageBlendFunction,
  BlendFunction,
  BlendMode,
  BokehMaterial,
  BoxBlurMaterial,
  BufferDebugPass,
  CircleOfConfusionMaterial,
  ClearFlags,
  ClearPass,
  ClearValues,
  ColorBlendFunction,
  ColorBurnBlendFunction,
  ColorChannel,
  ColorDodgeBlendFunction,
  CopyMaterial,
  CopyPass,
  DarkenBlendFunction,
  DepthCopyMaterial,
  DepthCopyMode,
  DepthCopyPass,
  DepthDownsamplingMaterial,
  DepthDownsamplingPass,
  DepthPickingPass,
  DepthTestStrategy,
  DifferenceBlendFunction,
  DivideBlendFunction,
  DownsamplingMaterial,
  DstBlendFunction,
  EdgeDetectionMaterial,
  EdgeDetectionMode,
  Effect,
  EffectMaterial,
  EffectPass,
  EffectShaderData,
  EffectShaderSection,
  ExclusionBlendFunction,
  FXAAEffect,
  FullscreenMaterial,
  GBuffer,
  GData,
  GaussKernel,
  GaussianBlurMaterial,
  GeometryPass,
  GlitchMode,
  HardLightBlendFunction,
  HardMixBlendFunction,
  HueBlendFunction,
  IOManager,
  Input,
  InvertBlendFunction,
  InvertRGBBlendFunction,
  KawaseBlurMaterial,
  KernelSize,
  LambdaPass,
  LightenBlendFunction,
  LinearBurnBlendFunction,
  LinearDodgeBlendFunction,
  LinearLightBlendFunction,
  Log,
  LogLevel,
  LookupTexture,
  LuminanceMaterial,
  LuminancePass,
  LuminosityBlendFunction,
  MaskFunction,
  MaskMaterial,
  MixBlendFunction,
  MultiplyBlendFunction,
  NegationBlendFunction,
  NoiseTexture,
  ObservableMap,
  ObservableSet,
  Output,
  OverlayBlendFunction,
  Pass,
  PinLightBlendFunction,
  PredicationMode,
  RawImageData,
  ReflectBlendFunction,
  RenderPipeline,
  Resolution,
  SMAAAreaImageData,
  SMAAImageGenerator,
  SMAAPreset,
  SMAASearchImageData,
  SMAAWeightsMaterial,
  SaturationBlendFunction,
  ScreenBlendFunction,
  Selection,
  ShaderPass,
  SoftLightBlendFunction,
  SrcBlendFunction,
  SubtractBlendFunction,
  TetrahedralUpscaler,
  TiltShiftBlurMaterial,
  ToneMapping,
  ToneMappingEffect,
  UpsamplingMaterial,
  VignetteEffect,
  VignetteTechnique,
  VividLightBlendFunction,
  getHash,
  lerp,
  orthographicDepthToViewZ,
  prefixSubstrings,
  saturate,
  unpackRGBAToFloat,
  version,
  viewZToOrthographicDepth
};
